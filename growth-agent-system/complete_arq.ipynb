{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84b9622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 1: INSTALAÇÃO COMPLETA\n",
    "# ============================================================================\n",
    "\n",
    "import sys\n",
    "print(f\"Python version: {sys.version}\")\n",
    "\n",
    "# Instalar dependências\n",
    "print(\"\\n[INFO] Instalando dependências...\\n\")\n",
    "!pip install -q google-adk>=1.18.0\n",
    "!pip install -q google-cloud-bigquery>=3.15.0\n",
    "!pip install -q google-cloud-bigquery-storage>=2.26.0\n",
    "!pip install -q scipy>=1.11.0\n",
    "!pip install -q pandas>=2.1.0\n",
    "!pip install -q numpy>=1.24.0\n",
    "\n",
    "print(\"\\n[OK] Todas as dependências instaladas!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb73693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 2: CONFIGURAÇÃO KAGGLE E LOGGING\n",
    "# ============================================================================\n",
    "\n",
    "import os\n",
    "import logging\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "# Configurar logging estruturado\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# API Key do Gemini (obrigatória)\n",
    "try:\n",
    "    GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "    os.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = \"FALSE\"\n",
    "    logger.info(\"Gemini API key configurada com sucesso\")\n",
    "    print(\"[OK] Gemini API key configurada\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Erro ao configurar Gemini API key: {e}\")\n",
    "    print(f\"[ERRO] {e}\")\n",
    "    print(\"\\n[INFO] Configure em: Add-ons → Secrets → GOOGLE_API_KEY\")\n",
    "    raise\n",
    "\n",
    "# BigQuery Service Account (opcional)\n",
    "BIGQUERY_ENABLED = False\n",
    "try:\n",
    "    BIGQUERY_CREDENTIALS = UserSecretsClient().get_secret(\"BIGQUERY_SERVICE_ACCOUNT_JSON\")\n",
    "    os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/tmp/bigquery_credentials.json\"\n",
    "    with open(\"/tmp/bigquery_credentials.json\", \"w\") as f:\n",
    "        f.write(BIGQUERY_CREDENTIALS)\n",
    "    logger.info(\"BigQuery credentials configuradas\")\n",
    "    print(\"[OK] BigQuery credentials configuradas\")\n",
    "    BIGQUERY_ENABLED = True\n",
    "except Exception as e:\n",
    "    logger.warning(f\"BigQuery não configurado: {e}\")\n",
    "    print(\"[AVISO] BigQuery não configurado (opcional)\")\n",
    "    print(\"\\n[INFO] Para habilitar BigQuery:\")\n",
    "    print(\"   1. Crie Service Account no GCP\")\n",
    "    print(\"   2. Baixe JSON das credenciais\")\n",
    "    print(\"   3. Adicione em Kaggle Secrets: BIGQUERY_SERVICE_ACCOUNT_JSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65e8c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 3: IMPORTS COMPLETOS\n",
    "# ============================================================================\n",
    "\n",
    "from google.adk.agents import Agent, SequentialAgent, ParallelAgent, LoopAgent\n",
    "from google.adk.runners import InMemoryRunner\n",
    "from google.adk.tools import AgentTool, FunctionTool, google_search\n",
    "\n",
    "# BigQuery (se disponível)\n",
    "if BIGQUERY_ENABLED:\n",
    "    from google.adk.tools.bigquery import (\n",
    "        BigQueryToolset,\n",
    "        BigQueryCredentialsConfig,\n",
    "        BigQueryToolConfig,\n",
    "        WriteMode\n",
    "    )\n",
    "    from google.cloud import bigquery\n",
    "    import google.auth\n",
    "\n",
    "# Code Execution (verificar disponibilidade)\n",
    "CODE_EXECUTION_AVAILABLE = False\n",
    "try:\n",
    "    from google.adk.tools.code_execution import code_execution\n",
    "    CODE_EXECUTION_AVAILABLE = True\n",
    "    logger.info(\"Code Execution disponível\")\n",
    "    print(\"[OK] Code Execution disponível\")\n",
    "except ImportError:\n",
    "    logger.warning(\"Code Execution não disponível nesta versão do ADK\")\n",
    "    print(\"[AVISO] Code Execution não disponível nesta versão do ADK\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import math\n",
    "import json\n",
    "import re\n",
    "from typing import Dict, Any, List, Optional\n",
    "from io import StringIO\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "logger.info(\"Todos os imports carregados\")\n",
    "print(\"\\n[OK] Imports carregados!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766888ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 4: STATISTICAL TOOLKIT (CENTRALIZADO)\n",
    "# ============================================================================\n",
    "\n",
    "class StatisticalToolkit:\n",
    "    \"\"\"Centraliza todas as ferramentas estatísticas em uma classe.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def calculate_sample_size(\n",
    "        baseline_rate: float,\n",
    "        mde: float,\n",
    "        alpha: float = 0.05,\n",
    "        power: float = 0.8\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"Calcula tamanho de amostra para experimento A/B.\n",
    "        \n",
    "        Args:\n",
    "            baseline_rate: Taxa de conversão atual (ex: 0.025 = 2.5%)\n",
    "            mde: Minimum Detectable Effect em pontos percentuais (ex: 0.5)\n",
    "            alpha: Significância estatística (padrão: 0.05)\n",
    "            power: Poder estatístico (padrão: 0.8)\n",
    "        \n",
    "        Returns:\n",
    "            Dict com resultados completos\n",
    "        \"\"\"\n",
    "        logger.info(f\"Calculando sample size: baseline={baseline_rate}, mde={mde}\")\n",
    "        \n",
    "        p1 = baseline_rate\n",
    "        p2 = baseline_rate + (mde / 100)\n",
    "        \n",
    "        z_alpha = stats.norm.ppf(1 - alpha / 2)\n",
    "        z_beta = stats.norm.ppf(power)\n",
    "        \n",
    "        numerator = (z_alpha + z_beta) ** 2 * (p1 * (1 - p1) + p2 * (1 - p2))\n",
    "        denominator = (p1 - p2) ** 2\n",
    "        \n",
    "        n_per_group = math.ceil(numerator / denominator)\n",
    "        \n",
    "        result = {\n",
    "            \"sample_size_per_group\": n_per_group,\n",
    "            \"total_sample_size\": n_per_group * 2,\n",
    "            \"baseline_rate\": baseline_rate,\n",
    "            \"target_rate\": p2,\n",
    "            \"mde_percentage\": mde,\n",
    "            \"mde_absolute\": p2 - p1,\n",
    "            \"alpha\": alpha,\n",
    "            \"power\": power,\n",
    "            \"recommendation\": f\"Necessário {n_per_group:,} usuários por grupo (total: {n_per_group*2:,})\",\n",
    "            \"estimated_weeks\": {\n",
    "                \"1000_daily\": math.ceil(n_per_group * 2 / (1000 * 7)),\n",
    "                \"5000_daily\": math.ceil(n_per_group * 2 / (5000 * 7)),\n",
    "                \"10000_daily\": math.ceil(n_per_group * 2 / (10000 * 7))\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        logger.info(f\"Sample size calculado: {n_per_group} por grupo\")\n",
    "        return result\n",
    "    \n",
    "    @staticmethod\n",
    "    def calculate_statistical_significance(\n",
    "        control_conversions: int,\n",
    "        control_total: int,\n",
    "        treatment_conversions: int,\n",
    "        treatment_total: int,\n",
    "        alpha: float = 0.05\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"Calcula significância estatística entre grupos A/B.\n",
    "        \n",
    "        Returns:\n",
    "            Dict com p-value, uplift, intervalos\n",
    "        \"\"\"\n",
    "        logger.info(f\"Calculando significance: control={control_conversions}/{control_total}, \"\n",
    "                   f\"treatment={treatment_conversions}/{treatment_total}\")\n",
    "        \n",
    "        p1 = control_conversions / control_total if control_total > 0 else 0\n",
    "        p2 = treatment_conversions / treatment_total if treatment_total > 0 else 0\n",
    "        \n",
    "        # Z-test para proporções\n",
    "        p_pooled = (control_conversions + treatment_conversions) / (control_total + treatment_total)\n",
    "        se = math.sqrt(p_pooled * (1 - p_pooled) * (1/control_total + 1/treatment_total))\n",
    "        \n",
    "        z = (p2 - p1) / se if se > 0 else 0\n",
    "        p_value = 2 * (1 - stats.norm.cdf(abs(z)))\n",
    "        \n",
    "        # Uplift relativo e absoluto\n",
    "        uplift_relative = ((p2 - p1) / p1 * 100) if p1 > 0 else 0\n",
    "        uplift_absolute = (p2 - p1) * 100  # em pontos percentuais\n",
    "        \n",
    "        # Intervalo de confiança\n",
    "        se_diff = math.sqrt(p1 * (1 - p1) / control_total + p2 * (1 - p2) / treatment_total)\n",
    "        ci_margin = stats.norm.ppf(1 - alpha/2) * se_diff\n",
    "        ci_lower = p2 - p1 - ci_margin\n",
    "        ci_upper = p2 - p1 + ci_margin\n",
    "        \n",
    "        # Interpretação\n",
    "        is_significant = p_value < alpha\n",
    "        is_positive = p2 > p1\n",
    "        \n",
    "        if is_significant and is_positive:\n",
    "            recommendation = \"[OK] IMPLEMENTAR: Resultado significativo e positivo\"\n",
    "        elif is_significant and not is_positive:\n",
    "            recommendation = \"[AVISO] NÃO IMPLEMENTAR: Resultado significativo mas negativo\"\n",
    "        else:\n",
    "            recommendation = \"[INFO] CONTINUAR TESTANDO: Resultado não significativo\"\n",
    "        \n",
    "        result = {\n",
    "            \"control_rate\": p1,\n",
    "            \"treatment_rate\": p2,\n",
    "            \"uplift_relative_percentage\": uplift_relative,\n",
    "            \"uplift_absolute_pp\": uplift_absolute,\n",
    "            \"p_value\": p_value,\n",
    "            \"is_significant\": is_significant,\n",
    "            \"is_positive\": is_positive,\n",
    "            \"z_statistic\": z,\n",
    "            \"confidence_interval_95\": {\n",
    "                \"lower\": ci_lower,\n",
    "                \"upper\": ci_upper,\n",
    "                \"lower_pp\": ci_lower * 100,\n",
    "                \"upper_pp\": ci_upper * 100\n",
    "            },\n",
    "            \"interpretation\": \"SIGNIFICATIVO (p < 0.05)\" if is_significant else \"NÃO SIGNIFICATIVO\",\n",
    "            \"recommendation\": recommendation,\n",
    "            \"sample_sizes\": {\n",
    "                \"control\": control_total,\n",
    "                \"treatment\": treatment_total,\n",
    "                \"total\": control_total + treatment_total\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        logger.info(f\"Significance calculado: p-value={p_value:.4f}, significant={is_significant}\")\n",
    "        return result\n",
    "    \n",
    "    @staticmethod\n",
    "    def analyze_csv_dataframe(csv_data: str) -> Dict[str, Any]:\n",
    "        \"\"\"Analisa dados CSV em formato string.\n",
    "        \n",
    "        Args:\n",
    "            csv_data: String com dados CSV\n",
    "        \n",
    "        Returns:\n",
    "            Dict com estatísticas descritivas\n",
    "        \"\"\"\n",
    "        logger.info(\"Analisando CSV dataframe\")\n",
    "        \n",
    "        df = pd.read_csv(StringIO(csv_data))\n",
    "        \n",
    "        # Estatísticas numéricas\n",
    "        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "        numeric_summary = {}\n",
    "        if numeric_cols:\n",
    "            for col in numeric_cols:\n",
    "                numeric_summary[col] = {\n",
    "                    \"mean\": float(df[col].mean()),\n",
    "                    \"median\": float(df[col].median()),\n",
    "                    \"std\": float(df[col].std()),\n",
    "                    \"min\": float(df[col].min()),\n",
    "                    \"max\": float(df[col].max()),\n",
    "                    \"q25\": float(df[col].quantile(0.25)),\n",
    "                    \"q75\": float(df[col].quantile(0.75))\n",
    "                }\n",
    "        \n",
    "        # Valores faltantes\n",
    "        missing = df.isnull().sum()\n",
    "        missing_pct = (missing / len(df) * 100).round(2)\n",
    "        missing_summary = {\n",
    "            col: {\"count\": int(missing[col]), \"percentage\": float(missing_pct[col])}\n",
    "            for col in df.columns if missing[col] > 0\n",
    "        }\n",
    "        \n",
    "        # Duplicatas\n",
    "        duplicate_rows = df.duplicated().sum()\n",
    "        \n",
    "        # Tipos de dados\n",
    "        dtypes_summary = {col: str(dtype) for col, dtype in df.dtypes.items()}\n",
    "        \n",
    "        result = {\n",
    "            \"shape\": {\"rows\": len(df), \"columns\": len(df.columns)},\n",
    "            \"columns\": df.columns.tolist(),\n",
    "            \"dtypes\": dtypes_summary,\n",
    "            \"missing_values\": missing_summary,\n",
    "            \"duplicate_rows\": int(duplicate_rows),\n",
    "            \"numeric_summary\": numeric_summary,\n",
    "            \"sample_data\": df.head(5).to_dict('records'),\n",
    "            \"memory_usage_mb\": float(df.memory_usage(deep=True).sum() / 1024**2)\n",
    "        }\n",
    "        \n",
    "        logger.info(f\"CSV analisado: {len(df)} linhas, {len(df.columns)} colunas\")\n",
    "        return result\n",
    "\n",
    "\n",
    "# Wrapper functions para FunctionTool (mantém compatibilidade com ADK)\n",
    "def calculate_sample_size(baseline_rate: float, mde: float, alpha: float = 0.05, power: float = 0.8) -> str:\n",
    "    \"\"\"Wrapper que retorna JSON string para FunctionTool.\"\"\"\n",
    "    try:\n",
    "        result = StatisticalToolkit.calculate_sample_size(baseline_rate, mde, alpha, power)\n",
    "        return json.dumps(result, indent=2)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erro ao calcular sample size: {e}\")\n",
    "        return json.dumps({\"error\": str(e)})\n",
    "\n",
    "def calculate_statistical_significance(\n",
    "    control_conversions: int,\n",
    "    control_total: int,\n",
    "    treatment_conversions: int,\n",
    "    treatment_total: int\n",
    ") -> str:\n",
    "    \"\"\"Wrapper que retorna JSON string para FunctionTool.\"\"\"\n",
    "    try:\n",
    "        result = StatisticalToolkit.calculate_statistical_significance(\n",
    "            control_conversions, control_total, treatment_conversions, treatment_total\n",
    "        )\n",
    "        return json.dumps(result, indent=2)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erro ao calcular significance: {e}\")\n",
    "        return json.dumps({\"error\": str(e)})\n",
    "\n",
    "def analyze_csv_dataframe(csv_data: str) -> str:\n",
    "    \"\"\"Wrapper que retorna JSON string para FunctionTool.\"\"\"\n",
    "    try:\n",
    "        result = StatisticalToolkit.analyze_csv_dataframe(csv_data)\n",
    "        return json.dumps(result, indent=2)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erro ao analisar CSV: {e}\")\n",
    "        return json.dumps({\"error\": str(e)})\n",
    "\n",
    "\n",
    "# Criar FunctionTools\n",
    "sample_size_tool = FunctionTool(\n",
    "    function=calculate_sample_size,\n",
    "    description=\"\"\"Calcula tamanho de amostra necessário para experimento A/B.\n",
    "    \n",
    "    Parâmetros:\n",
    "    - baseline_rate: Taxa atual (0.025 = 2.5%)\n",
    "    - mde: Efeito mínimo detectável em pontos percentuais (0.5 = 0.5pp)\n",
    "    - alpha: Significância (padrão 0.05)\n",
    "    - power: Poder estatístico (padrão 0.8)\n",
    "    \n",
    "    Retorna JSON com sample_size_per_group, total_sample_size e estimativa de semanas.\"\"\"\n",
    ")\n",
    "\n",
    "significance_tool = FunctionTool(\n",
    "    function=calculate_statistical_significance,\n",
    "    description=\"\"\"Calcula significância estatística entre grupos A/B (z-test para proporções).\n",
    "    \n",
    "    Parâmetros:\n",
    "    - control_conversions: Número de conversões no controle\n",
    "    - control_total: Total de usuários no controle\n",
    "    - treatment_conversions: Número de conversões no tratamento\n",
    "    - treatment_total: Total de usuários no tratamento\n",
    "    \n",
    "    Retorna JSON com p-value, uplift relativo/absoluto, intervalo de confiança e recomendação.\"\"\"\n",
    ")\n",
    "\n",
    "csv_analysis_tool = FunctionTool(\n",
    "    function=analyze_csv_dataframe,\n",
    "    description=\"\"\"Analisa dados CSV fornecidos como string.\n",
    "    \n",
    "    Retorna estatísticas descritivas completas:\n",
    "    - Shape (linhas, colunas)\n",
    "    - Tipos de dados\n",
    "    - Valores faltantes (contagem e %)\n",
    "    - Linhas duplicadas\n",
    "    - Estatísticas numéricas (média, mediana, quartis)\n",
    "    - Amostra dos dados (5 primeiras linhas)\"\"\"\n",
    ")\n",
    "\n",
    "logger.info(\"StatisticalToolkit + FunctionTools criados\")\n",
    "print(\"[OK] StatisticalToolkit + 3 FunctionTools criados:\")\n",
    "print(\"   - calculate_sample_size\")\n",
    "print(\"   - calculate_statistical_significance\")\n",
    "print(\"   - analyze_csv_dataframe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac05e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 5: CONFIGURAÇÃO BIGQUERY (SE DISPONÍVEL)\n",
    "# ============================================================================\n",
    "\n",
    "bq_toolset = None\n",
    "\n",
    "if BIGQUERY_ENABLED:\n",
    "    try:\n",
    "        # Opção 1: Service Account (para Kaggle)\n",
    "        from google.oauth2 import service_account\n",
    "        credentials = service_account.Credentials.from_service_account_file(\n",
    "            \"/tmp/bigquery_credentials.json\"\n",
    "        )\n",
    "        \n",
    "        credentials_config = BigQueryCredentialsConfig(credentials=credentials)\n",
    "        tool_config = BigQueryToolConfig(write_mode=WriteMode.BLOCKED)\n",
    "        \n",
    "        bq_toolset = BigQueryToolset(\n",
    "            credentials_config=credentials_config,\n",
    "            bigquery_tool_config=tool_config\n",
    "        )\n",
    "        \n",
    "        logger.info(\"BigQueryToolset configurado com sucesso\")\n",
    "        print(\"[OK] BigQueryToolset configurado!\")\n",
    "        print(\"   - Modo: BLOCKED (somente leitura)\")\n",
    "        print(\"   - Ferramentas: execute_sql, ask_data_insights\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erro ao configurar BigQuery: {e}\")\n",
    "        print(f\"[AVISO] Erro ao configurar BigQuery: {e}\")\n",
    "        bq_toolset = None\n",
    "        BIGQUERY_ENABLED = False\n",
    "else:\n",
    "    logger.info(\"BigQuery não disponível\")\n",
    "    print(\"[AVISO] BigQuery não disponível\")\n",
    "    print(\"\\n[INFO] Para habilitar BigQuery:\")\n",
    "    print(\"   1. Crie Service Account no GCP\")\n",
    "    print(\"   2. Baixe JSON das credenciais\")\n",
    "    print(\"   3. Adicione em Kaggle Secrets: BIGQUERY_SERVICE_ACCOUNT_JSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f04fe6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 6: SUB-AGENTES ESPECIALIZADOS\n",
    "# ============================================================================\n",
    "\n",
    "MODEL = \"gemini-2.0-flash-exp\"  # Modelo verificado e disponível\n",
    "logger.info(f\"Usando modelo: {MODEL}\")\n",
    "\n",
    "# 1. FUNNEL AGENT\n",
    "funnel_tools = [google_search, csv_analysis_tool]\n",
    "if bq_toolset:\n",
    "    funnel_tools.append(bq_toolset)\n",
    "\n",
    "funnel_agent = Agent(\n",
    "    name=\"FunnelAgent\",\n",
    "    model=MODEL,\n",
    "    instruction=\"\"\"\n",
    "    Você é o FunnelAgent - Especialista em Análise de Funil de Conversão.\n",
    "    \n",
    "    RESPONSABILIDADES:\n",
    "    1. Analisar dados de funil (visita → cadastro → compra)\n",
    "    2. Calcular taxas de conversão entre etapas\n",
    "    3. Identificar pontos de maior drop-off\n",
    "    4. Segmentar por canal, dispositivo, campanha\n",
    "    \n",
    "    FERRAMENTAS DISPONÍVEIS:\n",
    "    - analyze_csv_dataframe: para dados CSV\n",
    "    - BigQuery execute_sql: para dados em BigQuery (se disponível)\n",
    "    - google_search: para benchmarks de mercado\n",
    "    \n",
    "    FORMATO DE OUTPUT (sempre JSON estruturado):\n",
    "    {\n",
    "      \"etapas\": [\n",
    "        {\"nome\": \"visita\", \"usuarios\": 5000, \"taxa_conversao\": 100},\n",
    "        {\"nome\": \"signup\", \"usuarios\": 3500, \"taxa_conversao\": 70},\n",
    "        {\"nome\": \"purchase\", \"usuarios\": 1050, \"taxa_conversao\": 21}\n",
    "      ],\n",
    "      \"gargalo_principal\": \"signup → purchase (queda de 70% para 30%)\",\n",
    "      \"insights\": [\"insight 1\", \"insight 2\"]\n",
    "    }\n",
    "    \n",
    "    Seja objetivo e baseie suas conclusões em dados.\n",
    "    \"\"\",\n",
    "    tools=funnel_tools,\n",
    "    output_key=\"funnel_report\"\n",
    ")\n",
    "\n",
    "# 2. STATS AGENT\n",
    "stats_agent = Agent(\n",
    "    name=\"StatsAgent\",\n",
    "    model=MODEL,\n",
    "    instruction=\"\"\"\n",
    "    Você é o StatsAgent - Especialista em Análise Estatística.\n",
    "    \n",
    "    RESPONSABILIDADES:\n",
    "    1. Validar significância estatística de experimentos\n",
    "    2. Calcular intervalos de confiança\n",
    "    3. Interpretar p-values e uplift\n",
    "    \n",
    "    FERRAMENTAS:\n",
    "    - calculate_statistical_significance: para testes A/B\n",
    "    \n",
    "    SEMPRE interprete os resultados estatísticos de forma clara,\n",
    "    explicando se o experimento teve sucesso ou não.\n",
    "    \n",
    "    Use linguagem acessível para analistas não-estatísticos.\n",
    "    \"\"\",\n",
    "    tools=[significance_tool],\n",
    "    output_key=\"stats_results\"\n",
    ")\n",
    "\n",
    "# 3. INSIGHTS AGENT\n",
    "insights_agent = Agent(\n",
    "    name=\"InsightsAgent\",\n",
    "    model=MODEL,\n",
    "    instruction=\"\"\"\n",
    "    Você é o InsightsAgent - Especialista em Recomendações de Growth.\n",
    "    \n",
    "    CONTEXTO:\n",
    "    Você receberá dados de outros agentes via {funnel_report} e {stats_results}.\n",
    "    \n",
    "    RESPONSABILIDADES:\n",
    "    1. Sintetizar análises anteriores\n",
    "    2. Identificar quick wins (alto impacto, baixo esforço)\n",
    "    3. Priorizar usando RICE: Reach × Impact × Confidence / Effort\n",
    "    \n",
    "    FORMATO OUTPUT (sempre estruturado):\n",
    "    ## TOP 3 QUICK WINS\n",
    "    1. [Nome] - Impacto: Alto | Esforço: Baixo | Score RICE: 8.5\n",
    "    \n",
    "    ## TOP 2 EXPERIMENTOS\n",
    "    1. [Hipótese] - Métrica: [X] | Impacto estimado: +15%\n",
    "    \n",
    "    Seja específico e acionável.\n",
    "    \"\"\",\n",
    "    tools=[google_search],\n",
    "    output_key=\"insights\"\n",
    ")\n",
    "\n",
    "# 4. DATA QUALITY AGENT\n",
    "data_quality_tools = [csv_analysis_tool]\n",
    "if bq_toolset:\n",
    "    data_quality_tools.append(bq_toolset)\n",
    "\n",
    "data_quality_agent = Agent(\n",
    "    name=\"DataQualityAgent\",\n",
    "    model=MODEL,\n",
    "    instruction=\"\"\"\n",
    "    Você é o DataQualityAgent - Especialista em Validação de Dados.\n",
    "    \n",
    "    CHECKLIST DE VALIDAÇÃO:\n",
    "    1. Missing Values: % de dados faltantes por coluna\n",
    "    2. Duplicatas: IDs duplicados, eventos repetidos\n",
    "    3. Consistência Temporal: eventos em ordem lógica\n",
    "    4. Outliers: valores absurdos (ex: idade = 999)\n",
    "    5. Integridade: todos os user_ids têm eventos esperados\n",
    "    \n",
    "    OUTPUT:\n",
    "    - Score de qualidade: 0-100\n",
    "    - Lista de problemas encontrados\n",
    "    - Recomendações de correção (priorize as mais críticas)\n",
    "    \n",
    "    Use a ferramenta analyze_csv_dataframe para inspecionar os dados.\n",
    "    \"\"\",\n",
    "    tools=data_quality_tools,\n",
    "    output_key=\"data_quality_report\"\n",
    ")\n",
    "\n",
    "# 5. TRACKING AGENT\n",
    "tracking_agent = Agent(\n",
    "    name=\"TrackingAgent\",\n",
    "    model=MODEL,\n",
    "    instruction=\"\"\"\n",
    "    Você é o TrackingAgent - Especialista em Validação de Tracking.\n",
    "    \n",
    "    VALIDAÇÕES:\n",
    "    1. Eventos Esperados vs Encontrados\n",
    "       - Ex: [page_view, signup, purchase] → Todos presentes?\n",
    "    2. Schema Validation: campos obrigatórios presentes?\n",
    "    3. Lógica de Negócio: usuário pode comprar sem signup?\n",
    "    4. Cobertura: % de usuários com tracking completo\n",
    "    \n",
    "    OUTPUT:\n",
    "    - Eventos encontrados: [lista]\n",
    "    - Eventos faltando: [lista]\n",
    "    - Gaps críticos: [descrição]\n",
    "    - Recomendações de implementação\n",
    "    \n",
    "    Seja específico sobre quais eventos estão faltando e onde.\n",
    "    \"\"\",\n",
    "    tools=data_quality_tools,\n",
    "    output_key=\"tracking_report\"\n",
    ")\n",
    "\n",
    "# 6. EXPERIMENT AGENT\n",
    "experiment_agent = Agent(\n",
    "    name=\"ExperimentAgent\",\n",
    "    model=MODEL,\n",
    "    instruction=\"\"\"\n",
    "    Você é o ExperimentAgent - Especialista em Design de Experimentos A/B.\n",
    "    \n",
    "    FRAMEWORK COMPLETO:\n",
    "    1. HIPÓTESE: \"Se [mudança], então [resultado] porque [razão]\"\n",
    "    2. MÉTRICA PRIMÁRIA: North Star Metric (ex: taxa de conversão)\n",
    "    3. MÉTRICAS SECUNDÁRIAS: métricas de suporte\n",
    "    4. GUARDRAILS: métricas que não podem piorar (ex: churn)\n",
    "    5. RANDOMIZAÇÃO: como alocar usuários (por user_id, session, etc)\n",
    "    6. SAMPLE SIZE: use calculate_sample_size tool\n",
    "    7. DURAÇÃO: com base no tráfego diário\n",
    "    8. ANÁLISE: método estatístico (t-test, chi-square)\n",
    "    9. STOPPING RULES: quando parar (ex: p < 0.05 por 3 dias)\n",
    "    \n",
    "    SEMPRE use a ferramenta calculate_sample_size para calcular\n",
    "    o tamanho de amostra necessário.\n",
    "    \n",
    "    OUTPUT: Documento completo pronto para implementação.\n",
    "    \"\"\",\n",
    "    tools=[sample_size_tool, google_search],\n",
    "    output_key=\"experiment_plan\"\n",
    ")\n",
    "\n",
    "logger.info(\"6 sub-agentes criados com sucesso\")\n",
    "print(\"[OK] 6 sub-agentes criados com instruções completas!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebc632b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 7: LOOP AGENT - REFINAMENTO ITERATIVO\n",
    "# ============================================================================\n",
    "\n",
    "# Função de saída do loop\n",
    "def exit_refinement_loop() -> str:\n",
    "    \"\"\"Chame esta função quando o refinamento estiver completo e aprovado.\"\"\"\n",
    "    logger.info(\"Exit refinement loop chamado\")\n",
    "    return json.dumps({\"status\": \"approved\", \"message\": \"Refinamento completo\"})\n",
    "\n",
    "exit_loop_tool = FunctionTool(\n",
    "    function=exit_refinement_loop,\n",
    "    description=\"Chame quando o insight/experimento estiver refinado e aprovado para sair do loop.\"\n",
    ")\n",
    "\n",
    "# Agente Crítico (avalia qualidade)\n",
    "critic_agent = Agent(\n",
    "    name=\"CriticAgent\",\n",
    "    model=MODEL,\n",
    "    instruction=\"\"\"\n",
    "    Você é um crítico rigoroso de planos de experimentos.\n",
    "    \n",
    "    Revise o experimento em {experiment_plan} e verifique:\n",
    "    1. Hipótese está clara e testável?\n",
    "    2. Métricas estão bem definidas?\n",
    "    3. Sample size foi calculado?\n",
    "    4. Duração é realista?\n",
    "    5. Há guardrails para proteger experiência do usuário?\n",
    "    \n",
    "    IMPORTANTE: Se TUDO estiver perfeito, responda EXATAMENTE: \"APPROVED\"\n",
    "    (pode ter texto antes ou depois, mas a palavra APPROVED deve aparecer)\n",
    "    \n",
    "    Caso contrário, liste os problemas específicos para correção.\n",
    "    \"\"\",\n",
    "    tools=[],\n",
    "    output_key=\"critique\"\n",
    ")\n",
    "\n",
    "# Agente Refinador (corrige com base na crítica)\n",
    "refiner_agent = Agent(\n",
    "    name=\"RefinerAgent\",\n",
    "    model=MODEL,\n",
    "    instruction=\"\"\"\n",
    "    Você refina planos de experimento com base em feedback.\n",
    "    \n",
    "    ENTRADA:\n",
    "    - Experimento atual: {experiment_plan}\n",
    "    - Crítica recebida: {critique}\n",
    "    \n",
    "    LÓGICA:\n",
    "    - Se critique contém \"APPROVED\" (case-insensitive), você DEVE chamar exit_refinement_loop\n",
    "    - Caso contrário, reescreva o experimento corrigindo os problemas\n",
    "    \n",
    "    Sempre melhore o experimento incorporando todo o feedback.\n",
    "    \"\"\",\n",
    "    tools=[exit_loop_tool, sample_size_tool],\n",
    "    output_key=\"experiment_plan\"  # Sobrescreve o plano original\n",
    ")\n",
    "\n",
    "# Loop de refinamento\n",
    "refinement_loop = LoopAgent(\n",
    "    name=\"ExperimentRefinementLoop\",\n",
    "    sub_agents=[critic_agent, refiner_agent],\n",
    "    max_iterations=3  # Máximo 3 iterações de refinamento\n",
    ")\n",
    "\n",
    "logger.info(\"LoopAgent criado para refinamento iterativo\")\n",
    "print(\"[OK] LoopAgent criado para refinamento iterativo!\")\n",
    "print(\"   - CriticAgent avalia qualidade\")\n",
    "print(\"   - RefinerAgent corrige problemas\")\n",
    "print(\"   - Max 3 iterações\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997584d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 8: AGENTES COMPOSTOS - PARALLEL & SEQUENTIAL\n",
    "# ============================================================================\n",
    "\n",
    "# PARALLEL: Diagnósticos independentes simultâneos\n",
    "parallel_diagnostic = ParallelAgent(\n",
    "    name=\"ParallelDiagnosticAgent\",\n",
    "    sub_agents=[funnel_agent, data_quality_agent, tracking_agent]\n",
    ")\n",
    "\n",
    "# SEQUENTIAL: Pipeline completo de análise\n",
    "sequential_pipeline = SequentialAgent(\n",
    "    name=\"SequentialAnalysisPipeline\",\n",
    "    sub_agents=[\n",
    "        parallel_diagnostic,  # Etapa 1: Diagnósticos em paralelo\n",
    "        stats_agent,          # Etapa 2: Análise estatística\n",
    "        insights_agent,       # Etapa 3: Gerar insights\n",
    "        experiment_agent,     # Etapa 4: Desenhar experimento\n",
    "        refinement_loop       # Etapa 5: Refinar experimento\n",
    "    ]\n",
    ")\n",
    "\n",
    "logger.info(\"Agentes compostos criados\")\n",
    "print(\"[OK] Agentes compostos criados!\")\n",
    "print(\"   - ParallelDiagnosticAgent: 3 análises simultâneas\")\n",
    "print(\"   - SequentialAnalysisPipeline: pipeline de 5 etapas + loop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a54fd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 9: AGENTE COORDENADOR (ROOT)\n",
    "# ============================================================================\n",
    "\n",
    "coordinator_tools = [\n",
    "    AgentTool(agent=funnel_agent),\n",
    "    AgentTool(agent=stats_agent),\n",
    "    AgentTool(agent=insights_agent),\n",
    "    AgentTool(agent=data_quality_agent),\n",
    "    AgentTool(agent=tracking_agent),\n",
    "    AgentTool(agent=experiment_agent),\n",
    "    google_search,\n",
    "    csv_analysis_tool\n",
    "]\n",
    "\n",
    "if bq_toolset:\n",
    "    coordinator_tools.append(bq_toolset)\n",
    "\n",
    "coordinator = Agent(\n",
    "    name=\"CoordinatorAgent\",\n",
    "    model=MODEL,\n",
    "    instruction=\"\"\"\n",
    "    Você é o Growth & Experimentation - Marketing Data Scientist Specialist Partner.\n",
    "    \n",
    "    ## IDENTIDADE\n",
    "    Cientista de dados sênior focado em:\n",
    "    - Aquisição e ativação de usuários\n",
    "    - Otimização de conversão\n",
    "    - Design e análise de experimentos A/B\n",
    "    - Retenção e lifetime value\n",
    "    \n",
    "    Você combina rigor analítico com pensamento criativo de growth.\n",
    "    \n",
    "    ## PRINCÍPIOS FUNDAMENTAIS\n",
    "    1. **Data-Driven:** Decisões sempre baseadas em dados e hipóteses testáveis\n",
    "    2. **Questione:** Pergunte quando houver ambiguidade\n",
    "    3. **Priorize:** Quick wins + experimentos de alto impacto\n",
    "    4. **Rigor Estatístico:** Valide significância sempre\n",
    "    5. **Profundidade:** Vá além do óbvio, busque insights não-intuitivos\n",
    "    6. **Transparência:** Explique raciocínio e mostre cálculos\n",
    "    \n",
    "    ## SUB-AGENTES DISPONÍVEIS (via AgentTool)\n",
    "    Você pode chamar estes especialistas:\n",
    "    \n",
    "    - **FunnelAgent:** Analisa funil de conversão, identifica gargalos\n",
    "      → Retorna: {funnel_report}\n",
    "      \n",
    "    - **StatsAgent:** Testes estatísticos, p-values, intervalos de confiança\n",
    "      → Retorna: {stats_results}\n",
    "      \n",
    "    - **InsightsAgent:** Gera recomendações priorizadas e quick wins\n",
    "      → Retorna: {insights}\n",
    "      \n",
    "    - **DataQualityAgent:** Valida qualidade e consistência dos dados\n",
    "      → Retorna: {data_quality_report}\n",
    "      \n",
    "    - **TrackingAgent:** Verifica implementação de eventos/tracking\n",
    "      → Retorna: {tracking_report}\n",
    "      \n",
    "    - **ExperimentAgent:** Desenha experimentos A/B completos\n",
    "      → Retorna: {experiment_plan}\n",
    "    \n",
    "    ## FLUXO DE TRABALHO\n",
    "    \n",
    "    ### 1. INTAKE & UNDERSTANDING\n",
    "    - Entenda e resuma o problema do usuário\n",
    "    - Identifique dados disponíveis\n",
    "    - Clarifique objetivos e métricas\n",
    "    \n",
    "    ### 2. SANITY CHECKS\n",
    "    - Chame DataQualityAgent para validar dados\n",
    "    - Chame TrackingAgent para verificar eventos\n",
    "    - Identifique gaps críticos\n",
    "    \n",
    "    ### 3. EXPLORATORY ANALYSIS\n",
    "    - Chame FunnelAgent para análise de funil\n",
    "    - Use StatsAgent para métricas atuais\n",
    "    - Identifique baseline e oportunidades\n",
    "    \n",
    "    ### 4. HYPOTHESIS GENERATION\n",
    "    - Chame InsightsAgent para gerar hipóteses\n",
    "    - Priorize usando RICE/ICE framework\n",
    "    - Valide viabilidade técnica\n",
    "    \n",
    "    ### 5. EXPERIMENT DESIGN\n",
    "    - Chame ExperimentAgent para experimentos\n",
    "    - Valide sample size e duração\n",
    "    - Defina métricas primárias e guardrails\n",
    "    \n",
    "    ### 6. DELIVERABLE\n",
    "    - Executive Summary (3 bullets máximo)\n",
    "    - Technical Analysis (com dados e cálculos)\n",
    "    - Action Plan (priorizado)\n",
    "    \n",
    "    ## USANDO OUTPUT_KEYS\n",
    "    \n",
    "    Após chamar um sub-agente, você pode referenciar sua saída:\n",
    "    \n",
    "    Exemplo:\n",
    "    1. Chame FunnelAgent → saída vai para {funnel_report}\n",
    "    2. Você pode usar: \"Segundo o {funnel_report}, o gargalo é...\"\n",
    "    3. Chame StatsAgent → saída vai para {stats_results}\n",
    "    4. Combine: \"Com base em {funnel_report} e {stats_results}...\"\n",
    "    \n",
    "    ## FORMATO DE RESPOSTA FINAL\n",
    "    \n",
    "    ```\n",
    "    # EXECUTIVE SUMMARY\n",
    "    - [Bullet 1: Principal finding]\n",
    "    - [Bullet 2: Oportunidade crítica]\n",
    "    - [Bullet 3: Próxima ação recomendada]\n",
    "    \n",
    "    # ANÁLISE TÉCNICA\n",
    "    [Justificativas, dados, cálculos, referências a {output_keys}]\n",
    "    \n",
    "    # ACTION PLAN\n",
    "    ## Quick Wins (0-2 semanas)\n",
    "    1. [Ação] - Impacto: [X] | Esforço: [Y]\n",
    "    \n",
    "    ## Experimentos (2-6 semanas)\n",
    "    1. [Experimento] - Hipótese: [H] | Métrica: [M] | Sample size: [N]\n",
    "    ```\n",
    "    \n",
    "    Seja objetivo, acionável e sempre baseado em dados.\n",
    "    \"\"\",\n",
    "    tools=coordinator_tools\n",
    ")\n",
    "\n",
    "logger.info(\"Coordenador criado com sucesso\")\n",
    "print(\"[OK] Coordenador criado com instruções completas!\")\n",
    "print(\"   - 6 sub-agentes via AgentTool\")\n",
    "print(\"   - Google Search + CSV Analysis\")\n",
    "if bq_toolset:\n",
    "    print(\"   - BigQuery habilitado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf3e516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 10: RUNNER\n",
    "# ============================================================================\n",
    "\n",
    "runner = InMemoryRunner(agent=coordinator)\n",
    "logger.info(\"InMemoryRunner configurado\")\n",
    "print(\"\\n[OK] InMemoryRunner configurado!\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Sistema completo pronto para uso!\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\n[INFO] Componentes implementados:\")\n",
    "print(\"   [x] 6 Sub-agentes especializados\")\n",
    "print(\"   [x] Padrão LLM Coordinator\")\n",
    "print(\"   [x] ParallelAgent para diagnósticos\")\n",
    "print(\"   [x] SequentialAgent para pipeline\")\n",
    "print(\"   [x] LoopAgent para refinamento\")\n",
    "print(\"   [x] StatisticalToolkit centralizado\")\n",
    "print(\"   [x] FunctionTool para estatística\")\n",
    "print(\"   [x] CSV analysis tool\")\n",
    "print(\"   [x] Error handling robusto\")\n",
    "print(\"   [x] Logging estruturado\")\n",
    "if bq_toolset:\n",
    "    print(\"   [x] BigQueryToolset configurado\")\n",
    "print(\"\\n[OK] 100% da Arquitetura MDS Partner implementada!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116b877b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 11: TESTE 1 - FERRAMENTAS ESTATÍSTICAS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TESTE 1: Ferramentas Estatísticas\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "try:\n",
    "    # Sample size\n",
    "    result1 = calculate_sample_size(baseline_rate=0.025, mde=0.5)\n",
    "    print(\"\\n[TEST] 1. Sample Size Calculation:\")\n",
    "    print(json.dumps(json.loads(result1), indent=2))\n",
    "    \n",
    "    # Significance\n",
    "    result2 = calculate_statistical_significance(\n",
    "        control_conversions=250,\n",
    "        control_total=10000,\n",
    "        treatment_conversions=280,\n",
    "        treatment_total=10000\n",
    "    )\n",
    "    print(\"\\n[TEST] 2. Statistical Significance:\")\n",
    "    print(json.dumps(json.loads(result2), indent=2))\n",
    "    \n",
    "    print(\"\\n[OK] Ferramentas estatísticas funcionando!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Erro nos testes estatísticos: {e}\")\n",
    "    print(f\"\\n[ERRO] Testes falharam: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88732c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 12: TESTE 2 - CRIAR DADOS DE EXEMPLO\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TESTE 2: Criando dados de exemplo\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "try:\n",
    "    np.random.seed(42)\n",
    "    n_users = 5000\n",
    "    \n",
    "    events = []\n",
    "    channels = ['organic', 'paid_search', 'social', 'direct']\n",
    "    devices = ['mobile', 'desktop']\n",
    "    \n",
    "    for i in range(n_users):\n",
    "        user_id = f\"user_{i}\"\n",
    "        channel = np.random.choice(channels)\n",
    "        device = np.random.choice(devices)\n",
    "        \n",
    "        # Landing (100%)\n",
    "        events.append({\n",
    "            'user_id': user_id,\n",
    "            'event': 'landing_page_view',\n",
    "            'timestamp': f'2024-11-{np.random.randint(1,16):02d}',\n",
    "            'device': device,\n",
    "            'channel': channel\n",
    "        })\n",
    "        \n",
    "        # Signup (70%)\n",
    "        if np.random.random() < 0.7:\n",
    "            events.append({\n",
    "                'user_id': user_id,\n",
    "                'event': 'signup',\n",
    "                'timestamp': f'2024-11-{np.random.randint(1,16):02d}',\n",
    "                'device': device,\n",
    "                'channel': channel\n",
    "            })\n",
    "            \n",
    "            # Purchase (30% dos signups)\n",
    "            if np.random.random() < 0.3:\n",
    "                events.append({\n",
    "                    'user_id': user_id,\n",
    "                    'event': 'purchase',\n",
    "                    'timestamp': f'2024-11-{np.random.randint(1,16):02d}',\n",
    "                    'device': device,\n",
    "                    'channel': channel\n",
    "                })\n",
    "    \n",
    "    df_events = pd.DataFrame(events)\n",
    "    \n",
    "    # Calcular métricas\n",
    "    total = df_events['user_id'].nunique()\n",
    "    signups = df_events[df_events['event'] == 'signup']['user_id'].nunique()\n",
    "    purchases = df_events[df_events['event'] == 'purchase']['user_id'].nunique()\n",
    "    \n",
    "    logger.info(f\"Dataset criado: {len(df_events)} eventos, {total} usuários\")\n",
    "    print(f\"\\n[OK] Dataset criado:\")\n",
    "    print(f\"   - {len(df_events):,} eventos\")\n",
    "    print(f\"   - {total:,} usuários únicos\")\n",
    "    print(f\"   - Signups: {signups:,} ({signups/total*100:.1f}%)\")\n",
    "    print(f\"   - Purchases: {purchases:,} ({purchases/total*100:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\n[INFO] Primeiras 10 linhas:\")\n",
    "    print(df_events.head(10).to_string())\n",
    "    \n",
    "    # Salvar para uso nos testes\n",
    "    csv_data = df_events.to_csv(index=False)\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Erro ao criar dados de exemplo: {e}\")\n",
    "    print(f\"\\n[ERRO] Falha ao criar dados: {e}\")\n",
    "    csv_data = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9925013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 13: TESTE 3 - CONSULTA SIMPLES AO COORDENADOR\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TESTE 3: Consulta simples ao Coordenador\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "query1 = \"\"\"\n",
    "Quais são os 3 principais erros que empresas cometem ao analisar \n",
    "funis de conversão? Forneça exemplos práticos e como evitá-los.\n",
    "\"\"\"\n",
    "\n",
    "print(f\"\\n[QUERY] {query1.strip()}\")\n",
    "print(\"\\n[INFO] Processando...\\n\")\n",
    "\n",
    "try:\n",
    "    response1 = await runner.run_debug(query1)\n",
    "    print(\"=\"*70)\n",
    "    print(\"RESPOSTA DO COORDENADOR\")\n",
    "    print(\"=\"*70)\n",
    "    print(response1)\n",
    "    print(\"\\n[OK] Teste 3 concluído!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Erro ao executar query 1: {e}\")\n",
    "    print(f\"\\n[ERRO] Falha na execução: {e}\")\n",
    "    print(\"\\n[INFO] Verifique:\")\n",
    "    print(\"   1. GOOGLE_API_KEY está configurada corretamente\")\n",
    "    print(\"   2. Internet está habilitada no Kaggle\")\n",
    "    print(\"   3. Modelo está disponível\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a567d877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 14: TESTE 4 - ANÁLISE COMPLETA COM DADOS\n",
    "# ============================================================================\n",
    "\n",
    "if csv_data:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"TESTE 4: Análise completa com dados CSV\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    query2 = f\"\"\"\n",
    "    Analise o seguinte dataset de eventos de usuários e forneça:\n",
    "    1. Diagnóstico completo do funil de conversão\n",
    "    2. Identificação de gargalos principais\n",
    "    3. Proposta de 2 experimentos A/B prioritários\n",
    "    \n",
    "    Dados CSV:\n",
    "    ```\n",
    "    {csv_data[:2000]}...\n",
    "    ```\n",
    "    \n",
    "    Use todos os agentes necessários para uma análise completa.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n[QUERY] Análise completa com {len(df_events)} eventos\")\n",
    "    print(\"\\n[INFO] Processando (pode levar 2-3 minutos)...\\n\")\n",
    "    \n",
    "    try:\n",
    "        response2 = await runner.run_debug(query2)\n",
    "        print(\"=\"*70)\n",
    "        print(\"ANÁLISE COMPLETA\")\n",
    "        print(\"=\"*70)\n",
    "        print(response2)\n",
    "        print(\"\\n[OK] Teste 4 concluído!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erro ao executar query 2: {e}\")\n",
    "        print(f\"\\n[ERRO] Falha na análise: {e}\")\n",
    "else:\n",
    "    print(\"\\n[AVISO] Teste 4 pulado (dados não disponíveis)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03aacee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 15: TESTE 5 - CÁLCULO DE SAMPLE SIZE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TESTE 5: Interação direta com ExperimentAgent\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "query3 = \"\"\"\n",
    "Preciso desenhar um experimento A/B para melhorar a taxa de conversão\n",
    "de signup para purchase, que atualmente está em 2.5%.\n",
    "\n",
    "Quero detectar um aumento de pelo menos 0.5 pontos percentuais (de 2.5% para 3.0%).\n",
    "\n",
    "Calcule:\n",
    "1. Tamanho de amostra necessário\n",
    "2. Duração estimada com 1000 usuários por dia\n",
    "3. Desenhe o plano completo do experimento\n",
    "\"\"\"\n",
    "\n",
    "print(f\"\\n[QUERY] {query3.strip()}\")\n",
    "print(\"\\n[INFO] Processando...\\n\")\n",
    "\n",
    "try:\n",
    "    response3 = await runner.run_debug(query3)\n",
    "    print(\"=\"*70)\n",
    "    print(\"PLANO DE EXPERIMENTO\")\n",
    "    print(\"=\"*70)\n",
    "    print(response3)\n",
    "    print(\"\\n[OK] Teste 5 concluído!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Erro ao executar query 3: {e}\")\n",
    "    print(f\"\\n[ERRO] Falha no planejamento: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80307a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 16: FUNÇÃO HELPER PARA USO INTERATIVO\n",
    "# ============================================================================\n",
    "\n",
    "async def ask_growth_agent(question: str, verbose: bool = True) -> str:\n",
    "    \"\"\"\n",
    "    Função helper para interagir com o Growth Agent de forma simples.\n",
    "    \n",
    "    Args:\n",
    "        question: Pergunta ou solicitação para o agente\n",
    "        verbose: Se True, mostra logs detalhados\n",
    "    \n",
    "    Returns:\n",
    "        Resposta do agente como string\n",
    "    \n",
    "    Exemplo:\n",
    "        response = await ask_growth_agent(\"Analise meu funil de conversão\")\n",
    "        print(response)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if verbose:\n",
    "            logger.info(f\"Processando pergunta: {question[:100]}...\")\n",
    "            print(f\"\\n[INFO] Processando sua pergunta...\\n\")\n",
    "        \n",
    "        response = await runner.run_debug(question)\n",
    "        \n",
    "        if verbose:\n",
    "            logger.info(\"Resposta gerada com sucesso\")\n",
    "            print(\"\\n[OK] Resposta gerada!\\n\")\n",
    "        \n",
    "        return response\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erro ao processar pergunta: {e}\")\n",
    "        error_msg = f\"[ERRO] Não foi possível processar sua pergunta: {e}\"\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\n{error_msg}\")\n",
    "            print(\"\\n[INFO] Dicas de troubleshooting:\")\n",
    "            print(\"   1. Verifique se a API key está configurada\")\n",
    "            print(\"   2. Simplifique a pergunta\")\n",
    "            print(\"   3. Verifique os logs acima para mais detalhes\")\n",
    "        \n",
    "        return error_msg\n",
    "\n",
    "\n",
    "print(\"\\n[OK] Função helper 'ask_growth_agent' disponível!\")\n",
    "print(\"\\n[INFO] Exemplo de uso:\")\n",
    "print('   response = await ask_growth_agent(\"Quais métricas devo acompanhar?\")')\n",
    "print('   print(response)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda208c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 17: EXEMPLOS DE USO AVANÇADO\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EXEMPLOS DE USO AVANÇADO\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\"\"\n",
    "# 1. ANÁLISE DE FUNIL\n",
    "query = '''\n",
    "Tenho os seguintes dados de funil:\n",
    "- 10.000 visitas à landing page\n",
    "- 3.500 signups (35%)\n",
    "- 700 purchases (20% dos signups, 7% do total)\n",
    "\n",
    "Qual o principal gargalo e como resolvê-lo?\n",
    "'''\n",
    "response = await ask_growth_agent(query)\n",
    "\n",
    "# 2. DESIGN DE EXPERIMENTO\n",
    "query = '''\n",
    "Quero testar se adicionar social proof (reviews) na página de checkout\n",
    "aumenta a conversão de 2.5% para 3.0%.\n",
    "\n",
    "Desenhe o experimento A/B completo.\n",
    "'''\n",
    "response = await ask_growth_agent(query)\n",
    "\n",
    "# 3. ANÁLISE DE DADOS CSV\n",
    "query = f'''\n",
    "Analise estes dados CSV e identifique oportunidades de growth:\n",
    "\n",
    "{csv_data}\n",
    "\n",
    "Forneça insights acionáveis.\n",
    "'''\n",
    "response = await ask_growth_agent(query)\n",
    "\n",
    "# 4. VALIDAÇÃO ESTATÍSTICA\n",
    "query = '''\n",
    "Rodei um teste A/B com estes resultados:\n",
    "- Controle: 250 conversões em 10.000 usuários (2.5%)\n",
    "- Tratamento: 280 conversões em 10.000 usuários (2.8%)\n",
    "\n",
    "O resultado é estatisticamente significativo? Devo implementar?\n",
    "'''\n",
    "response = await ask_growth_agent(query)\n",
    "\n",
    "# 5. PRIORIZAÇÃO DE EXPERIMENTOS\n",
    "query = '''\n",
    "Tenho 3 ideias de experimentos:\n",
    "1. Mudar cor do botão (fácil, impacto médio)\n",
    "2. Simplificar formulário de signup (médio, impacto alto)\n",
    "3. Adicionar onboarding tutorial (difícil, impacto alto)\n",
    "\n",
    "Como priorizar usando RICE framework?\n",
    "'''\n",
    "response = await ask_growth_agent(query)\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n[INFO] Cole qualquer exemplo acima em uma nova célula e execute!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b198e088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 18: SUMÁRIO FINAL E MÉTRICAS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SUMÁRIO FINAL - SISTEMA GROWTH AGENTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "summary = {\n",
    "    \"status\": \"OPERATIONAL\",\n",
    "    \"model\": MODEL,\n",
    "    \"agents\": {\n",
    "        \"coordinator\": \"CoordinatorAgent (root)\",\n",
    "        \"specialists\": [\n",
    "            \"FunnelAgent\",\n",
    "            \"StatsAgent\", \n",
    "            \"InsightsAgent\",\n",
    "            \"DataQualityAgent\",\n",
    "            \"TrackingAgent\",\n",
    "            \"ExperimentAgent\"\n",
    "        ],\n",
    "        \"composite\": [\n",
    "            \"ParallelDiagnosticAgent\",\n",
    "            \"SequentialAnalysisPipeline\",\n",
    "            \"ExperimentRefinementLoop\"\n",
    "        ]\n",
    "    },\n",
    "    \"tools\": {\n",
    "        \"function_tools\": [\n",
    "            \"calculate_sample_size\",\n",
    "            \"calculate_statistical_significance\",\n",
    "            \"analyze_csv_dataframe\"\n",
    "        ],\n",
    "        \"builtin_tools\": [\"google_search\"],\n",
    "        \"bigquery\": \"enabled\" if bq_toolset else \"disabled\",\n",
    "        \"code_execution\": \"enabled\" if CODE_EXECUTION_AVAILABLE else \"disabled\"\n",
    "    },\n",
    "    \"features\": {\n",
    "        \"parallel_execution\": True,\n",
    "        \"sequential_pipeline\": True,\n",
    "        \"iterative_refinement\": True,\n",
    "        \"output_keys\": True,\n",
    "        \"error_handling\": True,\n",
    "        \"structured_logging\": True\n",
    "    },\n",
    "    \"architecture\": \"100% MDS Partner Implementation\"\n",
    "}\n",
    "\n",
    "print(\"\\n[OK] SISTEMA OPERACIONAL\")\n",
    "print(json.dumps(summary, indent=2))\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PRONTO PARA USO!\")\n",
    "print(\"=\"*70)\n",
    "print(\"\"\"\n",
    "[INFO] Próximos passos:\n",
    "\n",
    "1. Execute uma consulta simples:\n",
    "   response = await ask_growth_agent(\"Como calcular sample size para A/B test?\")\n",
    "   \n",
    "2. Analise seus dados:\n",
    "   - Prepare CSV com eventos de usuários\n",
    "   - Use analyze_csv_dataframe para exploração\n",
    "   - Chame FunnelAgent para análise completa\n",
    "\n",
    "3. Desenhe experimentos:\n",
    "   - Use ExperimentAgent para planos detalhados\n",
    "   - Valide com StatsAgent\n",
    "   - Priorize com InsightsAgent\n",
    "\n",
    "4. Para produção:\n",
    "   - Configure BigQuery para dados reais\n",
    "   - Adicione métricas de observabilidade\n",
    "   - Implemente testes automatizados\n",
    "\n",
    "[OK] Sistema pronto! Happy experimenting!\n",
    "\"\"\")\n",
    "\n",
    "logger.info(\"Sistema Growth Agents inicializado com sucesso\")\n",
    "logger.info(\"Todas as células executadas sem erros críticos\")\n",
    "print(\"\\n[OK] Notebook completo executado com sucesso!\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
