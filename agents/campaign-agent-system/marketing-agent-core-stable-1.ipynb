{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"168199c2","cell_type":"markdown","source":"# ğŸ† MktPartner: Democratizando a CiÃªncia de Dados SÃªnior para o Brasil\n\n### **O Problema: O Abismo da InteligÃªncia de Dados**\nNo Brasil, 99% das empresas sÃ£o MPEs (Micro e Pequenas Empresas). O lucro mÃ©dio de um microempreendedor gira em torno de **2 salÃ¡rios mÃ­nimos**. Enquanto grandes corporaÃ§Ãµes investem milhÃµes em equipes de Data Science para otimizar cada centavo de marketing, o pequeno empresÃ¡rio opera no \"feeling\".\n*   **A consequÃªncia:** 29% fecham em 5 anos, muitas vezes por queimarem caixa em estratÃ©gias erradas.\n*   **A barreira:** Contratar um Cientista de Dados SÃªnior custa 10x o que eles ganham.\n\n### **A SoluÃ§Ã£o: Agentes de IA como \"SÃ³cios Fracionados\"**\nEste projeto constrÃ³i o **MktPartner**, um Sistema Multi-Agente que atua como um Cientista de Dados e Estrategista SÃªnior acessÃ­vel.\nNÃ£o Ã© apenas um chatbot. Ã‰ uma **equipe completa** (EstatÃ­stico, Auditor, Diretor Criativo, Estrategista) que:\n1.  **Audita Dados:** Garante que o dinheiro nÃ£o estÃ¡ indo para o ralo.\n2.  **Calcula Risco:** Usa estatÃ­stica rigorosa (nÃ£o alucinaÃ§Ã£o) para validar testes A/B.\n3.  **Define EstratÃ©gia:** Usa frameworks como RICE e RCA para priorizar o lucro.\n\n---\n**Arquitetura:** Google ADK + Gemini 2.0 Flash + Scipy/Pandas + Gradio.","metadata":{}},{"id":"29383bae","cell_type":"markdown","source":"## ğŸ› ï¸ Fase 1: A FundaÃ§Ã£o da Firma Virtual\nPara construir um escritÃ³rio de consultoria digital, precisamos das ferramentas certas. Aqui, instalamos o **Google ADK** (Agent Development Kit), que serÃ¡ o cÃ©rebro dos nossos agentes, e bibliotecas de anÃ¡lise de dados (`pandas`, `scipy`) que serÃ£o suas calculadoras. Diferente de modelos puramente linguÃ­sticos, nossos agentes precisam de \"Hard Skills\" matemÃ¡ticas.","metadata":{}},{"id":"cf4c84f4-3400-48a5-b5de-423703a53b94","cell_type":"code","source":"# CÃ©lula 1\nimport sys\nimport subprocess\nimport os\n\n# Limpa ambiente antigo para garantir construÃ§Ã£o limpa\n!rm -rf marketing_agent\n!mkdir -p marketing_agent\n!touch marketing_agent/__init__.py\n\nprint(f\"ğŸ Python: {sys.version}\")\nprint(\"\\n[INFO] Installing dependencies...\\n\")\n\nsubprocess.check_call([\n    sys.executable, \"-m\", \"pip\", \"uninstall\", \"-y\",\n    \"opentelemetry-api\",\n    \"opentelemetry-sdk\",\n    \"google-ai-generativelanguage\",\n    \"google-generativeai\",\n    \"protobuf\"\n])\n\n%pip install \\\n    \"protobuf<5.0.0\" \\\n    \"opentelemetry-api==1.37.0\" \\\n    \"opentelemetry-sdk==1.37.0\" \\\n    \"opentelemetry-proto\" \\\n    \"opentelemetry-exporter-otlp-proto-common==1.37.0\" \\\n    \"opentelemetry-exporter-otlp-proto-http==1.37.0\" \\\n    \"google-ai-generativelanguage==0.6.15\" \\\n    \"google-generativeai==0.8.5\" \\\n    \"langchain-google-genai\" \\\n    \"langchain>=0.1.0\" \\\n    \"google-adk>=1.18.0\" \\\n    \"chromadb\" \\\n    \"scipy>=1.11.0\" \\\n    \"pandas==2.2.2\" \\\n    \"numpy>=1.24.0\" \\\n    \"tenacity>=8.2.3\" \\\n    \"duckduckgo-search\"\n\nprint(\"\\n[OK] All dependencies installed! âœ…\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T23:46:31.844995Z","iopub.execute_input":"2025-11-26T23:46:31.845565Z","iopub.status.idle":"2025-11-26T23:46:39.136505Z","shell.execute_reply.started":"2025-11-26T23:46:31.845522Z","shell.execute_reply":"2025-11-26T23:46:39.134941Z"}},"outputs":[{"name":"stdout","text":"ğŸ Python: 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\n\n[INFO] Installing dependencies...\n\n","output_type":"stream"},{"name":"stderr","text":"WARNING: Skipping opentelemetry-api as it is not installed.\nWARNING: Skipping opentelemetry-sdk as it is not installed.\nWARNING: Skipping google-ai-generativelanguage as it is not installed.\nWARNING: Skipping google-generativeai as it is not installed.\nWARNING: Skipping protobuf as it is not installed.\n","output_type":"stream"},{"name":"stdout","text":"Collecting protobuf<5.0.0\n  Using cached protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\nCollecting opentelemetry-api==1.37.0\n  Using cached opentelemetry_api-1.37.0-py3-none-any.whl.metadata (1.5 kB)\nCollecting opentelemetry-sdk==1.37.0\n  Using cached opentelemetry_sdk-1.37.0-py3-none-any.whl.metadata (1.5 kB)\nRequirement already satisfied: opentelemetry-proto in /usr/local/lib/python3.11/dist-packages (1.37.0)\nRequirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.37.0 in /usr/local/lib/python3.11/dist-packages (1.37.0)\nRequirement already satisfied: opentelemetry-exporter-otlp-proto-http==1.37.0 in /usr/local/lib/python3.11/dist-packages (1.37.0)\nCollecting google-ai-generativelanguage==0.6.15\n  Using cached google_ai_generativelanguage-0.6.15-py3-none-any.whl.metadata (5.7 kB)\nCollecting google-generativeai==0.8.5\n  Using cached google_generativeai-0.8.5-py3-none-any.whl.metadata (3.9 kB)\nRequirement already satisfied: langchain-google-genai in /usr/local/lib/python3.11/dist-packages (2.1.12)\nRequirement already satisfied: langchain>=0.1.0 in /usr/local/lib/python3.11/dist-packages (0.3.27)\nRequirement already satisfied: google-adk>=1.18.0 in /usr/local/lib/python3.11/dist-packages (1.18.0)\nCollecting chromadb\n  Using cached chromadb-1.3.5-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.2 kB)\nRequirement already satisfied: scipy>=1.11.0 in /usr/local/lib/python3.11/dist-packages (1.15.3)\nCollecting pandas==2.2.2\n  Using cached pandas-2.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\nRequirement already satisfied: numpy>=1.24.0 in /usr/local/lib/python3.11/dist-packages (1.26.4)\nRequirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (9.1.2)\nRequirement already satisfied: duckduckgo-search in /usr/local/lib/python3.11/dist-packages (8.1.1)\nRequirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api==1.37.0) (8.7.0)\nRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api==1.37.0) (4.15.0)\nRequirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-sdk==1.37.0) (0.58b0)\nINFO: pip is looking at multiple versions of opentelemetry-proto to determine which version is compatible with other requirements. This could take a while.\nCollecting opentelemetry-exporter-otlp-proto-common==1.37.0\n  Downloading opentelemetry_exporter_otlp_proto_common-1.37.0-py3-none-any.whl.metadata (1.8 kB)\n\u001b[31mERROR: Cannot install opentelemetry-proto==1.37.0 and protobuf<5.0.0 because these package versions have conflicting dependencies.\u001b[0m\u001b[31m\n\u001b[0m\nThe conflict is caused by:\n    The user requested protobuf<5.0.0\n    opentelemetry-proto 1.37.0 depends on protobuf<7.0 and >=5.0\n\nTo fix this you could try to:\n1. loosen the range of package versions you've specified\n2. remove package versions to allow pip to attempt to solve the dependency conflict\n\n\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\u001b[0m\u001b[31m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n\n[OK] All dependencies installed! âœ…\n\n","output_type":"stream"}],"execution_count":11},{"id":"a5e60ac3-506a-49bb-9c45-e70c44d1de10","cell_type":"code","source":"# CÃ©lula 2\n!pip install -q google-adk 2>/dev/null || echo \"Google ADK pode nÃ£o estar disponÃ­vel\"\n!pip install -q pysqlite3-binary\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T23:31:31.864418Z","iopub.execute_input":"2025-11-26T23:31:31.864676Z","iopub.status.idle":"2025-11-26T23:31:43.752996Z","shell.execute_reply.started":"2025-11-26T23:31:31.864652Z","shell.execute_reply":"2025-11-26T23:31:43.751565Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m65.7/65.7 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m131.9/131.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m319.9/319.9 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":2},{"id":"4628dd80-807e-419c-9d5a-32d76ff4cdfc","cell_type":"code","source":"# CÃ©lula 3\n!pip install -U \"langchain-google-genai\" \"langchain-core<1.0.0\"\n!export GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T23:31:43.754497Z","iopub.execute_input":"2025-11-26T23:31:43.754821Z","iopub.status.idle":"2025-11-26T23:31:52.405971Z","shell.execute_reply.started":"2025-11-26T23:31:43.754791Z","shell.execute_reply":"2025-11-26T23:31:52.404567Z"}},"outputs":[{"name":"stdout","text":"Collecting langchain-google-genai\n  Using cached langchain_google_genai-3.2.0-py3-none-any.whl.metadata (2.7 kB)\nRequirement already satisfied: langchain-core<1.0.0 in /usr/local/lib/python3.11/dist-packages (0.3.72)\nCollecting langchain-core<1.0.0\n  Downloading langchain_core-0.3.80-py3-none-any.whl.metadata (3.2 kB)\nRequirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (1.2.0)\nCollecting google-ai-generativelanguage<1.0.0,>=0.9.0 (from langchain-google-genai)\n  Downloading google_ai_generativelanguage-0.9.0-py3-none-any.whl.metadata (10 kB)\nINFO: pip is looking at multiple versions of langchain-google-genai to determine which version is compatible with other requirements. This could take a while.\nCollecting langchain-google-genai\n  Downloading langchain_google_genai-3.1.0-py3-none-any.whl.metadata (2.7 kB)\n  Downloading langchain_google_genai-3.0.3-py3-none-any.whl.metadata (2.7 kB)\n  Downloading langchain_google_genai-3.0.2-py3-none-any.whl.metadata (2.7 kB)\n  Downloading langchain_google_genai-3.0.1-py3-none-any.whl.metadata (7.1 kB)\n  Downloading langchain_google_genai-3.0.0-py3-none-any.whl.metadata (7.1 kB)\n  Downloading langchain_google_genai-2.1.12-py3-none-any.whl.metadata (7.1 kB)\nRequirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (2.12.4)\nRequirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0) (0.4.8)\nRequirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0) (9.1.2)\nRequirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0) (1.33)\nRequirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0) (6.0.3)\nRequirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0) (4.15.0)\nRequirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0) (25.0)\nRequirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (2.28.1)\nRequirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (2.38.0)\nRequirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (1.74.0)\nRequirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (1.26.1)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (5.29.5)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0) (3.0.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0) (0.28.1)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0) (3.11.0)\nRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0) (2.32.5)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0) (1.0.0)\nRequirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0) (0.23.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain-google-genai) (0.7.0)\nRequirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain-google-genai) (2.41.5)\nRequirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain-google-genai) (0.4.2)\nRequirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (1.70.0)\nRequirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (1.71.2)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (5.5.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (0.4.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (4.9.1)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0) (4.11.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0) (2025.10.5)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0) (1.0.9)\nRequirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0) (3.11)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0) (0.16.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0) (3.4.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0) (2.5.0)\nRequirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1.0.0,>=0.9.0->langchain-google-genai) (0.6.1)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0) (1.3.1)\nDownloading langchain_google_genai-2.1.12-py3-none-any.whl (50 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading langchain_core-0.3.80-py3-none-any.whl (450 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m450.8/450.8 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading google_ai_generativelanguage-0.9.0-py3-none-any.whl (1.4 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: langchain-core, google-ai-generativelanguage, langchain-google-genai\n  Attempting uninstall: langchain-core\n    Found existing installation: langchain-core 0.3.72\n    Uninstalling langchain-core-0.3.72:\n      Successfully uninstalled langchain-core-0.3.72\nSuccessfully installed google-ai-generativelanguage-0.9.0 langchain-core-0.3.80 langchain-google-genai-2.1.12\n/bin/bash: -c: line 1: syntax error near unexpected token `('\n/bin/bash: -c: line 1: `export GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")'\n","output_type":"stream"}],"execution_count":3},{"id":"e99322ca-46ac-4af9-bfb4-4089e848360c","cell_type":"code","source":"%pip install \"langchain-community\" \"numpy<2.0.0\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T23:31:52.408351Z","iopub.execute_input":"2025-11-26T23:31:52.408677Z","iopub.status.idle":"2025-11-26T23:32:03.039808Z","shell.execute_reply.started":"2025-11-26T23:31:52.408647Z","shell.execute_reply":"2025-11-26T23:32:03.038240Z"}},"outputs":[{"name":"stdout","text":"Collecting langchain-community\n  Downloading langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\nRequirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.11/dist-packages (1.26.4)\nCollecting langchain-core<2.0.0,>=1.0.1 (from langchain-community)\n  Downloading langchain_core-1.1.0-py3-none-any.whl.metadata (3.6 kB)\nCollecting langchain-classic<2.0.0,>=1.0.0 (from langchain-community)\n  Downloading langchain_classic-1.0.0-py3-none-any.whl.metadata (3.9 kB)\nRequirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.41)\nRequirement already satisfied: requests<3.0.0,>=2.32.5 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.5)\nRequirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.3)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.13.2)\nRequirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\nRequirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\nRequirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.11.0)\nRequirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.8)\nRequirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0) (2.4.1)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\nCollecting langchain-text-splitters<2.0.0,>=1.0.0 (from langchain-classic<2.0.0,>=1.0.0->langchain-community)\n  Downloading langchain_text_splitters-1.0.0-py3-none-any.whl.metadata (2.6 kB)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (2.12.4)\nRequirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (1.33)\nRequirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (25.0)\nRequirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (4.15.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.28.1)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.11.0)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\nRequirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.23.0)\nRequirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (0.4.2)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2025.10.5)\nRequirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.2.3)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0.0) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0.0) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2.0.0) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2.0.0) (2024.2.0)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (4.11.0)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (0.16.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2.0.0) (2024.2.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.1->langchain-community) (3.0.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community) (0.7.0)\nRequirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community) (2.41.5)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.3.1)\nDownloading langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading langchain_classic-1.0.0-py3-none-any.whl (1.0 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_core-1.1.0-py3-none-any.whl (473 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m473.8/473.8 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_text_splitters-1.0.0-py3-none-any.whl (33 kB)\nInstalling collected packages: langchain-core, langchain-text-splitters, langchain-classic, langchain-community\n  Attempting uninstall: langchain-core\n    Found existing installation: langchain-core 0.3.80\n    Uninstalling langchain-core-0.3.80:\n      Successfully uninstalled langchain-core-0.3.80\n  Attempting uninstall: langchain-text-splitters\n    Found existing installation: langchain-text-splitters 0.3.9\n    Uninstalling langchain-text-splitters-0.3.9:\n      Successfully uninstalled langchain-text-splitters-0.3.9\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlangchain 0.3.27 requires langchain-core<1.0.0,>=0.3.72, but you have langchain-core 1.1.0 which is incompatible.\nlangchain 0.3.27 requires langchain-text-splitters<1.0.0,>=0.3.9, but you have langchain-text-splitters 1.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed langchain-classic-1.0.0 langchain-community-0.4.1 langchain-core-1.1.0 langchain-text-splitters-1.0.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":4},{"id":"5b9fbe7f-ff17-4568-9bd4-011aa5d73f67","cell_type":"code","source":"# CÃ©lula 5\n!pip install -q duckduckgo-search","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T23:32:03.041059Z","iopub.execute_input":"2025-11-26T23:32:03.041446Z","iopub.status.idle":"2025-11-26T23:32:08.185305Z","shell.execute_reply.started":"2025-11-26T23:32:03.041407Z","shell.execute_reply":"2025-11-26T23:32:08.184279Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":5},{"id":"696a0a75","cell_type":"markdown","source":"## ğŸ§° Fase 2: Equipando os Especialistas\nUm bom cientista de dados precisa de resiliÃªncia e memÃ³ria. Aqui instalamos:\n*   **LangChain & ChromaDB (RAG):** Para que o agente tenha \"memÃ³ria de longo prazo\" (Playbooks de Marketing) e nÃ£o precise reaprender estratÃ©gias bÃ¡sicas a cada sessÃ£o.\n*   **Tenacity:** Para garantir que o sistema nÃ£o falhe se uma API oscilar (resiliÃªncia empresarial).","metadata":{}},{"id":"0245d4bd-1101-490a-a193-cce8fa03ea37","cell_type":"code","source":"# ====================================================================\n# CELL 8: IMPORTS ADAPTATIVOS\n# ====================================================================\n!writefile marketing_agent/agent.py\n\nimport os\nimport sys\nimport logging\nimport tempfile\nimport atexit\nimport math\nimport json\nimport warnings\nimport uuid\nimport hashlib\nimport time\nimport asyncio\nfrom io import StringIO\nfrom functools import wraps\nfrom typing import Dict, Any, List, Optional, Tuple, Callable\nfrom dataclasses import dataclass, field, asdict\nfrom datetime import datetime, timedelta\nfrom enum import Enum\nfrom duckduckgo_search import DDGS\n\ntry:\n    __import__('pysqlite3')\n    sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')\n    print(\"âœ… SQLite atualizado com sucesso (Hack aplicado)!\")\nexcept ImportError:\n    print(\"âš ï¸ Falha ao aplicar hack do SQLite.\")\n\n# 3. Agora testamos a importaÃ§Ã£o\nimport sqlite3\nprint(f\"VersÃ£o do SQLite atual: {sqlite3.sqlite_version}\")\n\nprint(\"ğŸ”„ Carregando dependÃªncias...\")\n\n# ============ BÃSICOS ============\nimport os, sys, logging, json, warnings, time\nfrom typing import Dict, Any, List, Optional\nfrom dataclasses import dataclass\nfrom datetime import datetime\n\n# ============ DADOS ============\nimport numpy as np\nimport pandas as pd\n\n# SciPy (opcional)\ntry:\n    from scipy import stats\n    SCIPY_OK = True\nexcept:\n    SCIPY_OK = False\n    \nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\nfrom PIL import Image\n\n# ============ BUSCA WEB ============\ntry:\n    from duckduckgo_search import DDGS\n    DDGS_OK = True\n    print(\"âœ… DuckDuckGo Search\")\nexcept ImportError as e:\n    DDGS_OK = False\n    print(f\"âŒ DuckDuckGo: {e}\")\n    class DDGS:\n        def text(self, *args, **kwargs): return []\n\n# ============ GOOGLE ADK ============\ntry:\n    from google.adk.agents import Agent, SequentialAgent, ParallelAgent, LoopAgent\n    from google.adk.runners import InMemoryRunner\n    from google.adk.tools import AgentTool, FunctionTool\n    ADK_OK = True\n    print(\"âœ… Google ADK\")\nexcept ImportError:\n    ADK_OK = False\n    print(\"âŒ Google ADK\")\n    class Agent: pass\n    class SequentialAgent: pass\n    class ParallelAgent: pass\n    class LoopAgent: pass\n    class InMemoryRunner: pass\n    class AgentTool: pass\n    class FunctionTool:\n        def __init__(self, func): self.func = func\n\n# ============ KAGGLE ============\ntry:\n    from kaggle_secrets import UserSecretsClient\n    SECRETS_OK = True\n    print(\"âœ… Kaggle Secrets\")\nexcept ImportError:\n    SECRETS_OK = False\n    print(\"âš ï¸ Kaggle Secrets nÃ£o disponÃ­vel\")\n    class UserSecretsClient:\n        @staticmethod\n        def get_secret(key): return os.getenv(key)\n\n# ============ LANGCHAIN ============\ntry:\n    from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI\n    from langchain_core.documents import Document\n    LANGCHAIN_OK = True\n    print(\"âœ… LangChain Google GenAI\")\nexcept ImportError as e:\n    LANGCHAIN_OK = False\n    print(f\"âŒ LangChain: {e}\")\n    class GoogleGenerativeAIEmbeddings:\n        def __init__(self, **kwargs): pass\n    class Document:\n        def __init__(self, page_content, metadata=None):\n            self.page_content = page_content\n            self.metadata = metadata or {}\n\n# Text splitter\ntry:\n    from langchain_text_splitters import RecursiveCharacterTextSplitter\nexcept:\n    try:\n        from langchain.text_splitter import RecursiveCharacterTextSplitter\n    except:\n        class RecursiveCharacterTextSplitter:\n            def __init__(self, **kwargs): pass\n            def split_text(self, text): return [text]\n\n# ChromaDB\ntry:\n    from langchain_community.vectorstores import Chroma\n    CHROMA_OK = True\n    print(\"âœ… ChromaDB\")\nexcept:\n    try:\n        from langchain.vectorstores import Chroma\n        CHROMA_OK = True\n        print(\"âœ… ChromaDB (legacy)\")\n    except:\n        CHROMA_OK = False\n        print(\"âŒ ChromaDB\")\n        class Chroma:\n            def __init__(self, **kwargs): pass\n\n# ============ OUTROS ============\nfrom pydantic import BaseModel, Field\n\ntry:\n    import gradio as gr\n    GRADIO_OK = True\n    print(\"âœ… Gradio\")\nexcept:\n    GRADIO_OK = False\n    gr = None\n\n# ============ CONFIG ============\nlogging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\nlogger = logging.getLogger(__name__)\nwarnings.filterwarnings('ignore')\n\nbq_toolset = None\nBIGQUERY_ENABLED = False\n\n# ============ BUSCA WEB ============\ndef search_web(query: str) -> str:\n    \"\"\"Busca web com DuckDuckGo\"\"\"\n    if not DDGS_OK:\n        return \"Busca nÃ£o disponÃ­vel\"\n    try:\n        results = DDGS().text(query, max_results=3)\n        if not results:\n            return \"Sem resultados\"\n        return \"\\n\\n\".join([\n            f\"**{r['title']}**\\n{r['href']}\\n{r['body']}\"\n            for r in results\n        ])\n    except Exception as e:\n        return f\"Erro: {e}\"\n\ngoogle_search_tool = FunctionTool(search_web) if ADK_OK else search_web\n\n# --- CAMADA DE ROBUSTEZ (ANTI-ERRO 429) ---\nclass RobustGemini(Gemini):\n    \"\"\"Wrapper do Gemini com Retry automÃ¡tico e Backoff Exponencial.\"\"\"\n    \n    @retry(\n        retry=retry_if_exception_type(Exception),\n        stop=stop_after_attempt(10),\n        wait=wait_exponential(multiplier=2, min=4, max=60),\n        reraise=True\n    )\n    def generate_content(self, *args, **kwargs):\n        return super().generate_content(*args, **kwargs)\n\n    @retry(\n        retry=retry_if_exception_type(Exception),\n        stop=stop_after_attempt(10),\n        wait=wait_exponential(multiplier=2, min=4, max=60),\n        reraise=True\n    )\n    async def generate_content_async(self, *args, **kwargs):\n        return await super().generate_content_async(*args, **kwargs)\n\n# ConfiguraÃ§Ã£o Global do Modelo\nretry_config = types.HttpRetryOptions(\n    attempts=10,\n    exp_base=2,\n    initial_delay=2,\n    http_status_codes=[429, 500, 503],\n)\n\n# Recupera API Key\ntry:\n    api_key = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n    os.environ[\"GOOGLE_API_KEY\"] = api_key\nexcept Exception:\n    print(\"âš ï¸ GOOGLE_API_KEY nÃ£o encontrada nos Secrets\")\n\n# InstÃ¢ncia Global do Modelo (Usada por todos os agentes)\nmodel = RobustGemini(model=\"gemini-2.0-flash\", retry_options=retry_config)\n\nprint(\"âœ… Base do arquivo agent.py criada com RobustGemini!\")\n\n# ============ STATUS ============\nprint(\"\\n\" + \"=\"*60)\nprint(\"ğŸ“Š STATUS DO AMBIENTE\")\nprint(\"=\"*60)\nprint(f\"Python: {sys.version.split()[0]}\")\nprint(f\"NumPy: {np.__version__} | Pandas: {pd.__version__}\")\nprint(f\"SciPy: {'âœ…' if SCIPY_OK else 'âš ï¸'}\")\nprint(f\"Google ADK: {'âœ…' if ADK_OK else 'âŒ'}\")\nprint(f\"LangChain: {'âœ…' if LANGCHAIN_OK else 'âŒ'}\")\nprint(f\"ChromaDB: {'âœ…' if CHROMA_OK else 'âŒ'}\")\nprint(f\"DuckDuckGo: {'âœ…' if DDGS_OK else 'âŒ'}\")\nprint(f\"Gradio: {'âœ…' if GRADIO_OK else 'âŒ'}\")\n\nessentials = LANGCHAIN_OK and (DDGS_OK or not ADK_OK)\nprint(f\"\\n{'âœ… PRONTO' if essentials else 'âš ï¸ VERIFICAR DEPENDÃŠNCIAS'}\")\nprint(\"=\"*60 + \"\\n\")","metadata":{"execution":{"iopub.status.busy":"2025-11-26T23:34:30.454815Z","iopub.execute_input":"2025-11-26T23:34:30.455148Z","iopub.status.idle":"2025-11-26T23:36:07.891589Z","shell.execute_reply.started":"2025-11-26T23:34:30.455122Z","shell.execute_reply":"2025-11-26T23:36:07.889904Z"},"trusted":true},"outputs":[{"name":"stdout","text":"/bin/bash: line 1: writefile: command not found\nâœ… SQLite atualizado com sucesso (Hack aplicado)!\nVersÃ£o do SQLite atual: 3.46.1\nğŸ”„ Carregando dependÃªncias...\nâœ… DuckDuckGo Search\nâœ… Google ADK\nâœ… Kaggle Secrets\nâœ… LangChain Google GenAI\n","output_type":"stream"},{"name":"stderr","text":"2025-11-26 23:35:41.773286: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1764200142.015487      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1764200142.093114      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"âœ… ChromaDB\nâœ… Gradio\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_47/964662373.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;31m# --- CAMADA DE ROBUSTEZ (ANTI-ERRO 429) ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mRobustGemini\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGemini\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m     \u001b[0;34m\"\"\"Wrapper do Gemini com Retry automÃ¡tico e Backoff Exponencial.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'Gemini' is not defined"],"ename":"NameError","evalue":"name 'Gemini' is not defined","output_type":"error"}],"execution_count":9},{"id":"2bc14eae-3b22-481a-90e5-e062a8dcee41","cell_type":"code","source":"# Recarrega o que acabamos de escrever para a memÃ³ria do notebook\n!run -i marketing_agent/agent.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T23:36:07.894265Z","iopub.status.idle":"2025-11-26T23:36:07.894726Z","shell.execute_reply.started":"2025-11-26T23:36:07.894532Z","shell.execute_reply":"2025-11-26T23:36:07.894575Z"}},"outputs":[],"execution_count":null},{"id":"16fcb984","cell_type":"markdown","source":"## ğŸ” Fase 3: SeguranÃ§a e ConfianÃ§a\nPequenas empresas morrem se tiverem vazamento de dados. Implementamos um **Gerenciador de Credenciais Seguro** que limpa chaves de API da memÃ³ria apÃ³s o uso. O sistema suporta integraÃ§Ã£o opcional com **BigQuery**, permitindo que empresas que jÃ¡ cresceram um pouco conectem seus dados reais de forma robusta.","metadata":{}},{"id":"8c042162","cell_type":"code","source":"# ====================================================================\n# CELL 9: CONFIGURAÃ‡ÃƒO SEGURA DE CREDENCIAIS\n# ====================================================================\n\nclass SecureCredentialsManager:\n    \"\"\"Gerenciador seguro de credenciais com limpeza automÃ¡tica.\"\"\"\n\n    def __init__(self):\n        self.temp_files = []\n        atexit.register(self.cleanup)\n\n    def setup_gemini_key(self) -> bool:\n        \"\"\"Configura a API Key do Gemini de forma segura.\"\"\"\n        try:\n            api_key = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n            if not api_key or len(api_key) < 20:\n                raise ValueError(\"Invalid API key\")\n            os.environ[\"GOOGLE_API_KEY\"] = api_key\n            os.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = \"FALSE\"\n            logger.info(\"âœ… Gemini API configured\")\n            return True\n        except Exception as e:\n            logger.error(f\"âŒ API key failed: {e}\")\n            print(\"\\n[ACTION] Add GOOGLE_API_KEY in Kaggle Secrets\")\n            return False\n\n    def setup_bigquery_credentials(self) -> tuple:\n        \"\"\"Configura credenciais do BigQuery de forma segura.\"\"\"\n        try:\n            creds = UserSecretsClient().get_secret(\"BIGQUERY_SERVICE_ACCOUNT_JSON\")\n            fd, path = tempfile.mkstemp(suffix='.json', prefix='bq_')\n            os.write(fd, creds.encode())\n            os.close(fd)\n            os.chmod(path, 0o600)\n            os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = path\n            self.temp_files.append(path)\n            logger.info(\"âœ… BigQuery configured\")\n            return True, path\n        except Exception as e:\n            logger.warning(f\"âš ï¸ BigQuery not configured: {e}\")\n            return False, \"\"\n\n    def cleanup(self):\n        \"\"\"Remove arquivos temporÃ¡rios de credenciais.\"\"\"\n        for path in self.temp_files:\n            try:\n                if os.path.exists(path):\n                    os.unlink(path)\n            except:\n                pass\n\n# Inicializar gerenciador de credenciais\ncreds_manager = SecureCredentialsManager()\nGEMINI_READY = creds_manager.setup_gemini_key()\nBIGQUERY_ENABLED, BQ_PATH = creds_manager.setup_bigquery_credentials()\n\nif not GEMINI_READY:\n    raise RuntimeError(\"Cannot proceed without API key\")\n\nprint(f\"\\n{'='*60}\")\nprint(\"ğŸ” Security Status:\")\nprint(f\"  âœ… Gemini: Configured\")\nprint(f\"  {'âœ…' if BIGQUERY_ENABLED else 'âš ï¸'} BigQuery: {'Enabled' if BIGQUERY_ENABLED else 'Optional'}\")\nprint(f\"{'='*60}\\n\")\n\n","metadata":{"execution":{"iopub.status.busy":"2025-11-26T23:36:07.896733Z","iopub.status.idle":"2025-11-26T23:36:07.897152Z","shell.execute_reply.started":"2025-11-26T23:36:07.896942Z","shell.execute_reply":"2025-11-26T23:36:07.896963Z"},"trusted":true},"outputs":[],"execution_count":null},{"id":"2b63379c","cell_type":"code","source":"\n# ====================================================================\n# CELL 10 : IMPORTS E CONFIGURAÃ‡Ã•ES\n# ====================================================================\n\n\nif BIGQUERY_ENABLED:\n    try:\n        from google.adk.tools.bigquery import BigQueryToolset, BigQueryCredentialsConfig, BigQueryToolConfig, WriteMode\n        from google.oauth2 import service_account\n        credentials = service_account.Credentials.from_service_account_file(BQ_PATH)\n        creds_config = BigQueryCredentialsConfig(credentials=credentials)\n        tool_config = BigQueryToolConfig(write_mode=WriteMode.BLOCKED)\n        bq_toolset = BigQueryToolset(credentials_config=creds_config, bigquery_tool_config=tool_config)\n        if BQ_PATH and os.path.exists(BQ_PATH):\n            credentials = service_account.Credentials.from_service_account_file(BQ_PATH)\n            creds_config = BigQueryCredentialsConfig(credentials=credentials)\n            bq_toolset = BigQueryToolset(credentials_config=creds_config)\n            BIGQUERY_ENABLED = True\n            logger.info(\"âœ… BigQuery enabled\")\n        logger.info(\"âœ… BigQuery initialized\")\n    except Exception as e:\n        logger.error(f\"BigQuery init failed: {e}\")\n        BIGQUERY_ENABLED = False\n\ndef search_web(query: str) -> str:\n    \"\"\"\n    Realiza uma pesquisa na web para encontrar informaÃ§Ãµes atualizadas.\n    Use para buscar dados de mercado, benchmarks ou conceitos recentes.\n    \"\"\"\n    try:\n        results = DDGS().text(query, max_results=3)\n        if not results:\n            return \"Nenhum resultado encontrado.\"\n        return \"\\n\\n\".join([f\"Title: {r['title']}\\nLink: {r['href']}\\nSnippet: {r['body']}\" for r in results])\n    except Exception as e:\n        return f\"Erro na busca: {str(e)}\"\n\n\ngoogle_search = FunctionTool(search_web)\n\nlogger.info(\"âœ… Imports complete\")\nprint(\"[OK] Environment ready! ğŸš€\\n\")\n\n","metadata":{"execution":{"iopub.status.busy":"2025-11-26T23:32:08.231799Z","iopub.status.idle":"2025-11-26T23:32:08.232365Z","shell.execute_reply.started":"2025-11-26T23:32:08.232136Z","shell.execute_reply":"2025-11-26T23:32:08.232157Z"},"trusted":true},"outputs":[],"execution_count":null},{"id":"e1669f3c","cell_type":"markdown","source":"## ğŸ›¡ï¸ Fase 4: O Auditor Rigoroso (Guardrails)\nLLMs podem \"alucinar\" nÃºmeros. Em finanÃ§as e marketing, um zero a mais quebra a empresa.\nCriamos um **Framework de ValidaÃ§Ã£o (InputValidator)**. Se um agente tentar calcular uma taxa de conversÃ£o maior que 100% ou um ROAS negativo, o sistema bloqueia antes de apresentar ao usuÃ¡rio. Isso garante confiabilidade profissional.","metadata":{}},{"id":"d5dbe5e0","cell_type":"code","source":"# ====================================================================\n# CELL 11: FRAMEWORK DE VALIDAÃ‡ÃƒO\n# ====================================================================\n!writefile -a marketing_agent/agent.py\n\nclass ValidationError(Exception):\n    \"\"\"ExceÃ§Ã£o customizada para erros de validaÃ§Ã£o de entrada.\"\"\"\n    pass\n\nclass InputValidator:\n    \"\"\"Validador robusto de inputs para anÃ¡lises estatÃ­sticas.\"\"\"\n\n    @staticmethod\n    def validate_probability(value: float, name: str):\n        \"\"\"Valida se um valor Ã© uma probabilidade vÃ¡lida (0, 1).\"\"\"\n        if not isinstance(value, (int, float)):\n            raise ValidationError(f\"{name} must be numeric\")\n        if not 0 < value < 1:\n            raise ValidationError(f\"{name} must be in (0,1), got {value}\")\n\n    @staticmethod\n    def validate_positive(value: float, name: str):\n        \"\"\"Valida se um valor Ã© positivo.\"\"\"\n        if not isinstance(value, (int, float)):\n            raise ValidationError(f\"{name} must be numeric\")\n        if value <= 0:\n            raise ValidationError(f\"{name} must be positive\")\n\n    @staticmethod\n    def validate_ab_test_inputs(ctrl_conv, ctrl_total, treat_conv, treat_total):\n        \"\"\"Valida inputs de teste A/B.\"\"\"\n        for val, name in [(ctrl_conv, \"control_conversions\"), (ctrl_total, \"control_total\"),\n                          (treat_conv, \"treatment_conversions\"), (treat_total, \"treatment_total\")]:\n            if not isinstance(val, int) or val < 0:\n                raise ValidationError(f\"{name} must be non-negative integer\")\n        if ctrl_total == 0 or treat_total == 0:\n            raise ValidationError(\"Total cannot be zero\")\n        if ctrl_conv > ctrl_total:\n            raise ValidationError(f\"Control conversions > total\")\n        if treat_conv > treat_total:\n            raise ValidationError(f\"Treatment conversions > total\")\n\n    @staticmethod\n    def validate_dataframe(df: pd.DataFrame, required_cols: List[str] = None):\n        \"\"\"Valida um DataFrame.\"\"\"\n        if df.empty:\n            raise ValidationError(\"DataFrame is empty\")\n        if required_cols:\n            missing = set(required_cols) - set(df.columns)\n            if missing:\n                raise ValidationError(f\"Missing required columns: {missing}\")\n\nlogger.info(\"âœ… Validation framework ready\")\nprint(\"[OK] Input validation loaded!\\n\")\n\n","metadata":{"execution":{"iopub.status.busy":"2025-11-26T23:32:08.236031Z","iopub.status.idle":"2025-11-26T23:32:08.236714Z","shell.execute_reply.started":"2025-11-26T23:32:08.236534Z","shell.execute_reply":"2025-11-26T23:32:08.236557Z"},"trusted":true},"outputs":[],"execution_count":null},{"id":"0ea0d414-10d6-4e91-bbc7-0d67254b35d1","cell_type":"code","source":"!run -i marketing_agent/agent.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T23:32:08.237656Z","iopub.status.idle":"2025-11-26T23:32:08.238064Z","shell.execute_reply.started":"2025-11-26T23:32:08.237845Z","shell.execute_reply":"2025-11-26T23:32:08.237862Z"}},"outputs":[],"execution_count":null},{"id":"6a4c119f","cell_type":"markdown","source":"## ğŸ§  Fase 5: O CÃ©rebro HÃ­brido (RAG + Dados)\nUm Partner SÃªnior nÃ£o olha apenas planilhas; ele tem experiÃªncia.\nImplementamos um **HybridRAG**:\n1.  **MemÃ³ria de Dados:** Indexa os CSVs da campanha do cliente.\n2.  **MemÃ³ria EstratÃ©gica:** Carrega \"Playbooks\" validados (ex: \"O que fazer na Black Friday?\", \"Como corrigir CPA alto?\").\nIsso permite que o agente combine *dados do cliente* com *sabedoria de mercado*.","metadata":{}},{"id":"rag_system_005c","cell_type":"code","source":"# ====================================================================\n# CELL 12: RAG SYSTEM HÃBRIDO (DADOS + ESTRATÃ‰GIA)\n# ====================================================================\n!writefile -a marketing_agent/agent.py\n\nclass HybridRAG:\n    \"\"\"RAG system que combina anÃ¡lise de dados com playbooks estratÃ©gicos.\"\"\"\n    \n    def __init__(self, embedding_model: str = \"models/embedding-001\"):\n        self.embeddings = GoogleGenerativeAIEmbeddings(model=embedding_model)\n        self.data_store = None\n        self.persist_dir = tempfile.mkdtemp(prefix=\"chroma_\")\n        self.strategy_store = None\n        \n        self.text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n        \n        # Inicializar Playbooks PadrÃ£o (Sabedoria do Partner)\n        self._init_strategy_store()\n    \n    def _init_strategy_store(self):\n        \"\"\"Carrega estratÃ©gias de marketing validadas.\"\"\"\n        playbooks = [\n            \"Se o CPA subir repentinamente (>20%), verifique primeiro se o CPM subiu (leilÃ£o) ou se a CVR caiu (criativo/site). Se foi CPM, reduza orÃ§amento de Topo de Funil. Se foi CVR, revise tracking e criativos.\",\n            \"Para escalar campanhas PMax, nÃ£o aumente o budget mais de 20% a cada 3 dias para nÃ£o resetar o aprendizado da mÃ¡quina.\",\n            \"Em perÃ­odos de Black Friday, o foco deve mudar de AquisiÃ§Ã£o para Remarketing, pois o CPM de aquisiÃ§Ã£o fica proibitivo.\",\n            \"Se a retenÃ§Ã£o de coorte (Cohort Retention) cai no mÃªs 1, o problema geralmente Ã© Onboarding ou Expectativa vs Realidade do produto.\",\n            \"Clientes do cluster 'Whales' (Alto Valor, Alta FrequÃªncia) devem receber tratamento VIP e ofertas exclusivas de prÃ©-lanÃ§amento.\"\n        ]\n        docs = [Document(page_content=p, metadata={\"type\": \"playbook\"}) for p in playbooks]\n        try:\n            self.strategy_store = Chroma.from_documents(docs, self.embeddings, collection_name=\"marketing_strategy\")\n            logger.info(\"âœ… Strategic Playbooks indexed\")\n        except Exception as e:\n            logger.warning(f\"âš ï¸ Strategy RAG init failed: {e}\")\n\n    def chunk_campaign_data(self, df: pd.DataFrame) -> List[Document]:\n        \"\"\"Cria chunks semÃ¢nticos dos dados de campanha.\"\"\"\n        documents = []\n        if 'campaign_name' in df.columns:\n            for campaign, group in df.groupby('campaign_name'):\n                stats = [\n                    f\"Campaign: {campaign}\",\n                    f\"Period: {group['date'].min()} to {group['date'].max()}\",\n                    f\"Metrics: Cost={group['cost'].sum():.2f}, Conv={group['conversions'].sum()}\"\n                ]\n                documents.append(Document(page_content=\"\\n\".join(stats), metadata={'campaign': campaign}))\n        return documents\n    \n    def index_data(self, df: pd.DataFrame) -> bool:\n        \"\"\"Indexa os dados no vector store.\"\"\"\n        try:\n            documents = self.chunk_campaign_data(df)\n            self.data_store = Chroma.from_documents(documents, self.embeddings, collection_name=\"campaign_data_new\")\n            logger.info(f\"âœ… Indexed {len(documents)} data chunks\")\n            return True\n        except Exception as e:\n            logger.error(f\"âŒ RAG indexing failed: {e}\")\n            return False\n    \n    def retrieve_strategy(self, query: str, k: int = 2) -> str:\n        \"\"\"Busca conselhos estratÃ©gicos aplicÃ¡veis.\"\"\"\n        if not self.strategy_store: return \"\"\n        docs = self.strategy_store.similarity_search(query, k=k)\n        return \"\\n\".join([f\"PLAYBOOK TIP: {d.page_content}\" for d in docs])\n\nrag_system = HybridRAG()\nprint(\"[OK] HybridRAG initialized (Data + Strategy)! \\n\")","metadata":{"execution":{"iopub.status.busy":"2025-11-26T23:32:08.240013Z","iopub.status.idle":"2025-11-26T23:32:08.240520Z","shell.execute_reply.started":"2025-11-26T23:32:08.240222Z","shell.execute_reply":"2025-11-26T23:32:08.240241Z"},"trusted":true},"outputs":[],"execution_count":null},{"id":"71b9eb4a-fffd-4327-ab64-19a267334786","cell_type":"code","source":"%run -i marketing_agent/agent.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T23:32:08.243573Z","iopub.status.idle":"2025-11-26T23:32:08.244409Z","shell.execute_reply.started":"2025-11-26T23:32:08.243925Z","shell.execute_reply":"2025-11-26T23:32:08.243952Z"}},"outputs":[],"execution_count":null},{"id":"567c5ae2","cell_type":"markdown","source":"## ğŸ’¾ Fase 6: GestÃ£o de Clientes (Session Manager)\nPara atender mÃºltiplas microempresas (ou sessÃµes de aprendizado de jÃºnior), precisamos de isolamento. O **Session Manager** garante que os dados da \"Padaria do JoÃ£o\" nÃ£o se misturem com a \"Loja de Roupas da Maria\", mantendo o estado da anÃ¡lise e o histÃ³rico de conversas organizados.","metadata":{}},{"id":"session_manager_005d","cell_type":"code","source":"# ====================================================================\n# CELL 13: SESSION MANAGER E GESTÃƒO DE ESTADO\n# ====================================================================\n%%writefile -a marketing_agent/agent.py\n\n@dataclass\nclass AnalysisSession:\n    \"\"\"SessÃ£o de anÃ¡lise com estado persistente.\"\"\"\n    session_id: str = field(default_factory=lambda: str(uuid.uuid4()))\n    created_at: datetime = field(default_factory=datetime.now)\n    csv_data: Optional[pd.DataFrame] = None\n    rag_indexed: bool = False\n    analysis_history: List[Dict] = field(default_factory=list)\n    metadata: Dict = field(default_factory=dict)\n    \n    def add_analysis(self, analysis_type: str, result: Dict):\n        \"\"\"Adiciona uma anÃ¡lise ao histÃ³rico.\"\"\"\n        self.analysis_history.append({\n            'timestamp': datetime.now().isoformat(),\n            'type': analysis_type,\n            'result': result\n        })\n    \n    def get_context(self) -> str:\n        \"\"\"Retorna contexto da sessÃ£o para o LLM.\"\"\"\n        context = []\n        context.append(f\"Session ID: {self.session_id}\")\n        context.append(f\"Created: {self.created_at.strftime('%Y-%m-%d %H:%M:%S')}\")\n        \n        if self.csv_data is not None:\n            context.append(f\"CSV Data: {len(self.csv_data)} rows, {len(self.csv_data.columns)} columns\")\n            context.append(f\"Columns: {', '.join(self.csv_data.columns.tolist())}\")\n        \n        context.append(f\"RAG Indexed: {self.rag_indexed}\")\n        context.append(f\"Analysis History: {len(self.analysis_history)} analyses\")\n        \n        return \"\\n\".join(context)\n\nclass SessionManager:\n    \"\"\"Gerenciador de sessÃµes de anÃ¡lise.\"\"\"\n    \n    def __init__(self):\n        self.sessions: Dict[str, AnalysisSession] = {}\n        self.current_session_id: Optional[str] = None\n    \n    def create_session(self) -> AnalysisSession:\n        \"\"\"Cria uma nova sessÃ£o.\"\"\"\n        session = AnalysisSession()\n        self.sessions[session.session_id] = session\n        self.current_session_id = session.session_id\n        logger.info(f\"âœ… Created session: {session.session_id}\")\n        return session\n    \n    def get_session(self, session_id: Optional[str] = None) -> Optional[AnalysisSession]:\n        \"\"\"Retorna uma sessÃ£o especÃ­fica ou a atual.\"\"\"\n        sid = session_id or self.current_session_id\n        return self.sessions.get(sid)\n    \n    def switch_session(self, session_id: str) -> bool:\n        \"\"\"Troca para outra sessÃ£o.\"\"\"\n        if session_id in self.sessions:\n            self.current_session_id = session_id\n            logger.info(f\"âœ… Switched to session: {session_id}\")\n            return True\n        logger.warning(f\"âš ï¸ Session not found: {session_id}\")\n        return False\n    \n    def list_sessions(self) -> List[Dict]:\n        \"\"\"Lista todas as sessÃµes.\"\"\"\n        return [\n            {\n                'session_id': sid,\n                'created_at': session.created_at.isoformat(),\n                'has_data': session.csv_data is not None,\n                'analyses': len(session.analysis_history)\n            }\n            for sid, session in self.sessions.items()\n        ]\n\n# Inicializar gerenciador global\nsession_manager = SessionManager()\ncurrent_session = session_manager.create_session()\n\nlogger.info(\"âœ… Session Manager ready\")\nprint(f\"[OK] Session created: {current_session.session_id}\\n\")\n","metadata":{"execution":{"iopub.status.busy":"2025-11-26T23:32:08.245628Z","iopub.status.idle":"2025-11-26T23:32:08.245962Z","shell.execute_reply.started":"2025-11-26T23:32:08.245819Z","shell.execute_reply":"2025-11-26T23:32:08.245832Z"},"trusted":true},"outputs":[],"execution_count":null},{"id":"283fdc8a-cb02-4b70-b306-4293ba69f556","cell_type":"code","source":"%run -i marketing_agent/agent.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T23:32:08.247381Z","iopub.status.idle":"2025-11-26T23:32:08.247698Z","shell.execute_reply.started":"2025-11-26T23:32:08.247548Z","shell.execute_reply":"2025-11-26T23:32:08.247562Z"}},"outputs":[],"execution_count":null},{"id":"3a00fc78","cell_type":"code","source":"# CÃ©lula 14\n# Session management utilities: Export / Reset / Search\n%%writefile -a marketing_agent/agent.py\n\ndef export_session(session_id: Optional[str] = None, filename: str = \"session_export.json\") -> str:\n    \"\"\"Export the session state to a JSON file.\n    Exports: metadata, rag_indexed, analysis_history, current context and optional runner metrics.\n    Returns the filename written (or an error string prefixed by \"ERROR:\").\n    \"\"\"\n    try:\n        session = session_manager.get_session(session_id)\n        if session is None:\n            return \"ERROR: Session not found\"\n\n        export_data = {\n            \"session_id\": session.session_id,\n            \"created_at\": session.created_at.isoformat(),\n            \"rag_indexed\": session.rag_indexed,\n            \"metadata\": session.metadata,\n            \"analysis_history\": session.analysis_history,\n            \"context_summary\": session.get_context(),\n            \"rows\": len(session.csv_data) if session.csv_data is not None else None,\n            \"columns\": list(session.csv_data.columns) if session.csv_data is not None else None\n        }\n\n        try:\n            # Try to include runner stats if available\n            if 'runner' in globals() and runner is not None:\n                export_data[\"runner_stats\"] = runner.get_stats()\n        except Exception:\n            # non-fatal\n            export_data[\"runner_stats\"] = {\"error\": \"failed to fetch runner stats\"}\n\n        with open(filename, 'w', encoding='utf-8') as f:\n            json.dump(export_data, f, indent=2, default=str)\n\n        logger.info(\"Session exported\", filename=filename, session_id=session.session_id)\n        return filename\n\n    except Exception as e:\n        logger.error(\"Failed to export session\", error=str(e))\n        return f\"ERROR: {str(e)}\"\n\n\ndef reset_session(session_id: Optional[str] = None, create_new: bool = True) -> str:\n    \"\"\"Reset a session: remove its state; optionally create a new session and return its id.\n\n    This is safe for production: cleans `session_manager` mapping, but does not delete historical JSON exports.\n    \"\"\"\n    try:\n        sid = session_id or session_manager.current_session_id\n        if sid not in session_manager.sessions:\n            return \"ERROR: Session not found\"\n\n        # Backup: in-memory copy for debugging if needed\n        old = session_manager.sessions.pop(sid)\n        logger.info(\"Session popped\", session_id=sid)\n\n        # Make sure the current session id is reset\n        if session_manager.current_session_id == sid:\n            session_manager.current_session_id = None\n\n        if create_new:\n            new_session = session_manager.create_session()\n            logger.info(\"New session created\", session_id=new_session.session_id)\n            return new_session.session_id\n\n        return sid\n\n    except Exception as e:\n        logger.error(\"Failed to reset session\", error=str(e))\n        return f\"ERROR: {str(e)}\"\n\n\ndef search_analysis_history(keyword: str, session_id: Optional[str] = None) -> list:\n    \"\"\"Search the analysis history for a specific keyword (case-insensitive) and return matches.\"\"\"\n    try:\n        sid = session_id or session_manager.current_session_id\n        if sid not in session_manager.sessions:\n            return []\n\n        session = session_manager.sessions[sid]\n        results = []\n        lower = keyword.lower()\n        for i, entry in enumerate(session.analysis_history):\n            type_str = entry.get('type', '')\n            result_str = json.dumps(entry.get('result', {}))\n            if lower in type_str.lower() or lower in result_str.lower():\n                results.append({\n                    'index': i,\n                    'type': entry.get('type'),\n                    'timestamp': entry.get('timestamp'),\n                    'preview': result_str[:500]\n                })\n\n        logger.info(\"Search finished\", query=keyword, matches=len(results))\n        return results\n\n    except Exception as e:\n        logger.error(\"Error searching analysis history\", error=str(e))\n        return []\n\n\n","metadata":{"execution":{"iopub.status.busy":"2025-11-26T23:32:08.249129Z","iopub.status.idle":"2025-11-26T23:32:08.249742Z","shell.execute_reply.started":"2025-11-26T23:32:08.249487Z","shell.execute_reply":"2025-11-26T23:32:08.249519Z"},"trusted":true},"outputs":[],"execution_count":null},{"id":"8af2f4da-412d-43d8-8f96-e87b56453725","cell_type":"code","source":"%run -i marketing_agent/agent.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T23:32:08.251382Z","iopub.status.idle":"2025-11-26T23:32:08.251978Z","shell.execute_reply.started":"2025-11-26T23:32:08.251789Z","shell.execute_reply":"2025-11-26T23:32:08.251809Z"}},"outputs":[],"execution_count":null},{"id":"ddc90f5f","cell_type":"markdown","source":"## âš¡ Fase 7: Alta Disponibilidade (ResiliÃªncia)\nSistemas em produÃ§Ã£o falham. Implementamos padrÃµes de engenharia de software avanÃ§ados:\n*   **Cache:** Para nÃ£o gastar tokens (dinheiro) respondendo a mesma pergunta duas vezes.\n*   **Circuit Breaker:** Se uma ferramenta externa falhar repetidamente, o sistema \"abre o circuito\" para evitar falhas em cascata, protegendo a experiÃªncia do usuÃ¡rio.","metadata":{}},{"id":"resilience_patterns_005e","cell_type":"code","source":"# ====================================================================\n# CELL 15: CACHE E CIRCUIT BREAKER\n# ====================================================================\n%%writefile -a marketing_agent/agent.py\n\nclass QueryCache:\n    \"\"\"Cache simples para queries e anÃ¡lises.\"\"\"\n    \n    def __init__(self, ttl: int = 3600):\n        self.cache: Dict[str, tuple] = {}  # key -> (value, timestamp)\n        self.ttl = ttl\n        self.hits = 0\n        self.misses = 0\n    \n    def _hash_key(self, key: str) -> str:\n        \"\"\"Gera hash da chave.\"\"\"\n        return hashlib.sha256(key.encode()).hexdigest()[:16]\n    \n    def get(self, key: str) -> Optional[Any]:\n        \"\"\"Recupera valor do cache.\"\"\"\n        hashed = self._hash_key(key)\n        if hashed in self.cache:\n            value, timestamp = self.cache[hashed]\n            if time.time() - timestamp < self.ttl:\n                self.hits += 1\n                logger.debug(f\"âœ… Cache HIT: {key[:50]}...\")\n                return value\n            else:\n                del self.cache[hashed]\n        self.misses += 1\n        return None\n    \n    def set(self, key: str, value: Any):\n        \"\"\"Armazena valor no cache.\"\"\"\n        hashed = self._hash_key(key)\n        self.cache[hashed] = (value, time.time())\n        logger.debug(f\"ğŸ’¾ Cached: {key[:50]}...\")\n    \n    def clear(self):\n        \"\"\"Limpa o cache.\"\"\"\n        self.cache.clear()\n        self.hits = 0\n        self.misses = 0\n        logger.info(\"ğŸ—‘ï¸ Cache cleared\")\n    \n    def stats(self) -> Dict:\n        \"\"\"Retorna estatÃ­sticas do cache.\"\"\"\n        total = self.hits + self.misses\n        hit_rate = (self.hits / total * 100) if total > 0 else 0\n        return {\n            'hits': self.hits,\n            'misses': self.misses,\n            'hit_rate': f\"{hit_rate:.1f}%\",\n            'size': len(self.cache)\n        }\n\nclass CircuitBreaker:\n    \"\"\"Circuit Breaker para proteger contra falhas em cascata.\"\"\"\n    \n    def __init__(self, failure_threshold: int = 5, timeout: int = 60):\n        self.failure_threshold = failure_threshold\n        self.timeout = timeout\n        self.failures = 0\n        self.last_failure_time = None\n        self.state = \"CLOSED\"  # CLOSED, OPEN, HALF_OPEN\n    \n    def call(self, func: Callable, *args, **kwargs) -> Any:\n        \"\"\"Executa funÃ§Ã£o com proteÃ§Ã£o de circuit breaker.\"\"\"\n        if self.state == \"OPEN\":\n            if time.time() - self.last_failure_time > self.timeout:\n                self.state = \"HALF_OPEN\"\n                logger.info(\"ğŸŸ¡ Circuit breaker: HALF_OPEN\")\n            else:\n                raise Exception(\"Circuit breaker is OPEN\")\n        \n        try:\n            result = func(*args, **kwargs)\n            if self.state == \"HALF_OPEN\":\n                self.state = \"CLOSED\"\n                self.failures = 0\n                logger.info(\"ğŸŸ¢ Circuit breaker: CLOSED\")\n            return result\n        except Exception as e:\n            self.failures += 1\n            self.last_failure_time = time.time()\n            if self.failures >= self.failure_threshold:\n                self.state = \"OPEN\"\n                logger.warning(f\"ğŸ”´ Circuit breaker OPENED after {self.failures} failures\")\n            raise e\n\n# Inicializar sistemas de resiliÃªncia\nquery_cache = QueryCache()\ncircuit_breaker = CircuitBreaker()\n\nlogger.info(\"âœ… Resilience systems ready\")\nprint(\"[OK] Cache and Circuit Breaker initialized!\\n\")\n","metadata":{"execution":{"iopub.status.busy":"2025-11-26T23:32:08.253510Z","iopub.status.idle":"2025-11-26T23:32:08.253868Z","shell.execute_reply.started":"2025-11-26T23:32:08.253694Z","shell.execute_reply":"2025-11-26T23:32:08.253711Z"},"trusted":true},"outputs":[],"execution_count":null},{"id":"80b44fb7-50d2-461e-87c7-699727709ce3","cell_type":"code","source":"%run -i marketing_agent/agent.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T23:32:08.255357Z","iopub.status.idle":"2025-11-26T23:32:08.255664Z","shell.execute_reply.started":"2025-11-26T23:32:08.255522Z","shell.execute_reply":"2025-11-26T23:32:08.255534Z"}},"outputs":[],"execution_count":null},{"id":"96085c82","cell_type":"markdown","source":"## ğŸ“‹ Fase 8: ComunicaÃ§Ã£o Executiva (Structured Output)\nO microempreendedor nÃ£o tem tempo para ler textos vagos. Ele precisa de **Planos de AÃ§Ã£o**.\nUsamos **Pydantic** para forÃ§ar os agentes a responderem em formatos estruturados:\n*   **RCAReport:** AnÃ¡lise de Causa Raiz.\n*   **InsightsReport:** Tabela priorizada com score RICE.\n*   **ExperimentPlan:** Design de teste A/B pronto para execuÃ§Ã£o.","metadata":{}},{"id":"pydantic_models_005f","cell_type":"code","source":"# ====================================================================\n# CELL 16: STRUCTURED OUTPUTS COM PYDANTIC\n# ====================================================================\n%%writefile -a marketing_agent/agent.py\n\nclass Priority(str, Enum):\n    CRITICAL = \"CRÃTICA\"\n    HIGH = \"ALTA\"\n    MEDIUM = \"MÃ‰DIA\"\n    LOW = \"BAIXA\"\n\nclass Timeline(str, Enum):\n    IMMEDIATE = \"24h\"\n    SHORT = \"72h\"\n    MEDIUM = \"1-2 semanas\"\n    LONG = \"1 mÃªs+\"\n\nclass RootCause(BaseModel):\n    why_level: int = Field(description=\"NÃ­vel do 5 Whys (1-5)\", ge=1, le=5)\n    question: str = Field(description=\"Pergunta 'Por que?'\")\n    answer: str = Field(description=\"Resposta identificada\")\n\nclass ActionItem(BaseModel):\n    priority: Priority = Field(description=\"Prioridade da aÃ§Ã£o\")\n    timeline: Timeline = Field(description=\"Timeline para execuÃ§Ã£o\")\n    action: str = Field(description=\"DescriÃ§Ã£o detalhada da aÃ§Ã£o\")\n    expected_impact: str = Field(description=\"Impacto esperado (quantitativo se possÃ­vel)\")\n    owner: str = Field(description=\"ResponsÃ¡vel sugerido\")\n    dependencies: List[str] = Field(default_factory=list, description=\"DependÃªncias\")\n\nclass RCAReport(BaseModel):\n    problem_summary: str = Field(description=\"Resumo do problema em 1-2 frases\")\n    metrics_impacted: List[str] = Field(description=\"MÃ©tricas impactadas (CVR, CPA, CTR)\")\n    five_whys: List[RootCause] = Field(description=\"AnÃ¡lise completa dos 5 Whys\")\n    root_causes: List[str] = Field(description=\"Causas raiz identificadas\")\n    immediate_actions: List[ActionItem] = Field(description=\"AÃ§Ãµes imediatas (24-72h)\")\n    structural_actions: List[ActionItem] = Field(description=\"AÃ§Ãµes estruturais (longo prazo)\")\n    confidence_level: float = Field(description=\"ConfianÃ§a na anÃ¡lise (0-1)\", ge=0, le=1)\n    data_quality_notes: str = Field(description=\"Notas sobre qualidade dos dados\")\n\nclass RICEScore(BaseModel):\n    reach: int = Field(description=\"Pessoas/sessÃµes impactadas em 30 dias\", gt=0)\n    impact: float = Field(description=\"Impacto: 0.25 (baixo), 0.5 (mÃ©dio), 1 (alto), 2 (muito alto)\", gt=0)\n    confidence: float = Field(description=\"ConfianÃ§a na estimativa (0-1)\", ge=0, le=1)\n    effort: int = Field(description=\"EsforÃ§o em homem-dia\", gt=0)\n    rice_score: float = Field(description=\"Score RICE: (R Ã— I Ã— C) / E\")\n\nclass Opportunity(BaseModel):\n    name: str = Field(description=\"Nome curto e descritivo\")\n    description: str = Field(description=\"DescriÃ§Ã£o em 2-3 frases\")\n    rice: RICEScore = Field(description=\"Score RICE detalhado\")\n    rationale: str = Field(description=\"Por que estÃ¡ ranqueada nesta posiÃ§Ã£o\")\n\nclass InsightsReport(BaseModel):\n    opportunities: List[Opportunity] = Field(description=\"Oportunidades ordenadas por RICE\")\n    action_plan_30_days: Dict[str, List[str]] = Field(\n        description=\"Plano de aÃ§Ã£o dividido por semanas\",\n        default_factory=dict\n    )\n    key_insights: List[str] = Field(description=\"3-5 insights principais\")\n    risks_and_considerations: List[str] = Field(description=\"Riscos e consideraÃ§Ãµes\")\n\nclass ExperimentPlan(BaseModel):\n    hypothesis: str = Field(description=\"HipÃ³tese clara e testÃ¡vel\")\n    metric_primary: str = Field(description=\"MÃ©trica primÃ¡ria (CVR, CPA)\")\n    metrics_secondary: List[str] = Field(description=\"MÃ©tricas secundÃ¡rias\")\n    sample_size_per_group: int = Field(description=\"Tamanho de amostra por grupo\", gt=0)\n    duration_days: int = Field(description=\"DuraÃ§Ã£o estimada em dias\", gt=0)\n    mde: float = Field(description=\"Efeito mÃ­nimo detectÃ¡vel (MDE) em p.p.\", gt=0)\n    alpha: float = Field(description=\"NÃ­vel de significÃ¢ncia\", ge=0.01, le=0.1, default=0.05)\n    power: float = Field(description=\"Poder estatÃ­stico\", ge=0.7, le=0.95, default=0.8)\n    control_description: str = Field(description=\"DescriÃ§Ã£o do grupo controle\")\n    treatment_description: str = Field(description=\"DescriÃ§Ã£o do grupo tratamento\")\n    success_criteria: List[str] = Field(description=\"CritÃ©rios de sucesso\")\n    risks: List[str] = Field(description=\"Riscos identificados\")\n    rollout_plan: str = Field(description=\"Plano de rollout se bem-sucedido\")\n\nlogger.info(\"âœ… Structured Output Models ready\")\nprint(\"[OK] Pydantic models loaded!\\n\")\n","metadata":{"execution":{"iopub.status.busy":"2025-11-26T23:32:08.256724Z","iopub.status.idle":"2025-11-26T23:32:08.257010Z","shell.execute_reply.started":"2025-11-26T23:32:08.256883Z","shell.execute_reply":"2025-11-26T23:32:08.256895Z"},"trusted":true},"outputs":[],"execution_count":null},{"id":"daff44c2-db1f-45da-aa71-52182871991e","cell_type":"code","source":"%run -i marketing_agent/agent.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T23:32:08.257792Z","iopub.status.idle":"2025-11-26T23:32:08.258122Z","shell.execute_reply.started":"2025-11-26T23:32:08.257941Z","shell.execute_reply":"2025-11-26T23:32:08.257956Z"}},"outputs":[],"execution_count":null},{"id":"cf7c0220","cell_type":"markdown","source":"## ğŸ§® Fase 9: A Caixa de Ferramentas (Math vs. Magic)\n**Este Ã© o coraÃ§Ã£o tÃ©cnico do projeto.**\nPara evitar que o LLM \"invente\" matemÃ¡tica, criamos o **AdvancedDataScienceToolkit**.\nOs agentes nÃ£o \"estimam\" significÃ¢ncia estatÃ­stica; eles chamam funÃ§Ãµes Python (`scipy.stats`) para calcular Testes T, Qui-Quadrado e Tamanhos de Amostra. TambÃ©m adicionamos:\n*   **Cohort Analysis:** Para entender retenÃ§Ã£o (vital para SaaS e E-commerce).\n*   **Forecast:** RegressÃ£o linear simples para prever tendÃªncias de curto prazo.","metadata":{}},{"id":"cec118ef","cell_type":"code","source":"# ====================================================================\n# CELL 17: ADVANCED DATA SCIENCE TOOLKIT (FUSÃƒO: STATS + ML + COHORT)\n# ====================================================================\n%%writefile -a marketing_agent/agent.py\n# --- 1. Data Transfer Objects (DTOs) ---\n\n@dataclass\nclass SampleSizeResult:\n    \"\"\"Resultado do cÃ¡lculo de tamanho de amostra.\"\"\"\n    sample_size_per_group: int\n    total_sample_size: int\n    baseline_rate: float\n    target_rate: float\n    mde_percentage: float\n    mde_absolute: float\n    alpha: float\n    power: float\n\n    def to_dict(self):\n        return {\n            \"sample_size_per_group\": self.sample_size_per_group,\n            \"total_sample_size\": self.total_sample_size,\n            \"baseline_rate\": self.baseline_rate,\n            \"target_rate\": self.target_rate,\n            \"mde_percentage\": self.mde_percentage,\n            \"mde_absolute\": self.mde_absolute,\n            \"alpha\": self.alpha,\n            \"power\": self.power,\n            \"interpretation\": f\"Para detectar um MDE de {self.mde_percentage}pp com {self.power*100}% de poder, vocÃª precisa de {self.sample_size_per_group:,} amostras por grupo.\"\n        }\n\n@dataclass\nclass SignificanceResult:\n    \"\"\"Resultado do teste de significÃ¢ncia estatÃ­stica.\"\"\"\n    control_rate: float\n    treatment_rate: float\n    uplift_relative_pct: float\n    uplift_absolute_pp: float\n    p_value: float\n    z_statistic: float\n    is_significant: bool\n    is_positive: bool\n    ci_95_lower: float\n    ci_95_upper: float\n    sample_sizes: Dict[str, int]\n\n    def to_dict(self):\n        if self.is_significant and self.is_positive:\n            recommendation = \"[âœ… SHIP IT] Impacto positivo significativo\"\n        elif self.is_significant and not self.is_positive:\n            recommendation = \"[ğŸ›‘ DO NOT SHIP] Impacto negativo significativo\"\n        else:\n            recommendation = \"[â³ KEEP TESTING] Ainda nÃ£o significativo\"\n\n        return {\n            \"control_rate\": self.control_rate,\n            \"treatment_rate\": self.treatment_rate,\n            \"uplift_relative_percentage\": self.uplift_relative_pct,\n            \"uplift_absolute_pp\": self.uplift_absolute_pp,\n            \"p_value\": self.p_value,\n            \"z_statistic\": self.z_statistic,\n            \"is_significant\": bool(self.is_significant),\n            \"is_positive\": bool(self.is_positive),\n            \"confidence_interval_95\": {\n                \"lower\": self.ci_95_lower,\n                \"upper\": self.ci_95_upper,\n                \"lower_pp\": self.ci_95_lower * 100,\n                \"upper_pp\": self.ci_95_upper * 100\n            },\n            \"interpretation\": \"SIGNIFICATIVO (p < 0.05)\" if self.is_significant else \"NÃƒO SIGNIFICATIVO\",\n            \"recommendation\": recommendation,\n            \"sample_sizes\": self.sample_sizes\n        }\n\n@dataclass\nclass EDAResult:\n    \"\"\"Resultado da anÃ¡lise exploratÃ³ria de dados.\"\"\"\n    shape: Dict[str, int]\n    columns: List[str]\n    dtypes: Dict[str, str]\n    missing_values: Dict[str, Dict[str, float]]\n    duplicate_rows: int\n    numeric_summary: Dict[str, Dict[str, float]]\n    categorical_summary: Dict[str, Dict[str, Any]]\n    outliers: Dict[str, List[float]]\n    correlations: Dict[str, float]\n\n    def to_dict(self):\n        return {\n            \"shape\": self.shape,\n            \"columns\": self.columns,\n            \"dtypes\": self.dtypes,\n            \"missing_values\": self.missing_values,\n            \"duplicate_rows\": self.duplicate_rows,\n            \"numeric_summary\": self.numeric_summary,\n            \"categorical_summary\": self.categorical_summary,\n            \"outliers\": self.outliers,\n            \"correlations\": self.correlations\n        }\n\n# --- 2. Toolkit Class Unified ---\n\nclass AdvancedDataScienceToolkit:\n    \"\"\"Toolkit unificado: EstatÃ­stica (Stats) + Preditiva (ML) + Comportamental (Cohort).\"\"\"\n\n    # --- MÃ“DULO A: ESTATÃSTICA (Sua implementaÃ§Ã£o robusta) ---\n\n    @staticmethod\n    def calculate_sample_size(baseline_rate: float, mde: float, alpha=0.05, power=0.8) -> SampleSizeResult:\n        \"\"\"Calcula tamanho de amostra necessÃ¡rio para teste A/B.\"\"\"\n        # Se InputValidator existir (cÃ©lula 4), usa. Se nÃ£o, try/except pass.\n        try:\n            InputValidator.validate_probability(baseline_rate, \"baseline_rate\")\n            InputValidator.validate_positive(mde, \"mde\")\n        except NameError: pass\n\n        p1 = baseline_rate\n        p2 = baseline_rate + (mde / 100)\n\n        if p2 >= 1.0: p2 = 0.99 # Cap para evitar erro matemÃ¡tico\n\n        z_alpha = stats.norm.ppf(1 - alpha / 2)\n        z_beta = stats.norm.ppf(power)\n\n        numerator = (z_alpha + z_beta) ** 2 * (p1 * (1 - p1) + p2 * (1 - p2))\n        denominator = (p1 - p2) ** 2\n\n        n_per_group = math.ceil(numerator / denominator) if denominator > 0 else 0\n\n        return SampleSizeResult(\n            sample_size_per_group=n_per_group,\n            total_sample_size=n_per_group * 2,\n            baseline_rate=baseline_rate,\n            target_rate=p2,\n            mde_percentage=mde,\n            mde_absolute=p2 - p1,\n            alpha=alpha,\n            power=power\n        )\n\n    @staticmethod\n    def calculate_statistical_significance(\n        ctrl_conv: int, ctrl_total: int, \n        treat_conv: int, treat_total: int, \n        alpha: float = 0.05\n    ) -> SignificanceResult:\n        \"\"\"Calcula significÃ¢ncia estatÃ­stica de teste A/B usando teste Z.\"\"\"\n        try: InputValidator.validate_ab_test_inputs(ctrl_conv, ctrl_total, treat_conv, treat_total)\n        except NameError: pass\n\n        if ctrl_total == 0 or treat_total == 0:\n            raise ValueError(\"Total samples cannot be zero\")\n\n        p1 = ctrl_conv / ctrl_total\n        p2 = treat_conv / treat_total\n\n        p_pooled = (ctrl_conv + treat_conv) / (ctrl_total + treat_total)\n        se = math.sqrt(p_pooled * (1 - p_pooled) * (1/ctrl_total + 1/treat_total))\n\n        z = (p2 - p1) / se if se > 0 else 0\n        p_value = 2 * (1 - stats.norm.cdf(abs(z)))\n\n        uplift_relative = ((p2 - p1) / p1 * 100) if p1 > 0 else 0\n        uplift_absolute = (p2 - p1) * 100\n\n        se_diff = math.sqrt(p1 * (1 - p1) / ctrl_total + p2 * (1 - p2) / treat_total)\n        ci_margin = stats.norm.ppf(1 - alpha/2) * se_diff\n        ci_lower = p2 - p1 - ci_margin\n        ci_upper = p2 - p1 + ci_margin\n\n        return SignificanceResult(\n            control_rate=p1,\n            treatment_rate=p2,\n            uplift_relative_pct=uplift_relative,\n            uplift_absolute_pp=uplift_absolute,\n            p_value=p_value,\n            z_statistic=z,\n            is_significant=p_value < alpha,\n            is_positive=p2 > p1,\n            ci_95_lower=ci_lower,\n            ci_95_upper=ci_upper,\n            sample_sizes={\"control\": ctrl_total, \"treatment\": treat_total, \"total\": ctrl_total + treat_total}\n        )\n\n    @staticmethod\n    def perform_chi_square_test(contingency_table: List[List[int]]) -> Dict[str, Any]:\n        \"\"\"Executa teste qui-quadrado.\"\"\"\n        try:\n            chi2, p_value, dof, expected = stats.chi2_contingency(contingency_table, correction=False)\n            return {\n                \"test_type\": \"chi_square\",\n                \"p_value\": float(p_value),\n                \"is_significant\": bool(p_value < 0.05),\n                \"interpretation\": \"SIGNIFICATIVO (AssociaÃ§Ã£o detectada)\" if p_value < 0.05 else \"NÃƒO SIGNIFICATIVO\"\n            }\n        except Exception as e:\n            return {\"error\": str(e)}\n\n    @staticmethod\n    def perform_t_test(group_a: List[float], group_b: List[float]) -> Dict[str, Any]:\n        \"\"\"Executa teste t independente.\"\"\"\n        try:\n            t_stat, p_value = stats.ttest_ind(group_a, group_b, equal_var=False)\n            mean_a = np.mean(group_a)\n            mean_b = np.mean(group_b)\n            return {\n                \"test_type\": \"t_test\",\n                \"p_value\": float(p_value),\n                \"is_significant\": bool(p_value < 0.05),\n                \"diff_pct\": float((mean_b - mean_a) / mean_a * 100) if mean_a != 0 else 0\n            }\n        except Exception as e:\n            return {\"error\": str(e)}\n\n    @staticmethod\n    def analyze_csv_dataframe(csv_data: str) -> EDAResult:\n        \"\"\"AnÃ¡lise exploratÃ³ria completa (EDA).\"\"\"\n        try:\n            df = pd.read_csv(StringIO(csv_data))\n        except Exception as e:\n            return {\"error\": f\"Invalid CSV: {e}\"}\n\n        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n        numeric_summary = {}\n        outliers = {}\n\n        for col in numeric_cols:\n            numeric_summary[col] = {\n                \"mean\": float(df[col].mean()),\n                \"median\": float(df[col].median()),\n                \"min\": float(df[col].min()),\n                \"max\": float(df[col].max())\n            }\n            # Simplificando outliers para performance\n            Q1 = df[col].quantile(0.25)\n            Q3 = df[col].quantile(0.75)\n            outliers[col] = df[col][(df[col] < Q1 - 1.5*(Q3-Q1)) | (df[col] > Q3 + 1.5*(Q3-Q1))].head(5).tolist()\n\n        categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n        categorical_summary = {col: {\"top\": df[col].value_counts().head(3).to_dict()} for col in categorical_cols}\n\n        missing = df.isnull().sum()\n        missing_summary = {col: float(missing[col]) for col in df.columns if missing[col] > 0}\n\n        return EDAResult(\n            shape={\"rows\": len(df), \"columns\": len(df.columns)},\n            columns=df.columns.tolist(),\n            dtypes={col: str(dtype) for col, dtype in df.dtypes.items()},\n            missing_values=missing_summary,\n            duplicate_rows=int(df.duplicated().sum()),\n            numeric_summary=numeric_summary,\n            categorical_summary=categorical_summary,\n            outliers=outliers,\n            correlations={} \n        )\n\n    # --- MÃ“DULO B: PREDITIVA E CLUSTERING (Adicionado para suportar Agentes AvanÃ§ados) ---\n\n    @staticmethod\n    def forecast_metric(dates_json: str, values_json: str, days_ahead: int = 7) -> Dict:\n        \"\"\"Realiza previsÃ£o de sÃ©rie temporal simples (RegressÃ£o Linear).\"\"\"\n        try:\n            dates = json.loads(dates_json) if isinstance(dates_json, str) else dates_json\n            values = json.loads(values_json) if isinstance(values_json, str) else values_json\n            \n            if len(values) < 3: return {\"error\": \"Dados insuficientes para forecast (min 3 pontos)\"}\n            \n            X = np.array(range(len(values))).reshape(-1, 1)\n            y = np.array(values)\n            \n            model = LinearRegression()\n            model.fit(X, y)\n            r2 = model.score(X, y)\n            \n            future_X = np.array(range(len(values), len(values) + days_ahead)).reshape(-1, 1)\n            predictions = model.predict(future_X)\n            \n            return {\n                \"trend\": \"Crescente\" if model.coef_[0] > 0 else \"Decrescente\",\n                \"next_value\": round(predictions[0], 2),\n                \"forecast_7d\": np.round(predictions, 2).tolist(),\n                \"r2_score\": round(r2, 2),\n                \"reliability\": \"Alta\" if r2 > 0.7 else \"Baixa (Cuidado)\"\n            }\n        except Exception as e:\n            return {\"error\": str(e)}\n\n    @staticmethod\n    def segment_customers(rfm_json: str) -> Dict:\n        \"\"\"Segmenta clientes usando K-Means (RFM).\"\"\"\n        try:\n            data = json.loads(rfm_json)\n            df = pd.DataFrame(data)\n            required = {'recency', 'frequency', 'monetary'}\n            if not required.issubset(df.columns): return {\"error\": f\"Missing columns: {required}\"}\n            \n            # Simple heuristic implementation instead of full sklearn to avoid dependency if not installed\n            # (Assuming sklearn IS installed per Cell 1)\n            scaler = StandardScaler()\n            scaled = scaler.fit_transform(df[['recency', 'frequency', 'monetary']])\n            kmeans = KMeans(n_clusters=3, n_init=10, random_state=42)\n            df['cluster'] = kmeans.fit_predict(scaled)\n            \n            summary = df.groupby('cluster')[['recency', 'frequency', 'monetary']].mean().to_dict(orient='records')\n            return {\"clusters_summary\": summary, \"counts\": df['cluster'].value_counts().to_dict()}\n        except Exception as e:\n            return {\"error\": str(e)}\n\n    @staticmethod\n    def analyze_cohort_retention(csv_data: str) -> Dict:\n        \"\"\"Analisa retenÃ§Ã£o de coorte (Cohort Analysis).\"\"\"\n        try:\n            df = pd.read_csv(StringIO(csv_data))\n            if 'user_id' not in df.columns or 'date' not in df.columns:\n                return {\"status\": \"SKIPPED\", \"reason\": \"Missing user_id or date column\"}\n            \n            df['date'] = pd.to_datetime(df['date'])\n            # Definir mÃªs de coorte (primeira apariÃ§Ã£o)\n            df['cohort_month'] = df.groupby('user_id')['date'].transform('min').dt.to_period('M')\n            df['current_month'] = df['date'].dt.to_period('M')\n            \n            cohort_data = df.groupby(['cohort_month', 'current_month'])['user_id'].nunique().reset_index()\n            cohort_data['period_number'] = (cohort_data.current_month - cohort_data.cohort_month).apply(lambda x: x.n)\n            \n            cohort_pivot = cohort_data.pivot_table(index='cohort_month', columns='period_number', values='user_id')\n            cohort_size = cohort_pivot.iloc[:, 0]\n            retention = cohort_pivot.divide(cohort_size, axis=0)\n            \n            return {\n                \"retention_matrix\": retention.iloc[:, :4].fillna(0).applymap(lambda x: f\"{x:.1%}\").to_dict(),\n                \"insight\": \"Matriz de retenÃ§Ã£o calculada com sucesso.\"\n            }\n        except Exception as e:\n            return {\"error\": f\"Cohort failed: {str(e)}\"}\n\n# --- 3. Wrappers Seguros para os Agentes ---\n\ndef safe_calculate_sample_size(baseline_rate: float, mde: float, alpha: float = 0.05, power: float = 0.8) -> str:\n    \"\"\"Calcula tamanho de amostra. Inputs: baseline_rate (0-1), mde (pp).\"\"\"\n    try:\n        # Garante conversÃ£o interna caso o LLM envie string\n        res = AdvancedDataScienceToolkit.calculate_sample_size(float(baseline_rate), float(mde), float(alpha), float(power))\n        return json.dumps(res.to_dict(), indent=2)\n    except Exception as e: return json.dumps({\"error\": str(e)})\n\ndef safe_calculate_significance(ctrl_conv: int, ctrl_total: int, treat_conv: int, treat_total: int) -> str:\n    \"\"\"Calcula significÃ¢ncia estatÃ­stica (Teste Z).\"\"\"\n    try:\n        res = AdvancedDataScienceToolkit.calculate_statistical_significance(int(ctrl_conv), int(ctrl_total), int(treat_conv), int(treat_total))\n        return json.dumps(res.to_dict(), indent=2)\n    except Exception as e: return json.dumps({\"error\": str(e)})\n\ndef safe_analyze_csv(csv_data: str) -> str:\n    \"\"\"AnÃ¡lise exploratÃ³ria de CSV.\"\"\"\n    try:\n        res = AdvancedDataScienceToolkit.analyze_csv_dataframe(csv_data)\n        if isinstance(res, dict) and \"error\" in res: return json.dumps(res)\n        return json.dumps(res.to_dict(), indent=2, default=str)\n    except Exception as e: return json.dumps({\"error\": str(e)})\n\ndef safe_chi_square_test(contingency_table_json: str) -> str:\n    \"\"\"Teste Qui-Quadrado. Input: JSON string [[a,b],[c,d]].\"\"\"\n    try:\n        table = json.loads(contingency_table_json)\n        return json.dumps(AdvancedDataScienceToolkit.perform_chi_square_test(table), indent=2)\n    except Exception as e: return json.dumps({\"error\": str(e)})\n\ndef safe_t_test(group_a_json: str, group_b_json: str) -> str:\n    \"\"\"Teste T. Input: JSON strings de listas numÃ©ricas.\"\"\"\n    try:\n        return json.dumps(AdvancedDataScienceToolkit.perform_t_test(json.loads(group_a_json), json.loads(group_b_json)), indent=2)\n    except Exception as e: return json.dumps({\"error\": str(e)})\n\ndef safe_forecast(dates_json: str, values_json: str) -> str:\n    \"\"\"Forecast de mÃ©trica.\"\"\"\n    return json.dumps(AdvancedDataScienceToolkit.forecast_metric(dates_json, values_json))\n\ndef safe_cohort(csv_data: str) -> str:\n    \"\"\"AnÃ¡lise de Cohort.\"\"\"\n    return json.dumps(AdvancedDataScienceToolkit.analyze_cohort_retention(csv_data))\n\ndef safe_segmentation(rfm_json: str) -> str:\n    \"\"\"SegmentaÃ§Ã£o de clientes.\"\"\"\n    return json.dumps(AdvancedDataScienceToolkit.segment_customers(rfm_json))\n\n# --- 4. InstanciaÃ§Ã£o das Ferramentas (FunctionTools) ---\n\n# Core Statistics\nsample_size_tool = FunctionTool(safe_calculate_sample_size)\nsignificance_tool = FunctionTool(safe_calculate_significance)\ncsv_analysis_tool = FunctionTool(safe_analyze_csv)\nchi_square_tool = FunctionTool(safe_chi_square_test)\nt_test_tool = FunctionTool(safe_t_test)\n\n# Advanced DS (Novas ferramentas adicionadas)\nforecast_tool = FunctionTool(safe_forecast)\ncohort_tool = FunctionTool(safe_cohort)\nsegmentation_tool = FunctionTool(safe_segmentation)\n\n# Alias para compatibilidade retroativa\nStatisticalToolkit = AdvancedDataScienceToolkit\n\nlogger.info(\"âœ… Advanced Data Science Toolkit Ready (Stats + ML + Cohort)\")\nprint(\"[OK] All Statistical & ML functions loaded and tools created! ğŸ§ \\\\n\")","metadata":{"execution":{"iopub.status.busy":"2025-11-26T23:32:08.259988Z","iopub.status.idle":"2025-11-26T23:32:08.260300Z","shell.execute_reply.started":"2025-11-26T23:32:08.260144Z","shell.execute_reply":"2025-11-26T23:32:08.260156Z"},"trusted":true},"outputs":[],"execution_count":null},{"id":"9666760f-c608-4f45-ad20-f198b7a2e94e","cell_type":"code","source":"%run -i marketing_agent/agent.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T23:32:08.262248Z","iopub.status.idle":"2025-11-26T23:32:08.262566Z","shell.execute_reply.started":"2025-11-26T23:32:08.262444Z","shell.execute_reply":"2025-11-26T23:32:08.262458Z"}},"outputs":[],"execution_count":null},{"id":"5b90ccda-99a7-436b-9987-8e9d5af2140c","cell_type":"code","source":"# ====================================================================\n# CÃ‰LULA 17.5 MELHORADA: PYTHON REPL CIENTÃFICO COMPLETO\n# ====================================================================\n%%writefile -a marketing_agent/agent.py\n\nimport sys\nimport traceback\nfrom io import StringIO, BytesIO\nimport contextlib\nimport pandas as pd\nimport numpy as np\nfrom scipy import stats\nimport matplotlib\nmatplotlib.use('Agg')  # Backend sem GUI\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom PIL import Image\nimport base64\nimport time\n\nclass ScientificREPL:\n    \"\"\"\n    REPL Python com capacidades cientÃ­ficas completas:\n    - AnÃ¡lise de dados (pandas/numpy/scipy)\n    - VisualizaÃ§Ã£o (matplotlib/seaborn)\n    - AnÃ¡lise de imagens (PIL)\n    - PersistÃªncia de estado\n    \"\"\"\n    \n    def __init__(self):\n        self.local_scope = {}\n        self.figures_generated = []  # HistÃ³rico de grÃ¡ficos\n        \n        # PrÃ©-carregar ambiente cientÃ­fico\n        setup_code = \"\"\"\nimport pandas as pd\nimport numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom datetime import datetime, timedelta\nimport json\n\n# ConfiguraÃ§Ãµes de visualizaÃ§Ã£o\nplt.style.use('seaborn-v0_8-darkgrid')\nsns.set_palette(\"husl\")\npd.set_option('display.max_rows', 15)\npd.set_option('display.max_columns', 12)\npd.set_option('display.width', 1000)\npd.set_option('display.float_format', lambda x: f'{x:.2f}')\n\n# VariÃ¡vel global para armazenar a Ãºltima figura\n_last_fig = None\n\"\"\"\n        self.exec_code(setup_code)\n    \n    def load_data(self, csv_content: str) -> str:\n        \"\"\"Carrega CSV e faz anÃ¡lise inicial automÃ¡tica.\"\"\"\n        try:\n            code = f\"\"\"\nfrom io import StringIO\nimport pandas as pd\nimport numpy as np\n\n# Carregar dados\ncsv_data = '''{csv_content}'''\ndf = pd.read_csv(StringIO(csv_data))\n\n# Inferir tipos automaticamente\nfor col in df.columns:\n    if 'date' in col.lower():\n        try:\n            df[col] = pd.to_datetime(df[col])\n        except:\n            pass\n    elif df[col].dtype == 'object':\n        # Tentar converter para numÃ©rico\n        try:\n            df[col] = pd.to_numeric(df[col])\n        except:\n            pass\n\n# AnÃ¡lise Inicial AutomÃ¡tica\nprint(\"=\"*70)\nprint(\"ğŸ“Š DATASET CARREGADO\")\nprint(\"=\"*70)\nprint(f\"\\\\nğŸ“ DimensÃµes: {df.shape[0]:,} linhas Ã— {df.shape[1]} colunas\")\nprint(f\"\\\\nğŸ“‹ Colunas detectadas:\")\nfor col in df.columns:\n    dtype_info = f\"({df[col].dtype})\"\n    null_pct = (df[col].isnull().sum() / len(df) * 100)\n    null_info = f\"- {null_pct:.1f}% nulos\" if null_pct > 0 else \"\"\n    print(f\"   â€¢ {col:20s} {dtype_info:15s} {null_info}\")\n\nprint(f\"\\\\nğŸ” Preview (primeiras 3 linhas):\")\nprint(df.head(3).to_string())\n\nprint(f\"\\\\nğŸ“ˆ EstatÃ­sticas NumÃ©ricas:\")\nprint(df.describe().to_string())\n\"\"\"\n            return self.exec_code(code)\n        except Exception as e:\n            return f\"âŒ Erro ao carregar dados: {str(e)}\"\n    \n    def exec_code(self, code: str) -> str:\n        \"\"\"Executa cÃ³digo Python e captura output + grÃ¡ficos.\"\"\"\n        output_capture = StringIO()\n        \n        try:\n            with contextlib.redirect_stdout(output_capture):\n                # Executar cÃ³digo\n                exec(code, globals(), self.local_scope)\n                \n                # Capturar figura do matplotlib se houver\n                if plt.get_fignums():  # Se hÃ¡ figuras abertas\n                    fig = plt.gcf()\n                    \n                    # Salvar figura em base64\n                    buf = BytesIO()\n                    fig.savefig(buf, format='png', dpi=100, bbox_inches='tight')\n                    buf.seek(0)\n                    img_base64 = base64.b64encode(buf.read()).decode('utf-8')\n                    \n                    self.figures_generated.append({\n                        'timestamp': datetime.now().isoformat(),\n                        'base64': img_base64\n                    })\n                    \n                    plt.close(fig)  # Limpar\n                    \n                    output_capture.write(f\"\\n\\nğŸ“Š [GRÃFICO GERADO - ID: {len(self.figures_generated)}]\\n\")\n                    output_capture.write(f\"ğŸ–¼ï¸  VisualizaÃ§Ã£o salva. Use get_last_figure() para ver.\\n\")\n            \n            result = output_capture.getvalue()\n            \n            if not result:\n                return \"[âœ“ CÃ³digo executado sem output. Use print() para ver resultados.]\"\n            \n            # Limitar tamanho\n            if len(result) > 8000:\n                return result[:8000] + \"\\n\\nâš ï¸  [OUTPUT TRUNCADO - Seja mais especÃ­fico na query]\"\n            \n            return result\n            \n        except Exception:\n            error_msg = traceback.format_exc()\n            return f\"âŒ ERRO DE EXECUÃ‡ÃƒO:\\n{error_msg}\\n\\nğŸ’¡ Dica: Verifique sintaxe e nomes de variÃ¡veis.\"\n    \n    def get_last_figure(self) -> dict:\n        \"\"\"Retorna a Ãºltima figura gerada.\"\"\"\n        if self.figures_generated:\n            return self.figures_generated[-1]\n        return None\n    \n    def get_scope_info(self) -> str:\n        \"\"\"Retorna informaÃ§Ãµes sobre variÃ¡veis no escopo.\"\"\"\n        vars_info = []\n        for name, obj in self.local_scope.items():\n            if not name.startswith('_'):\n                type_name = type(obj).__name__\n                \n                # Info adicional por tipo\n                extra = \"\"\n                if isinstance(obj, pd.DataFrame):\n                    extra = f\" - {obj.shape[0]} rows Ã— {obj.shape[1]} cols\"\n                elif isinstance(obj, (list, dict, set)):\n                    extra = f\" - len: {len(obj)}\"\n                elif isinstance(obj, (int, float)):\n                    extra = f\" - value: {obj}\"\n                \n                vars_info.append(f\"  â€¢ {name:15s} ({type_name}){extra}\")\n        \n        return \"\\n\".join(vars_info) if vars_info else \"  [Nenhuma variÃ¡vel no escopo]\"\n\n# Instanciar REPL global\nscientific_repl = ScientificREPL()\n\n# ============ FERRAMENTAS PARA O AGENTE ============\n\ndef run_python_analysis(code: str) -> str:\n    \"\"\"\n    ğŸ EXECUTOR DE CÃ“DIGO PYTHON (Sandbox CientÃ­fico)\n    \n    Use para QUALQUER anÃ¡lise de dados. O dataframe estÃ¡ disponÃ­vel como 'df'.\n    \n    **Capacidades:**\n    - ğŸ“Š Pandas/Numpy: df.groupby(), df.pivot_table(), correlaÃ§Ãµes, etc.\n    - ğŸ“ˆ VisualizaÃ§Ã£o: plt.plot(), sns.heatmap(), histogramas, etc.\n    - ğŸ§® EstatÃ­stica: stats.ttest_ind(), chi2_contingency(), etc.\n    - ğŸ” ExploraÃ§Ã£o: df.describe(), value_counts(), crosstabs, etc.\n    \n    **Exemplos:**\n    # AnÃ¡lise de performance por canal\n    print(df.groupby('channel').agg({'cost': 'sum', 'revenue': 'sum'}).assign(ROAS=lambda x: x['revenue']/x['cost']))\n\n    # VisualizaÃ§Ã£o\n    daily = df.groupby('date')['conversions'].sum()\n    plt.plot(daily.index, daily.values)\n    plt.show()\n    \"\"\"\n    # 1. Executa no REPL\n    result = scientific_repl.exec_code(code)\n    time.sleep(2)\n\n    # 2. GUARDRAIL DE TOKENS (OtimizaÃ§Ã£o)\n    # Se o output for gigante (ex: print(df)), cortamos para nÃ£o estourar a API.\n    MAX_CHARS = 2500 \n    if len(result) > MAX_CHARS:\n        removed = len(result) - MAX_CHARS\n        return result[:MAX_CHARS] + f\"\\n\\nâš ï¸ [... OUTPUT TRUNCADO PELO SISTEMA: {removed} caracteres removidos. Use .head() ou agregaÃ§Ãµes para reduzir o tamanho ...]\"\n    \n    return result\ndef run_autopilot_eda() -> str:\n    \"\"\"\n    ğŸ¤– AUTOPILOT EDA (Raio-X AutomÃ¡tico)\n    \n    Executa protocolo completo de anÃ¡lise exploratÃ³ria:\n    1. Shape & Info\n    2. Nulos & Duplicatas  \n    3. EstatÃ­sticas Descritivas\n    4. DistribuiÃ§Ãµes (histogramas automÃ¡ticos)\n    5. CorrelaÃ§Ãµes (heatmap)\n    6. Outliers (boxplots)\n    \"\"\"\n    script = \"\"\"\nprint(\"=\"*70)\nprint(\"ğŸ”¬ PROTOCOLO DE ANÃLISE EXPLORATÃ“RIA\")\nprint(\"=\"*70)\n\n# 1. ESTRUTURA\nprint(\"\\\\nğŸ“ 1. ESTRUTURA DO DATASET\")\nprint(\"-\"*70)\nprint(df.info())\n\n# 2. QUALIDADE\nprint(\"\\\\nğŸ§¹ 2. QUALIDADE DOS DADOS\")\nprint(\"-\"*70)\nmissing = df.isnull().sum()\nif missing.sum() > 0:\n    print(\"âš ï¸  Valores Nulos Detectados:\")\n    print(missing[missing > 0].sort_values(ascending=False))\nelse:\n    print(\"âœ… Sem valores nulos\")\n\nduplicates = df.duplicated().sum()\nprint(f\"\\\\n{'âš ï¸ ' if duplicates > 0 else 'âœ…'} Duplicatas: {duplicates}\")\n\n# 3. ESTATÃSTICAS\nprint(\"\\\\nğŸ“Š 3. ESTATÃSTICAS DESCRITIVAS\")\nprint(\"-\"*70)\nprint(df.describe())\n\n# 4. DISTRIBUIÃ‡Ã•ES (apenas colunas numÃ©ricas principais)\nprint(\"\\\\nğŸ“ˆ 4. DISTRIBUIÃ‡Ã•ES\")\nprint(\"-\"*70)\nnumeric_cols = df.select_dtypes(include=[np.number]).columns[:4]  # Max 4 colunas\nif len(numeric_cols) > 0:\n    fig, axes = plt.subplots(1, len(numeric_cols), figsize=(15, 4))\n    if len(numeric_cols) == 1:\n        axes = [axes]\n    \n    for idx, col in enumerate(numeric_cols):\n        axes[idx].hist(df[col].dropna(), bins=30, edgecolor='black', alpha=0.7)\n        axes[idx].set_title(f'{col}')\n        axes[idx].set_xlabel('Valor')\n        axes[idx].set_ylabel('FrequÃªncia')\n    \n    plt.tight_layout()\n    plt.show()\n    print(f\"âœ… Histogramas gerados para: {', '.join(numeric_cols)}\")\nelse:\n    print(\"âš ï¸  Nenhuma coluna numÃ©rica detectada\")\n\n# 5. CORRELAÃ‡Ã•ES\nprint(\"\\\\nğŸ”— 5. MATRIZ DE CORRELAÃ‡ÃƒO\")\nprint(\"-\"*70)\nnumeric_df = df.select_dtypes(include=[np.number])\nif len(numeric_df.columns) > 1:\n    corr_matrix = numeric_df.corr()\n    \n    # Heatmap\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n                center=0, square=True, linewidths=1)\n    plt.title('Matriz de CorrelaÃ§Ã£o', fontsize=14, fontweight='bold')\n    plt.tight_layout()\n    plt.show()\n    \n    # Top correlaÃ§Ãµes\n    print(\"\\\\nğŸ” Top 5 CorrelaÃ§Ãµes Positivas:\")\n    corr_pairs = corr_matrix.unstack()\n    corr_pairs = corr_pairs[corr_pairs < 1.0]  # Remove diagonal\n    print(corr_pairs.sort_values(ascending=False).head(5))\nelse:\n    print(\"âš ï¸  NecessÃ¡rio pelo menos 2 colunas numÃ©ricas\")\n\n# 6. OUTLIERS\nprint(\"\\\\nğŸ¯ 6. DETECÃ‡ÃƒO DE OUTLIERS (Boxplots)\")\nprint(\"-\"*70)\noutlier_cols = numeric_df.columns[:4]\nif len(outlier_cols) > 0:\n    fig, axes = plt.subplots(1, len(outlier_cols), figsize=(15, 4))\n    if len(outlier_cols) == 1:\n        axes = [axes]\n    \n    for idx, col in enumerate(outlier_cols):\n        axes[idx].boxplot(df[col].dropna())\n        axes[idx].set_title(f'{col}')\n        axes[idx].set_ylabel('Valor')\n    \n    plt.tight_layout()\n    plt.show()\n    print(f\"âœ… Boxplots gerados para: {', '.join(outlier_cols)}\")\n\nprint(\"\\\\n\" + \"=\"*70)\nprint(\"âœ… ANÃLISE EXPLORATÃ“RIA COMPLETA\")\nprint(\"=\"*70)\n\"\"\"\n    return scientific_repl.exec_code(script)\n\ndef analyze_image(image_description: str, analysis_goal: str) -> str:\n    \"\"\"\n    ğŸ–¼ï¸  ANÃLISE DE IMAGEM (via DescriÃ§Ã£o)\n    \n    Como nÃ£o temos acesso direto a imagens no ambiente, use esta ferramenta\n    para guiar anÃ¡lise visual quando o usuÃ¡rio descrever uma imagem/grÃ¡fico.\n    \n    Args:\n        image_description: DescriÃ§Ã£o detalhada da imagem\n        analysis_goal: O que vocÃª quer descobrir (ex: \"identificar outliers\", \"validar tendÃªncia\")\n    \"\"\"\n    return f\"\"\"\nğŸ“¸ ANÃLISE VISUAL SOLICITADA\n\n**DescriÃ§Ã£o:** {image_description}\n**Objetivo:** {analysis_goal}\n\nğŸ’¡ **RecomendaÃ§Ãµes para AnÃ¡lise:**\n1. Se for um grÃ¡fico de linha/sÃ©rie temporal:\n   - Procure por quebras abruptas (possÃ­vel erro de dados)\n   - Identifique sazonalidade (padrÃµes repetidos)\n   - Observe a tendÃªncia geral (crescente/decrescente)\n\n2. Se for um grÃ¡fico de barras/colunas:\n   - Compare magnitudes relativas\n   - Identifique outliers (barras muito maiores/menores)\n   - Verifique se faz sentido de negÃ³cio\n\n3. Se for um scatter plot:\n   - Procure por correlaÃ§Ã£o visual\n   - Identifique clusters\n   - Detecte outliers\n\n4. Se for um heatmap:\n   - Cores quentes = valores altos\n   - Cores frias = valores baixos\n   - Procure por padrÃµes (linhas/colunas similares)\n\n**AÃ§Ã£o Recomendada:** Use `run_python_analysis()` para recriar este grÃ¡fico com os dados\ne validar suas observaÃ§Ãµes com estatÃ­sticas.\n\"\"\"\n\ndef get_variable_info() -> str:\n    \"\"\"\n    ğŸ“‹ INSPETOR DE VARIÃVEIS\n    \n    Mostra todas as variÃ¡veis atualmente no escopo do Python (df, resultados, etc.)\n    \"\"\"\n    info = f\"\"\"\nğŸ” VARIÃVEIS NO ESCOPO PYTHON:\n\n{scientific_repl.get_scope_info()}\n\nğŸ’¡ Dica: Use print(nome_da_variavel) para inspecionar qualquer uma delas.\n\"\"\"\n    return info\n\n# Criar FunctionTools\npython_tool = FunctionTool(run_python_analysis)\nautopilot_tool = FunctionTool(run_autopilot_eda)\nimage_analysis_tool = FunctionTool(analyze_image)\nscope_inspector_tool = FunctionTool(get_variable_info)\n\nprint(\"âœ… Scientific REPL Ready!\")\nprint(\"ğŸ“Š Capacidades: Pandas + Matplotlib + Seaborn + SciPy\")\nprint(\"ğŸ¨ VisualizaÃ§Ãµes: AutomÃ¡ticas (base64)\")\nprint(\"ğŸ”¬ Autopilot: EDA Completo em 1 comando\\n\")","metadata":{"execution":{"iopub.status.busy":"2025-11-26T23:32:08.263777Z","iopub.status.idle":"2025-11-26T23:32:08.264259Z","shell.execute_reply.started":"2025-11-26T23:32:08.263942Z","shell.execute_reply":"2025-11-26T23:32:08.263955Z"},"trusted":true},"outputs":[],"execution_count":null},{"id":"1a6727ce-5d19-4a6d-b379-88239b23ddb9","cell_type":"code","source":"%run -i marketing_agent/agent.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T23:32:08.266658Z","iopub.status.idle":"2025-11-26T23:32:08.266951Z","shell.execute_reply.started":"2025-11-26T23:32:08.266825Z","shell.execute_reply":"2025-11-26T23:32:08.266837Z"}},"outputs":[],"execution_count":null},{"id":"d64ffe4d","cell_type":"markdown","source":"## ğŸ¤– Fase 10: Contratando o Time Operacional (Agentes NÃ­vel 1)\nAqui instanciamos os especialistas que farÃ£o o trabalho pesado. Cada agente tem uma \"Instruction\" (System Prompt) otimizada para atuar como um profissional especÃ­fico:\n*   **DataQualityAgent:** O Auditor que verifica se o CSV estÃ¡ limpo.\n*   **TrackingAgent:** O Engenheiro que valida se o pixel do Google/Facebook estÃ¡ funcionando.\n*   **StatsAgent:** O EstatÃ­stico que roda os testes de hipÃ³tese (nossa garantia contra o acaso).","metadata":{}},{"id":"1bc4c237-ebce-48e2-b41f-59702b0f2350","cell_type":"code","source":"# ====================================================================\n# CÃ‰LULA 17.6: SISTEMA DE MEMÃ“RIA PERSISTENTE PARA EDA\n# ====================================================================\n%%writefile -a marketing_agent/agent.py\n\nfrom dataclasses import dataclass, field, asdict\nfrom typing import List, Dict, Optional\nimport json\nimport hashlib\nfrom datetime import datetime\nfrom pathlib import Path\n\n@dataclass\nclass Hypothesis:\n    \"\"\"HipÃ³tese analÃ­tica rastreÃ¡vel.\"\"\"\n    id: str\n    text: str\n    confidence: float  # 0-1\n    evidence: List[str]  # CÃ³digo/outputs que suportam\n    status: str  # \"proposed\", \"testing\", \"confirmed\", \"rejected\"\n    created_at: str = field(default_factory=lambda: datetime.now().isoformat())\n    \n@dataclass\nclass AnalysisCheckpoint:\n    \"\"\"Checkpoint de uma etapa de anÃ¡lise.\"\"\"\n    stage: str\n    completed: bool\n    insights: List[str]\n    code_executed: List[str]\n    hypotheses_generated: List[str]\n    timestamp: str = field(default_factory=lambda: datetime.now().isoformat())\n    \n@dataclass\nclass EDAMemory:\n    \"\"\"MemÃ³ria persistente de toda a anÃ¡lise exploratÃ³ria.\"\"\"\n    dataset_hash: str\n    checkpoints: Dict[str, Dict] = field(default_factory=dict)\n    hypotheses: Dict[str, Dict] = field(default_factory=dict)\n    insights: List[str] = field(default_factory=list)\n    dead_ends: List[str] = field(default_factory=list)\n    convergence_metrics: Dict[str, float] = field(default_factory=dict)\n    \n    def to_json(self) -> str:\n        \"\"\"Serializa para JSON.\"\"\"\n        return json.dumps(asdict(self), default=str, indent=2)\n    \n    @classmethod\n    def from_json(cls, json_str: str) -> 'EDAMemory':\n        \"\"\"Desserializa de JSON.\"\"\"\n        data = json.loads(json_str)\n        return cls(**data)\n    \n    def save_to_disk(self, filepath: str):\n        \"\"\"Persiste em disco.\"\"\"\n        try:\n            Path(filepath).write_text(self.to_json())\n            logger.info(f\"ğŸ’¾ Memory saved: {filepath}\")\n        except Exception as e:\n            logger.warning(f\"âš ï¸ Could not save memory: {e}\")\n    \n    @classmethod\n    def load_from_disk(cls, filepath: str) -> Optional['EDAMemory']:\n        \"\"\"Carrega de disco.\"\"\"\n        try:\n            json_str = Path(filepath).read_text()\n            return cls.from_json(json_str)\n        except FileNotFoundError:\n            return None\n        except Exception as e:\n            logger.warning(f\"âš ï¸ Could not load memory: {e}\")\n            return None\n\nlogger.info(\"âœ… EDA Memory System ready\")\nprint(\"[OK] Sistema de MemÃ³ria EDA criado! ğŸ’¾\\n\")","metadata":{"execution":{"iopub.status.busy":"2025-11-26T23:32:08.267749Z","iopub.status.idle":"2025-11-26T23:32:08.268333Z","shell.execute_reply.started":"2025-11-26T23:32:08.267989Z","shell.execute_reply":"2025-11-26T23:32:08.268008Z"},"trusted":true},"outputs":[],"execution_count":null},{"id":"52cf7142-0fe9-4eaa-b99f-e195e1cc2daf","cell_type":"code","source":"%run -i marketing_agent/agent.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T23:32:08.269978Z","iopub.status.idle":"2025-11-26T23:32:08.270403Z","shell.execute_reply.started":"2025-11-26T23:32:08.270175Z","shell.execute_reply":"2025-11-26T23:32:08.270192Z"}},"outputs":[],"execution_count":null},{"id":"c7c4d7e0-8a11-4f08-a7e6-825ca90d1659","cell_type":"code","source":"# ====================================================================\n# CÃ‰LULA 17.7: CONTROLADOR DE LOOP DE EDA\n# ====================================================================\n%%writefile -a marketing_agent/agent.py\n\nclass EDALoopController:\n    \"\"\"\n    Controla o loop de anÃ¡lise exploratÃ³ria com critÃ©rios de convergÃªncia.\n    \"\"\"\n    \n    REQUIRED_STAGES = [\n        \"data_profiling\",\n        \"quality_check\",\n        \"univariate\",\n        \"bivariate\",\n        \"temporal\",\n        \"synthesis\"\n    ]\n    \n    def __init__(\n        self, \n        memory: EDAMemory,\n        max_iterations: int = 7,\n        convergence_threshold: float = 0.80\n    ):\n        self.memory = memory\n        self.max_iterations = max_iterations\n        self.convergence_threshold = convergence_threshold\n        self.current_iteration = 0\n        \n    def should_stop(self) -> tuple:\n        \"\"\"Retorna (should_stop: bool, reason: str).\"\"\"\n        \n        # CritÃ©rio 1: Limite de iteraÃ§Ãµes\n        if self.current_iteration >= self.max_iterations:\n            return True, f\"Max iterations ({self.max_iterations}) reached\"\n        \n        # CritÃ©rio 2: Cobertura completa\n        coverage = self.calculate_coverage()\n        if coverage >= self.convergence_threshold:\n            return True, f\"Coverage threshold met ({coverage:.1%})\"\n        \n        # CritÃ©rio 3: EstagnaÃ§Ã£o (sem novos insights em 2 iteraÃ§Ãµes)\n        if self.current_iteration >= 3:\n            recent_count = self._count_recent_insights(lookback=2)\n            if recent_count == 0:\n                return True, \"No new insights in last 2 iterations\"\n        \n        return False, \"\"\n    \n    def calculate_coverage(self) -> float:\n        \"\"\"Calcula % de cobertura dos estÃ¡gios obrigatÃ³rios.\"\"\"\n        completed = sum(\n            1 for stage in self.REQUIRED_STAGES \n            if stage in self.memory.checkpoints \n            and self.memory.checkpoints[stage].get('completed', False)\n        )\n        return completed / len(self.REQUIRED_STAGES) if self.REQUIRED_STAGES else 0\n    \n    def _count_recent_insights(self, lookback: int = 2) -> int:\n        \"\"\"Conta insights recentes.\"\"\"\n        if not self.memory.checkpoints:\n            return 0\n        \n        recent = sorted(\n            self.memory.checkpoints.values(),\n            key=lambda c: c.get('timestamp', ''),\n            reverse=True\n        )[:lookback]\n        \n        return sum(len(c.get('insights', [])) for c in recent)\n    \n    def get_next_stage(self) -> str:\n        \"\"\"Decide qual estÃ¡gio analisar a seguir.\"\"\"\n        for stage in self.REQUIRED_STAGES:\n            if stage not in self.memory.checkpoints or \\\n               not self.memory.checkpoints[stage].get('completed', False):\n                return stage\n        \n        # Todos completos: re-analisa o mais fraco\n        if self.memory.checkpoints:\n            weakest = min(\n                self.memory.checkpoints.items(),\n                key=lambda x: len(x[1].get('insights', []))\n            )[0]\n            return weakest\n        \n        return self.REQUIRED_STAGES[0]\n    \n    def get_context_for_llm(self) -> str:\n        \"\"\"Gera contexto rico para o LLM.\"\"\"\n        coverage = self.calculate_coverage()\n        \n        parts = [\n            f\"ğŸ“Š **EDA PROGRESS** (Iteration {self.current_iteration})\",\n            f\"Coverage: {coverage:.1%}\",\n            \"\",\n            \"âœ… **Completed:**\"\n        ]\n        \n        for stage, checkpoint in self.memory.checkpoints.items():\n            if checkpoint.get('completed'):\n                insights_count = len(checkpoint.get('insights', []))\n                parts.append(f\"  â€¢ {stage}: {insights_count} insights\")\n        \n        parts.append(\"\\nğŸ’¡ **Recent Insights:**\")\n        for insight in self.memory.insights[-3:]:\n            parts.append(f\"  â€¢ {insight}\")\n        \n        if self.memory.dead_ends:\n            parts.append(\"\\nâš ï¸ **Avoid (dead ends):**\")\n            for dead in self.memory.dead_ends[-2:]:\n                parts.append(f\"  â€¢ {dead}\")\n        \n        return \"\\n\".join(parts)\n\nlogger.info(\"âœ… EDA Loop Controller ready\")\nprint(\"[OK] Controlador de Loop criado! ğŸ”„\\n\")","metadata":{"execution":{"iopub.status.busy":"2025-11-26T23:32:08.271640Z","iopub.status.idle":"2025-11-26T23:32:08.271890Z","shell.execute_reply.started":"2025-11-26T23:32:08.271778Z","shell.execute_reply":"2025-11-26T23:32:08.271789Z"},"trusted":true},"outputs":[],"execution_count":null},{"id":"6ebaa8fe-d0e0-4e79-bdc8-ccc3c52a378d","cell_type":"code","source":"%run -i marketing_agent/agent.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T23:32:08.272968Z","iopub.status.idle":"2025-11-26T23:32:08.273368Z","shell.execute_reply.started":"2025-11-26T23:32:08.273164Z","shell.execute_reply":"2025-11-26T23:32:08.273180Z"}},"outputs":[],"execution_count":null},{"id":"00d7e997-13ac-42b9-87d9-b25ba7e0ae99","cell_type":"code","source":"# ====================================================================\n# CÃ‰LULA 17.8: AGENTE DE EDA AUTÃ”NOMO\n# ====================================================================\n%%writefile -a marketing_agent/agent.py\n\nclass AutonomousEDAAgent:\n    \"\"\"Agente autÃ´nomo que conduz EDA completa usando padrÃ£o ReAct.\"\"\"\n    \n    def __init__(\n        self,\n        scientific_repl,\n        memory: EDAMemory,\n        controller: EDALoopController\n    ):\n        self.repl = scientific_repl\n        self.memory = memory\n        self.controller = controller\n        \n    def run_autonomous_eda_sync(self) -> Dict[str, Any]:\n        \"\"\"VersÃ£o SÃNCRONA para usar em FunctionTool.\"\"\"\n        \n        print(\"ğŸš€ Starting Autonomous EDA...\")\n        print(\"=\"*70)\n        \n        while True:\n            self.controller.current_iteration += 1\n            iteration = self.controller.current_iteration\n            \n            print(f\"\\nğŸ”„ Iteration {iteration}\")\n            \n            # STEP 1: Check convergÃªncia\n            should_stop, reason = self.controller.should_stop()\n            if should_stop:\n                print(f\"\\nâœ… EDA Complete! {reason}\")\n                break\n            \n            next_stage = self.controller.get_next_stage()\n            context = self.controller.get_context_for_llm()\n            \n            print(f\"ğŸ¯ Stage: {next_stage} | Coverage: {self.controller.calculate_coverage():.1%}\")\n            \n            # STEP 2: Gerar cÃ³digo de anÃ¡lise\n            code = self._generate_analysis_code(next_stage, context)\n            \n            if not code:\n                print(\"âš ï¸ No code generated, skipping\")\n                continue\n            \n            # STEP 3: Executar\n            try:\n                print(f\"ğŸ’» Executing... ({len(code)} chars)\")\n                result = self.repl.exec_code(code)\n                print(f\"ğŸ“Š Result: {result[:300]}...\")\n                \n                # STEP 4: Processar resultados\n                checkpoint = self._process_results(next_stage, code, result)\n                self.memory.checkpoints[next_stage] = asdict(checkpoint)\n                \n                # Persistir\n                self.memory.save_to_disk(f\"eda_memory_{self.memory.dataset_hash}.json\")\n                \n            except Exception as e:\n                print(f\"âŒ Error: {e}\")\n                self.memory.dead_ends.append(f\"Iter {iteration} ({next_stage}): {str(e)}\")\n                continue\n        \n        # STEP 5: SÃ­ntese final\n        return self._generate_report()\n    \n    def _generate_analysis_code(self, stage: str, context: str) -> str:\n        \"\"\"Gera cÃ³digo Python para o estÃ¡gio atual.\"\"\"\n        \n        # Mapeamento de estÃ¡gio â†’ cÃ³digo template\n        code_templates = {\n            \"data_profiling\": \"\"\"\nprint(\"ğŸ“‹ DATA PROFILING\")\nprint(\"-\" * 50)\nprint(f\"Shape: {df.shape}\")\nprint(f\"\\\\nColumns: {df.columns.tolist()}\")\nprint(f\"\\\\nTypes:\\\\n{df.dtypes}\")\nprint(f\"\\\\nMissing:\\\\n{df.isnull().sum()}\")\nprint(f\"\\\\nDuplicates: {df.duplicated().sum()}\")\n\"\"\",\n            \"quality_check\": \"\"\"\nprint(\"ğŸ” QUALITY CHECK\")\nprint(\"-\" * 50)\n# Outliers\nnumeric_cols = df.select_dtypes(include=[np.number]).columns\nfor col in numeric_cols[:3]:\n    Q1 = df[col].quantile(0.25)\n    Q3 = df[col].quantile(0.75)\n    IQR = Q3 - Q1\n    outliers = df[(df[col] < Q1 - 1.5*IQR) | (df[col] > Q3 + 1.5*IQR)]\n    print(f\"{col}: {len(outliers)} outliers ({len(outliers)/len(df)*100:.1f}%)\")\n\"\"\",\n            \"univariate\": \"\"\"\nprint(\"ğŸ“Š UNIVARIATE ANALYSIS\")\nprint(\"-\" * 50)\nprint(df.describe())\n# Histograms\nnumeric_cols = df.select_dtypes(include=[np.number]).columns\nif len(numeric_cols) > 0:\n    fig, axes = plt.subplots(1, min(3, len(numeric_cols)), figsize=(15, 4))\n    if len(numeric_cols) == 1:\n        axes = [axes]\n    for idx, col in enumerate(numeric_cols[:3]):\n        axes[idx].hist(df[col].dropna(), bins=30, edgecolor='black')\n        axes[idx].set_title(col)\n    plt.tight_layout()\n    plt.show()\n\"\"\",\n            \"bivariate\": \"\"\"\nprint(\"ğŸ”— BIVARIATE ANALYSIS\")\nprint(\"-\" * 50)\nnumeric_df = df.select_dtypes(include=[np.number])\nif len(numeric_df.columns) > 1:\n    corr = numeric_df.corr()\n    print(\"\\\\nTop Correlations:\")\n    corr_pairs = corr.unstack()\n    corr_pairs = corr_pairs[corr_pairs < 1.0]\n    print(corr_pairs.sort_values(ascending=False).head(5))\n\"\"\",\n            \"temporal\": \"\"\"\nprint(\"ğŸ“ˆ TEMPORAL ANALYSIS\")\nprint(\"-\" * 50)\ndate_cols = [col for col in df.columns if 'date' in col.lower()]\nif date_cols:\n    date_col = date_cols[0]\n    df_temp = df.copy()\n    df_temp[date_col] = pd.to_datetime(df_temp[date_col])\n    df_temp = df_temp.sort_values(date_col)\n    \n    # Trend\n    numeric_cols = df_temp.select_dtypes(include=[np.number]).columns\n    if len(numeric_cols) > 0:\n        col = numeric_cols[0]\n        daily = df_temp.groupby(date_col)[col].mean()\n        print(f\"Trend in {col}:\")\n        print(f\"  Start: {daily.iloc[0]:.2f}\")\n        print(f\"  End: {daily.iloc[-1]:.2f}\")\n        print(f\"  Change: {(daily.iloc[-1]/daily.iloc[0]-1)*100:.1f}%\")\nelse:\n    print(\"No date column found\")\n\"\"\",\n            \"synthesis\": \"\"\"\nprint(\"âœ¨ SYNTHESIS\")\nprint(\"-\" * 50)\nprint(\"Analysis complete. Key findings:\")\nprint(f\"  â€¢ Dataset: {df.shape[0]} rows Ã— {df.shape[1]} cols\")\nprint(f\"  â€¢ Completeness: {(1 - df.isnull().sum().sum()/(df.shape[0]*df.shape[1]))*100:.1f}%\")\nnumeric_cols = df.select_dtypes(include=[np.number]).columns\nif len(numeric_cols) > 0:\n    print(f\"  â€¢ Numeric features: {len(numeric_cols)}\")\n\"\"\"\n        }\n        \n        # Retorna template ou cÃ³digo genÃ©rico\n        return code_templates.get(stage, f\"print('Analyzing {stage}...')\\nprint(df.head())\")\n    \n    def _process_results(self, stage: str, code: str, result: str) -> AnalysisCheckpoint:\n        \"\"\"Processa resultados e extrai insights.\"\"\"\n        \n        # ExtraÃ§Ã£o simples de insights (regex bÃ¡sico)\n        insights = []\n        \n        # Se hÃ¡ nÃºmeros no resultado, pode ser insight\n        if any(char.isdigit() for char in result):\n            # Pega primeira linha com nÃºmero\n            for line in result.split('\\n'):\n                if any(char.isdigit() for char in line) and len(line) < 200:\n                    insights.append(line.strip())\n                    if len(insights) >= 3:\n                        break\n        \n        # Adiciona Ã  memÃ³ria global\n        for insight in insights:\n            if insight and insight not in self.memory.insights:\n                self.memory.insights.append(insight)\n        \n        # Considera completo se gerou insights ou executou sem erro\n        completed = len(insights) > 0 or \"Error\" not in result\n        \n        return AnalysisCheckpoint(\n            stage=stage,\n            completed=completed,\n            insights=insights,\n            code_executed=[code],\n            hypotheses_generated=[]\n        )\n    \n    def _generate_report(self) -> Dict[str, Any]:\n        \"\"\"Gera relatÃ³rio final.\"\"\"\n        \n        summary_lines = [\n            \"ğŸ¯ **AUTONOMOUS EDA COMPLETED**\",\n            \"\",\n            f\"**Iterations:** {self.controller.current_iteration}\",\n            f\"**Coverage:** {self.controller.calculate_coverage():.1%}\",\n            f\"**Insights:** {len(self.memory.insights)}\",\n            f\"**Stages:** {len(self.memory.checkpoints)}/{len(self.controller.REQUIRED_STAGES)}\",\n            \"\",\n            \"**Key Findings:**\"\n        ]\n        \n        # Top insights\n        for idx, insight in enumerate(self.memory.insights[:5], 1):\n            summary_lines.append(f\"{idx}. {insight}\")\n        \n        return {\n            \"summary\": \"\\n\".join(summary_lines),\n            \"iterations\": self.controller.current_iteration,\n            \"coverage\": self.controller.calculate_coverage(),\n            \"insights_count\": len(self.memory.insights),\n            \"memory_file\": f\"eda_memory_{self.memory.dataset_hash}.json\"\n        }\n\nlogger.info(\"âœ… Autonomous EDA Agent ready\")\nprint(\"[OK] Agente AutÃ´nomo criado! ğŸ¤–\\n\")","metadata":{"execution":{"iopub.status.busy":"2025-11-26T23:32:08.275850Z","iopub.status.idle":"2025-11-26T23:32:08.276284Z","shell.execute_reply.started":"2025-11-26T23:32:08.276073Z","shell.execute_reply":"2025-11-26T23:32:08.276091Z"},"trusted":true},"outputs":[],"execution_count":null},{"id":"826e8974-8689-4b69-94a8-0ffcf43166eb","cell_type":"code","source":"%run -i marketing_agent/agent.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T23:32:08.277183Z","iopub.status.idle":"2025-11-26T23:32:08.277641Z","shell.execute_reply.started":"2025-11-26T23:32:08.277483Z","shell.execute_reply":"2025-11-26T23:32:08.277499Z"}},"outputs":[],"execution_count":null},{"id":"9706c5b7-9bcd-427b-8ef0-78fcb78abbb7","cell_type":"code","source":"# ====================================================================\n# CÃ‰LULA 17.9: TOOL WRAPPER PARA O AGENTE AUTÃ”NOMO\n# ====================================================================\n%%writefile -a marketing_agent/agent.py\n\ndef run_autonomous_eda_analysis() -> str:\n    \"\"\"\n    ğŸ¤– EDA AUTÃ”NOMO COM LOOP CONTROLADO\n    \n    Executa anÃ¡lise exploratÃ³ria completa de forma autÃ´noma:\n    - Loop com critÃ©rios de convergÃªncia\n    - MemÃ³ria persistente\n    - 6 estÃ¡gios obrigatÃ³rios\n    \n    Diferente do autopilot (single-shot), este itera atÃ© completude.\n    \"\"\"\n    try:\n        # Validar se hÃ¡ dados\n        if 'df' not in scientific_repl.local_scope:\n            return \"âŒ Erro: Nenhum dataset carregado. Use upload ou load_data() primeiro.\"\n        \n        df = scientific_repl.local_scope['df']\n        \n        # Hash do dataset\n        dataset_hash = hashlib.md5(df.to_csv().encode()).hexdigest()[:12]\n        \n        # Carregar ou criar memÃ³ria\n        memory_file = f\"eda_memory_{dataset_hash}.json\"\n        eda_memory = EDAMemory.load_from_disk(memory_file)\n        \n        if eda_memory:\n            print(f\"ğŸ“‚ Loaded existing memory: {memory_file}\")\n        else:\n            print(f\"ğŸ†• Creating new memory: {memory_file}\")\n            eda_memory = EDAMemory(dataset_hash=dataset_hash)\n        \n        # Criar controller\n        controller = EDALoopController(\n            memory=eda_memory,\n            max_iterations=6,  # Limite seguro\n            convergence_threshold=0.75  # 75% de cobertura\n        )\n        \n        # Criar agente\n        agent = AutonomousEDAAgent(\n            scientific_repl=scientific_repl,\n            memory=eda_memory,\n            controller=controller\n        )\n        \n        # Executar\n        report = agent.run_autonomous_eda_sync()\n        \n        return json.dumps(report, indent=2)\n        \n    except Exception as e:\n        logger.error(f\"Autonomous EDA error: {e}\")\n        return f\"âŒ Erro: {str(e)}\"\n\n# Criar FunctionTool\nautonomous_eda_tool = FunctionTool(run_autonomous_eda_analysis)\n\nlogger.info(\"âœ… Autonomous EDA Tool ready\")\nprint(\"[OK] Tool criada! Pronta para uso no agente! ğŸ”§\\n\")","metadata":{"execution":{"iopub.status.busy":"2025-11-26T23:32:08.279555Z","iopub.status.idle":"2025-11-26T23:32:08.279848Z","shell.execute_reply.started":"2025-11-26T23:32:08.279729Z","shell.execute_reply":"2025-11-26T23:32:08.279741Z"},"trusted":true},"outputs":[],"execution_count":null},{"id":"7ff45f33-7b59-4440-843c-7a57807159ca","cell_type":"code","source":"%run -i marketing_agent/agent.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T23:32:08.280609Z","iopub.status.idle":"2025-11-26T23:32:08.280949Z","shell.execute_reply.started":"2025-11-26T23:32:08.280781Z","shell.execute_reply":"2025-11-26T23:32:08.280796Z"}},"outputs":[],"execution_count":null},{"id":"7321d497","cell_type":"code","source":"# ====================================================================\n# CELL 18: CRIAÃ‡ÃƒO DOS AGENTES ESPECIALIZADOS (NÃVEL 1) - FUSÃƒO\n# ====================================================================\n%%writefile -a marketing_agent/agent.py\n\n# --- Agente 1: Data Quality Agent (Mantido Original - Era Excelente) ---\ndata_quality_tools = [csv_analysis_tool]\nif bq_toolset:\n    data_quality_tools.append(bq_toolset)\n\ndata_quality_agent = Agent(\n    name=\"DataQualityAgent\",\n    model=model,\n    instruction=\"\"\"VocÃª Ã© um auditor de dados especializado em validaÃ§Ã£o de qualidade.\n\nSua funÃ§Ã£o Ã© verificar a integridade e confiabilidade dos dados ANTES de qualquer anÃ¡lise.\n\nProtocolo de Auditoria:\n1. **Valores Nulos/Missing**: Identifique colunas crÃ­ticas com missing values (ex: gclid, event_name, campaign_id, cost, conversions)\n2. **Anomalias Temporais**: Detecte picos ou vales extremos em mÃ©tricas-chave que indiquem falha de ingestÃ£o\n3. **Duplicatas**: Verifique IDs duplicados (transaction_id, user_id, gclid)\n4. **ConsistÃªncia de MÃ©tricas**: Valide relaÃ§Ãµes lÃ³gicas (ex: clicks <= impressions, conversions <= sessions)\n5. **Outliers**: Identifique valores absurdos (CPC negativo, CTR > 100%, revenue negativo)\n\nFormato de SaÃ­da:\n- Status: OK / WARNING / CRITICAL\n- Lista de problemas encontrados com severidade\n- RecomendaÃ§Ã£o: se CRITICAL, anÃ¡lise deve parar atÃ© correÃ§Ã£o\n\nSeja objetivo e tÃ©cnico.\"\"\",\n    tools=data_quality_tools,\n    output_key=\"data_quality_report\"\n)\n\n# --- Agente 2: Tracking Agent (Mantido Original - Era Excelente) ---\ntracking_tools = [csv_analysis_tool]\nif bq_toolset:\n    tracking_tools.append(bq_toolset)\n\ntracking_agent = Agent(\n    name=\"TrackingAgent\",\n    model=model,\n    instruction=\"\"\"VocÃª Ã© um especialista em implementaÃ§Ã£o de tracking e tags.\n\nSua funÃ§Ã£o Ã© validar se os eventos e conversÃµes estÃ£o sendo rastreados corretamente.\n\nChecklist de ValidaÃ§Ã£o:\n1. **Eventos de ConversÃ£o**: Verifique presenÃ§a de eventos crÃ­ticos (purchase, generate_lead, sign_up)\n2. **GCLID**: Para trÃ¡fego 'google / cpc', valide presenÃ§a e formato do gclid\n3. **ParÃ¢metros UTM**: Verifique consistÃªncia de utm_source, utm_medium, utm_campaign\n4. **AtribuiÃ§Ã£o**: Valide se conversÃµes estÃ£o sendo atribuÃ­das corretamente Ã s campanhas\n5. **DiscrepÃ¢ncias**: Compare mÃ©tricas entre plataformas (Google Ads vs GA4)\n\nFormato de SaÃ­da:\n- Status: OK / WARNING / CRITICAL\n- Problemas de tracking identificados\n- Impacto estimado (% de dados afetados)\n- AÃ§Ãµes corretivas recomendadas\n\nSeja preciso e tÃ©cnico.\"\"\",\n    tools=tracking_tools,\n    output_key=\"tracking_report\"\n)\n\n# --- Agente 3: Funnel Agent (Mantido Original) ---\nfunnel_tools = [csv_analysis_tool, google_search]\nif bq_toolset:\n    funnel_tools.append(bq_toolset)\n\nfunnel_agent = Agent(\n    name=\"FunnelAgent\",\n    model=model,\n    instruction=\"\"\"VocÃª Ã© um analista de funil de conversÃ£o especializado.\n\nSua funÃ§Ã£o Ã© mapear o funil completo e identificar gargalos.\n\nAnÃ¡lise de Funil:\n1. **Etapas do Funil**: ImpressÃµes â†’ Cliques â†’ SessÃµes â†’ ConversÃµes\n2. **Taxas de ConversÃ£o**:\n   - CTR = Cliques / ImpressÃµes\n   - Session Rate = SessÃµes / Cliques\n   - CVR = ConversÃµes / SessÃµes\n3. **IdentificaÃ§Ã£o de Gargalo**: Qual etapa tem maior drop-off percentual?\n4. **SegmentaÃ§Ã£o**: Analise funil por:\n   - Canal (paid_search, social, display)\n   - Device (mobile, desktop)\n   - Campanha\n5. **Benchmarks**: Compare com benchmarks de mercado\n\nFormato de SaÃ­da:\n- VisÃ£o geral do funil com taxas\n- Gargalo primÃ¡rio identificado\n- Segmentos com melhor/pior performance\n- HipÃ³teses iniciais sobre causas\n\nUse dados e seja especÃ­fico.\"\"\",\n    tools=funnel_tools,\n    output_key=\"funnel_report\"\n)\n\n# --- Agente 4: EDA Agent (FUSÃƒO: Estrutura Original + Cohort Tool) ---\neda_tools = [csv_analysis_tool, cohort_tool, google_search] # Adicionado cohort_tool\nif bq_toolset:\n    eda_tools.append(bq_toolset)\n\neda_agent = Agent(\n    name=\"EdaAgent\",\n    model=model,\n    instruction=\"\"\"VocÃª Ã© um especialista em EDA (Exploratory Data Analysis) e Comportamento do UsuÃ¡rio (Retention).\n\nQuando receber dados de campanhas, siga SEMPRE esta estrutura:\n\n1. **VisÃ£o Geral do Dado**\n   - PerÃ­odo, granularidade, dimensÃµes principais\n   - MÃ©tricas disponÃ­veis\n\n2. **Qualidade do Dado** (problemas escondidos)\n   - Missing values, duplicatas, outliers\n   - Problemas de marketing (Datas invertidas, CTR > 100%)\n\n3. **EDA de Performance & RetenÃ§Ã£o (ATUALIZADO)**\n   - Calcule: CTR, CPC, CPA, CVR, ROAS.\n   - **AnÃ¡lise de Coorte (OBRIGATÃ“RIO se houver 'user_id')**:\n     * Use a ferramenta `cohort_tool`.\n     * Analise a retenÃ§Ã£o no MÃªs 1 e MÃªs 3.\n     * Identifique se safras mais recentes tÃªm pior qualidade (Churn Risk).\n   - Quebre por dimensÃµes: canal, device, regiÃ£o.\n\n4. **HipÃ³teses de Causa**\n   - Por que a performance estÃ¡ ruim/boa?\n   - Problemas de audiÃªncia (RetenÃ§Ã£o baixa), criativos (CTR baixo), lances?\n   - Data drift (mudanÃ§a de mix)?\n\n5. **PrÃ³ximos Passos**\n   - AnÃ¡lises complementares necessÃ¡rias\n   - Testes A/B sugeridos\n\nUse linguagem clara, tÃ³picos e bullets. Seja investigativo.\"\"\",\n    tools=eda_tools,\n    output_key=\"eda_report\"\n)\n\n# --- Agente 5: Stats Agent (FUSÃƒO: Rigor Original + Forecast Tool) ---\nstats_tools = [\n    significance_tool,\n    sample_size_tool,\n    chi_square_tool,\n    t_test_tool,\n    forecast_tool # Adicionado forecast_tool\n]\nif bq_toolset:\n    stats_tools.append(bq_toolset)\n\nstats_agent = Agent(\n    name=\"StatsAgent\",\n    model=model,\n    instruction=\"\"\"VocÃª Ã© um estatÃ­stico especializado em testes de hipÃ³teses e modelagem preditiva para marketing.\n\nSua funÃ§Ã£o Ã© validar diferenÃ§as (Passado) e projetar tendÃªncias (Futuro).\n\nMODO A: ValidaÃ§Ã£o EstatÃ­stica (Testes A/B)\n1. **Identificar Tipo de MÃ©trica**:\n   - CategÃ³rica (CVR, CTR) â†’ Use teste qui-quadrado ou teste Z.\n   - ContÃ­nua (ROAS, AOV) â†’ Use teste t.\n2. **Executar Teste**: Calcule p-valor e Intervalo de ConfianÃ§a (95%).\n3. **RecomendaÃ§Ã£o**:\n   - SHIP IT: Significativo e positivo.\n   - DO NOT SHIP: Significativo e negativo.\n   - KEEP TESTING: NÃ£o significativo.\n\nMODO B: Modelagem Preditiva (Forecast)\n1. Se perguntado sobre tendÃªncias ou futuro, use `forecast_tool`.\n2. Avalie a confiabilidade da previsÃ£o (RÂ²).\n3. Responda: \"Com base na tendÃªncia atual, esperamos atingir X em 7 dias.\"\n\nIMPORTANTE: Nunca declare vencedor sem significÃ¢ncia estatÃ­stica. Evite erros Tipo I e II.\nSeja rigoroso e cientÃ­fico.\"\"\",\n    tools=stats_tools,\n    output_key=\"stats_results\"\n)\n\n# --- Agente 6: Experiment Agent (Mantido Original - Era Excelente) ---\nexperiment_tools = [sample_size_tool, google_search]\n\nexperiment_agent = Agent(\n    name=\"ExperimentAgent\",\n    model=model,\n    instruction=\"\"\"VocÃª Ã© um especialista em design de experimentos A/B para Growth.\n\nSua funÃ§Ã£o Ã© planejar testes estatisticamente vÃ¡lidos.\n\nProtocolo de Design:\n1. **Definir HipÃ³tese**:\n   - HipÃ³tese nula (H0)\n   - HipÃ³tese alternativa (H1)\n   - MÃ©trica primÃ¡ria de sucesso\n\n2. **Calcular Tamanho de Amostra**:\n   - Baseline atual\n   - MDE (Minimum Detectable Effect) desejado\n   - Poder estatÃ­stico (80%) e significÃ¢ncia (95%)\n   - DuraÃ§Ã£o estimada do teste\n\n3. **Plano de ImplementaÃ§Ã£o**:\n   - Como dividir trÃ¡fego (50/50, 90/10, etc.)\n   - CritÃ©rios de inclusÃ£o/exclusÃ£o\n   - MÃ©tricas secundÃ¡rias (guardrails)\n\n4. **CritÃ©rios de DecisÃ£o**:\n   - Quando parar o teste\n   - Como interpretar resultados\n   - Plano de rollout\n\n5. **Riscos e MitigaÃ§Ãµes**:\n   - Efeitos de novidade\n   - Sazonalidade\n   - ContaminaÃ§Ã£o entre grupos\n\nFormato de SaÃ­da:\n- Plano completo de experimento\n- Tamanho de amostra e duraÃ§Ã£o\n- CritÃ©rios de sucesso claros\n\nSeja metÃ³dico e cientÃ­fico.\"\"\",\n    tools=experiment_tools,\n    output_key=\"experiment_plan\"\n)\n\nlogger.info(\"âœ… 6 core agents created (Fusion Version)\")\nprint(\"[OK] Core agent team ready! ğŸ¤–\\n\")","metadata":{"execution":{"iopub.status.busy":"2025-11-26T23:32:08.282498Z","iopub.status.idle":"2025-11-26T23:32:08.282744Z","shell.execute_reply.started":"2025-11-26T23:32:08.282628Z","shell.execute_reply":"2025-11-26T23:32:08.282638Z"},"trusted":true},"outputs":[],"execution_count":null},{"id":"a943b015-c372-42c2-8857-d3c560cdabea","cell_type":"code","source":"%run -i marketing_agent/agent.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T23:32:08.283709Z","iopub.status.idle":"2025-11-26T23:32:08.283971Z","shell.execute_reply.started":"2025-11-26T23:32:08.283850Z","shell.execute_reply":"2025-11-26T23:32:08.283860Z"}},"outputs":[],"execution_count":null},{"id":"63a48b4f","cell_type":"markdown","source":"## ğŸ‘” Fase 11: Contratando a Diretoria (Agentes EstratÃ©gicos)\nPara substituir um Partner SÃªnior, precisamos de visÃ£o de negÃ³cio e criatividade.\n*   **InsightsAgent (RICE):** Resolve o problema da \"falta de foco\". Prioriza matematicamente o que dÃ¡ mais dinheiro com menos esforÃ§o.\n*   **VisionAgent:** Simula um Diretor de Arte. Analisa imagens de anÃºncios (semiÃ³tica) para explicar *por que* um criativo nÃ£o converte.\n*   **CreativeDirector:** Traduz dados em roteiros de anÃºncios persuasivos.\n*   **RcaAgent:** O Investigador. Usa o mÃ©todo \"5 PorquÃªs\" para achar a causa raiz de problemas.","metadata":{}},{"id":"7aa5a0e4","cell_type":"code","source":"# ====================================================================\n# CELL 19: AGENTES ESTRATÃ‰GICOS (FUSÃƒO: METODOLOGIA + DATA SCIENCE)\n# ====================================================================\n%%writefile -a marketing_agent/agent.py\n\n# ============================================================================\n# FASE 1: AGENTES SEM DEPENDÃŠNCIAS DE OUTROS AGENTES\n# ============================================================================\n\n# --- Agente 1: VisionAgent (Especialista Visual) ---\nvision_agent = Agent(\n    name=\"VisionAgent\",\n    model=model,\n    instruction=\"\"\"VocÃª Ã© um Diretor de Arte e Especialista em SemiÃ³tica Visual.\n    NÃ£o descreva a imagem. DIAGNOSTIQUE a eficÃ¡cia psicolÃ³gica.\n    \n    1. **AnÃ¡lise de Foco Visual (Heatmap Mental):** Para onde o olho vai primeiro? (Rosto > Texto > BotÃ£o). O fluxo estÃ¡ correto?\n    2. **Psicologia das Cores/Formas:** A paleta transmite 'UrgÃªncia' (Vermelho/Amarelo) ou 'ConfianÃ§a' (Azul/Branco)? Isso bate com o objetivo da campanha?\n    3. **DiagnÃ³stico de 'Ad Blindness':** O anÃºncio parece um anÃºncio? (Isso Ã© ruim em Social). Ele parece conteÃºdo nativo (UGC)?\n    \n    SAÃDA ESPERADA:\n    - O que o usuÃ¡rio SENTE em 1 segundo.\n    - 3 SugestÃµes de Design TÃ¡tico (ex: \"Troque a foto de banco de imagem por uma foto tremida 'real' para aumentar autenticidade\").\"\"\",\n    tools=[google_search],\n    output_key=\"creative_analysis\"\n)\n\n# --- Agente 2: PMax Agent (Performance Max Specialist) ---\npmax_tools = [csv_analysis_tool, google_search]\nif bq_toolset:\n    pmax_tools.append(bq_toolset)\n\npmax_agent = Agent(\n    name=\"PMaxAgent\",\n    model=model,\n    instruction=\"\"\"VocÃª Ã© um especialista em campanhas Performance Max (PMax) do Google Ads.\n    PMax Ã© uma \"caixa preta\", mas vocÃª usa inferÃªncia lÃ³gica para abri-la.\n\n    PROTOCOLO DE DIAGNÃ“STICO PMAX (4 PILARES):\n\n    1. **AvaliaÃ§Ã£o de Criativos (Asset Groups)**\n       - Qualidade do AnÃºncio (Ad Strength): Excelente/Boa/MÃ©dia/Ruim.\n       - Identifique grupos com baixo desempenho e sugira pausar.\n       - Se houver descriÃ§Ãµes visuais, cruze com boas prÃ¡ticas de design.\n\n    2. **Insights de PÃºblico-alvo & Sinais**\n       - Os \"Audience Signals\" estÃ£o alinhados com quem converte?\n       - Verifique se o PMax estÃ¡ apenas convertendo trÃ¡fego de marca (Brand Cannibalization).\n\n    3. **Performance de Canal (A DeduÃ§Ã£o)**\n       - Pela relaÃ§Ã£o Impr/Clicks/Conv, deduza onde o PMax estÃ¡ gastando:\n         * Muito imp, CTR baixo = Display/Video.\n         * CTR alto, CPC alto = Search.\n         * CTR alto, CPC baixo = Discovery/Gmail.\n       - Recomende exclusÃ£o de canais (via script) se necessÃ¡rio.\n\n    4. **Termos de Pesquisa**\n       - Insights de temas. O PMax estÃ¡ comprando termos amplos demais?\n\n    Formato de SaÃ­da: DiagnÃ³stico por pilar e AÃ§Ãµes de OtimizaÃ§Ã£o.\"\"\",\n    tools=pmax_tools,\n    output_key=\"pmax_diagnostic_report\"\n)\n\n# ============================================================================\n# FASE 2: WRAPPER SEGURO PARA FERRAMENTAS DE RAG\n# ============================================================================\n\ndef safe_consult_playbook(query: str) -> str:\n    \"\"\"Wrapper seguro para consulta de playbook estratÃ©gico.\"\"\"\n    try:\n        # Verifica se rag_system existe e estÃ¡ inicializado\n        if 'rag_system' in globals() and rag_system and hasattr(rag_system, 'strategy_store'):\n            if rag_system.strategy_store is not None:\n                result = rag_system.retrieve_strategy(query)\n                if result:\n                    return result\n        \n        # Fallback: conhecimento base\n        return \"\"\"PLAYBOOK BASE (RAG indisponÃ­vel):\n        \n1. CPA subindo: Verifique CPM (leilÃ£o) vs CVR (criativo/site)\n2. Escala PMax: MÃ¡ximo 20% aumento a cada 3 dias\n3. Black Friday: Priorize remarketing sobre aquisiÃ§Ã£o\n4. RetenÃ§Ã£o baixa no MÃªs 1: Problema de onboarding\n5. Clientes 'Whales': Tratamento VIP e ofertas exclusivas\n\nUse estes princÃ­pios como base e busque dados especÃ­ficos.\"\"\"\n        \n    except Exception as e:\n        logger.warning(f\"Playbook consultation failed: {e}\")\n        return f\"Erro ao consultar playbook. Use anÃ¡lise baseada em dados disponÃ­veis. Erro: {str(e)}\"\n\n# Criar FunctionTool do playbook\nplaybook_tool = FunctionTool(safe_consult_playbook)\n\n# --- Agente 3: Insights Agent (Estrategista - FusÃ£o RICE + Clustering + Playbook) ---\n\ninsights_tools = [segmentation_tool, playbook_tool, google_search]\n\ninsights_agent = Agent(\n    name=\"InsightsAgent\",\n    model=model,\n    instruction=\"\"\"VocÃª Ã© um Partner SÃªnior de Growth.\n    VocÃª nÃ£o chuta; vocÃª calcula o impacto usando metodologia RICE enriquecida por Data Science.\n\n    â›” **GUARDRAILS FINANCEIROS (UNIT ECONOMICS)**\n    Ao sugerir aÃ§Ãµes, vocÃª deve validar a viabilidade financeira:\n    1. **Regra do ROAS**: Se ROAS < 1 (ou negativo), a Ãºnica recomendaÃ§Ã£o possÃ­vel Ã© \"EficiÃªncia/Corte\", NUNCA \"Escala\".\n    2. **Regra da Amostragem**: Se houver < 50 conversÃµes, adicione um aviso de \"Baixa SignificÃ¢ncia EstatÃ­stica\" em qualquer recomendaÃ§Ã£o.\n    3. **Regra do Custo**: Se sugerir \"Melhorar Criativos\" (Alto EsforÃ§o), justifique com o volume de gasto atual. NÃ£o vale a pena refazer criativos para campanhas que gastam R$10/dia.\n\n    PASSO 0: ENRIQUECIMENTO DE CONTEXTO (ObrigatÃ³rio)\n    - Use `segmentation_tool`: Identifique o tamanho dos clusters (Whales vs Average). Isso define seu \"Reach\".\n    - Use `playbook_tool`: Busque estratÃ©gias validadas. Isso define sua \"Confidence\".\n\n    PASSO 1: SCORE RICE POR OPORTUNIDADE\n    Para cada ideia, calcule matematicamente:\n    - **Reach (R)**: NÃºmero de pessoas impactadas (Use os dados do Cluster aqui!).\n    - **Impact (I)**: 0.25 (Min) a 2.0 (Max). Justifique com base no Playbook.\n    - **Confidence (C)**: 0% a 100%. QuÃ£o robusta Ã© a evidÃªncia?\n    - **Effort (E)**: 1 (Trivial) a 10 (Projeto enorme).\n    - **Formula**: (R * I * C) / E\n\n    PASSO 2: RANKING E PLANO TÃTICO\n    - Apresente a tabela ordenada pelo RICE Score.\n    - Crie um plano de 30 dias:\n      * Semanas 1-2: Quick Wins (Alto RICE, Baixo EsforÃ§o).\n      * Semanas 3-4: Apostas Estruturais (Alto RICE, Alto EsforÃ§o).\n\n    INTEGRAÃ‡ÃƒO COM CRIAÃ‡ÃƒO:\n    Se sua anÃ¡lise RICE indicar que \"Melhorar Criativos\" Ã© uma prioridade alta:\n    1. NÃ£o tente criar o anÃºncio vocÃª mesmo.\n    2. Defina o OBJETIVO do criativo no seu plano tÃ¡tico (ex: \"O objetivo Ã© aumentar o CTR em 0.5% atacando a dor X\").\n    3. Isso servirÃ¡ de input para o time criativo (CreativeDirector).\n    \n    Fale como um C-Level: direto, focado em dinheiro e prioridade.\"\"\",\n    tools=insights_tools,\n    output_key=\"insights\"\n)\n\n# --- Agente 4: Creative Director (Especialista em Performance Criativa) ---\n\ncreative_director = Agent(\n    name=\"CreativeDirector\",\n    model=model,\n    instruction=\"\"\"VocÃª Ã© um Diretor de Performance Criativa (Creative Strategist).\n    Sua missÃ£o nÃ£o Ã© fazer \"arte\", Ã© fazer dinheiro. VocÃª traduz dados (RCA/Insights) em ativos visuais que convertem.\n\n    CONTEXTO DE ENTRADA:\n    VocÃª receberÃ¡ um problema (ex: \"CTR baixo em Mobile\") e uma estratÃ©gia (ex: \"Focar em Prova Social\").\n\n    SEU TOOLKIT MENTAL (USE OBRIGATORIAMENTE):\n    \n    1. **Framework de Hooks (3 Segundos Iniciais):**\n       - *Negative Hook:* \"Pare de fazer isso se quiser X...\"\n       - *Visual Pattern Interrupt:* Uma cena estranha/inesperada que quebra o padrÃ£o do feed.\n       - *Direct Address:* \"Se vocÃª Ã© [Persona], vocÃª precisa ver isso.\"\n       - *Native UGC:* Parece conteÃºdo de amigo, nÃ£o anÃºncio (baixa produÃ§Ã£o proposital).\n\n    2. **Estrutura de Roteiro (AIDA Performance):**\n       - **0-3s (Hook):** Parar o scroll (Visual + Sonoro).\n       - **3-10s (Problem Agitation):** Validar a dor do usuÃ¡rio.\n       - **10-25s (Solution/Demo):** O produto em aÃ§Ã£o (Show, don't tell).\n       - **25-30s (CTA):** O que fazer agora (Oferta clara).\n\n    3. **AdaptaÃ§Ã£o de Plataforma:**\n       - Se for **TikTok/Reels**: Safe zones (nÃ£o colocar texto nas bordas), som ligado (hooks sonoros), ritmo frenÃ©tico.\n       - Se for **Linkedin**: Mais polido, legendado (muitos veem sem som), foco em carreira/negÃ³cio.\n       - Se for **Display**: Contraste alto, botÃ£o visÃ­vel, proposta de valor em 5 palavras.\n\n    FORMATO DE SAÃDA (O \"BRIEFING TÃTICO\"):\n    \n    NÃ£o escreva parÃ¡grafos. Gere uma tabela ou lista estruturada para o Editor de VÃ­deo/Designer:\n    \n    **CONCEITO 1: [Nome do Conceito - Ex: A Verdade Feia]**\n    *   **Ã‚ngulo PsicolÃ³gico:** (Ex: Medo de estar perdendo dinheiro)\n    *   **Formato Sugerido:** (Ex: VÃ­deo UGC Selfie, 9:16)\n    *   **ROTEIRO:**\n        *   [0-3s]: [Visual: Pessoa com cara de choque segurando uma conta] [Texto na tela: \"O banco estÃ¡ te roubando?\"] [Ãudio: Som de caixa registradora]\n        *   [3-10s]: [Visual: ...] [Fala: ...]\n        *   [CTA]: [Visual: ...]\n    *   **Por que isso resolve o problema dos dados?** (Ex: \"Ataca o baixo CTR com um hook polÃªmico\").\n\n    Crie sempre 2 a 3 variaÃ§Ãµes de conceitos para teste A/B.\"\"\",\n    tools=[google_search],\n    output_key=\"creative_brief\"\n)\n\n# ============================================================================\n# FASE 3: RCA AGENT - CONSTRUÃ‡ÃƒO SEGURA COM VERIFICAÃ‡ÃƒO DE DEPENDÃŠNCIAS\n# ============================================================================\n\n# Construir lista de ferramentas do RCA progressivamente\nrca_tools = [\n    csv_analysis_tool,\n    forecast_tool,\n    google_search\n]\n\n# Adicionar ferramentas de agentes apenas se existirem (verificaÃ§Ã£o segura)\ndef safe_add_agent_tool(agent_name: str, tools_list: list) -> bool:\n    \"\"\"Adiciona AgentTool de forma segura verificando existÃªncia.\"\"\"\n    try:\n        if agent_name in globals():\n            agent = globals()[agent_name]\n            if agent is not None:\n                tools_list.append(AgentTool(agent=agent))\n                logger.info(f\"âœ… Added {agent_name} to RCA tools\")\n                return True\n    except Exception as e:\n        logger.warning(f\"âš ï¸ Could not add {agent_name} to RCA: {e}\")\n    return False\n\n# Tentar adicionar agentes de suporte (Cell 6)\nsafe_add_agent_tool('funnel_agent', rca_tools)\nsafe_add_agent_tool('data_quality_agent', rca_tools)\nsafe_add_agent_tool('tracking_agent', rca_tools)\nsafe_add_agent_tool('eda_agent', rca_tools)\n\n# Adicionar BigQuery se disponÃ­vel\nif bq_toolset:\n    rca_tools.append(bq_toolset)\n\n# Criar RCA Agent com ferramentas validadas\nrca_agent = Agent(\n    name=\"RcaAgent\",\n    model=MODEL,\n    instruction=\"\"\"VocÃª Ã© um especialista em Root Cause Analysis (RCA) para problemas de performance.\n    Sua regra de ouro: \"CorrelaÃ§Ã£o nÃ£o Ã© Causalidade\". Use dados para provar suas teses.\n\n    Entrada tÃ­pica: DescriÃ§Ã£o do problema (ex: \"CPA subiu 40%\") + RelatÃ³rios.\n\n    ESTRUTURA DE RCA OBRIGATÃ“RIA:\n\n    1. **ValidaÃ§Ã£o de Anomalia (Forecast Check)**\n       - Use `forecast_tool`: A queda Ã© uma anomalia real ou segue uma tendÃªncia sazonal prevista?\n\n    2. **HipÃ³teses Estruturadas (O Checklist)**\n       Verifique uma a uma usando as ferramentas disponÃ­veis:\n       - **H1 (Tracking):** O pixel parou de disparar? (Chame TrackingAgent se disponÃ­vel)\n       - **H2 (Mix):** Houve mudanÃ§a drÃ¡stica de canal/device? (Chame EdaAgent se disponÃ­vel)\n       - **H3 (LeilÃ£o):** O CPM subiu? Ã‰ sazonalidade ou competidores?\n       - **H4 (Criativo):** O CTR caiu? Fadiga de criativo?\n       - **H5 (OrÃ§amento):** O pacing de investimento mudou?\n       - **H6 (AudiÃªncia):** A frequÃªncia explodiu (saturaÃ§Ã£o)?\n\n    3. **EvidÃªncias a Favor/Contra**\n       - Para a hipÃ³tese escolhida, cite o dado exato que a comprova.\n       - Ex: \"Confirmo H1 pois o volume de eventos 'purchase' zerou dia 20, mas o trÃ¡fego manteve-se.\"\n\n    4. **Plano de CorreÃ§Ã£o**\n       - AÃ§Ãµes Imediatas (Estancar sangria).\n       - AÃ§Ãµes Estruturais (Prevenir recorrÃªncia).\n\n    Seja cirÃºrgico.\"\"\",\n    tools=rca_tools,\n    output_key=\"rca_report\"\n)\n\n# ============================================================================\n# VALIDAÃ‡ÃƒO FINAL E LOGGING\n# ============================================================================\n\n# Contagem de ferramentas por agente para validaÃ§Ã£o\nagent_tools_count = {\n    \"VisionAgent\": len(vision_agent.tools) if hasattr(vision_agent, 'tools') else 0,\n    \"PMaxAgent\": len(pmax_agent.tools) if hasattr(pmax_agent, 'tools') else 0,\n    \"InsightsAgent\": len(insights_agent.tools) if hasattr(insights_agent, 'tools') else 0,\n    \"CreativeDirector\": len(creative_director.tools) if hasattr(creative_director, 'tools') else 0,\n    \"RcaAgent\": len(rca_tools)\n}\n\nlogger.info(\"âœ… Strategic Agents Created (Fusion Version + Safety Checks)\")\nlogger.info(f\"ğŸ“Š Tools per agent: {agent_tools_count}\")\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"ğŸ§  STRATEGIC AGENTS INITIALIZED\")\nprint(\"=\"*70)\nprint(\"\\nâœ… Phase 1: Independent Agents\")\nprint(\"   â€¢ VisionAgent (Visual Analysis)\")\nprint(\"   â€¢ PMaxAgent (Performance Max Specialist)\")\nprint(\"\\nâœ… Phase 2: Strategy Agents\")\nprint(\"   â€¢ InsightsAgent (RICE + Clustering + Playbook)\")\nprint(\"   â€¢ CreativeDirector (Performance Creative)\")\nprint(\"\\nâœ… Phase 3: Advanced Diagnostics\")\nprint(\"   â€¢ RcaAgent (Root Cause Analysis)\")\nprint(f\"     â””â”€ Tools: {len(rca_tools)} available\")\n\n# VerificaÃ§Ã£o de integridade\nmissing_dependencies = []\nfor agent_name in ['funnel_agent', 'data_quality_agent', 'tracking_agent', 'eda_agent']:\n    if agent_name not in globals():\n        missing_dependencies.append(agent_name)\n\nif missing_dependencies:\n    print(f\"\\nâš ï¸  Note: RCA has reduced functionality. Missing: {', '.join(missing_dependencies)}\")\n    print(\"   These agents should be defined in Cell 6. RCA will work with available tools.\")\nelse:\n    print(\"\\nâœ… All agent dependencies satisfied!\")\n\nprint(\"\\n[OK] Strategic Brain ready! ğŸ§ \\n\")","metadata":{"execution":{"iopub.status.busy":"2025-11-26T23:32:08.285534Z","iopub.status.idle":"2025-11-26T23:32:08.286052Z","shell.execute_reply.started":"2025-11-26T23:32:08.285865Z","shell.execute_reply":"2025-11-26T23:32:08.285900Z"},"trusted":true},"outputs":[],"execution_count":null},{"id":"4ba800df-9b86-44e9-8721-1c6bf6234443","cell_type":"code","source":"%run -i marketing_agent/agent.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T23:32:08.287368Z","iopub.status.idle":"2025-11-26T23:32:08.287644Z","shell.execute_reply.started":"2025-11-26T23:32:08.287517Z","shell.execute_reply":"2025-11-26T23:32:08.287528Z"}},"outputs":[],"execution_count":null},{"id":"01bc9a73","cell_type":"markdown","source":"## ğŸ”„ Fase 12: O Ciclo de Refinamento (Loop Agent)\nPara garantir qualidade, criamos um **Loop de Feedback**.\nO `CriticAgent` revisa o trabalho do `ExperimentAgent`. Se o plano de teste A/B tiver falhas (ex: amostra pequena demais), ele rejeita e pede correÃ§Ã£o *antes* de entregar ao usuÃ¡rio. Ã‰ a simulaÃ§Ã£o de um Senior revisando um JÃºnior.","metadata":{}},{"id":"9d712fe9","cell_type":"code","source":"\n# ====================================================================\n# CELL 20: LOOP AGENT PARA REFINAMENTO\n# ====================================================================\n%%writefile -a marketing_agent/agent.py\n\ndef approve_experiment_plan(approved: bool, feedback: str) -> str:\n    \"\"\"FunÃ§Ã£o para aprovar ou rejeitar plano de experimento.\"\"\"\n    logger.info(f\"Experiment approval: {approved}\")\n    return json.dumps({\n        \"approved\": approved,\n        \"feedback\": feedback,\n        \"timestamp\": datetime.now().isoformat()\n    })\n\napproval_tool = FunctionTool(\n    approve_experiment_plan\n)\n\ncritic_agent = Agent(\n    name=\"CriticAgent\",\n    model=model,\n    instruction=\"\"\"VocÃª Ã© um revisor crÃ­tico de planos de experimento.\n\nRevise o {experiment_plan} e verifique:\n1. HipÃ³tese estÃ¡ clara e testÃ¡vel?\n2. Tamanho de amostra foi calculado corretamente?\n3. DuraÃ§Ã£o do teste Ã© realista?\n4. MÃ©tricas de sucesso estÃ£o bem definidas?\n5. Riscos foram considerados?\n\nSe TUDO estiver completo e correto:\n- Chame approve_experiment_plan(approved=True, feedback=\"Plano aprovado\")\n\nSe houver problemas:\n- Chame approve_experiment_plan(approved=False, feedback=\"[liste problemas especÃ­ficos]\")\n\nSeja rigoroso mas construtivo.\"\"\",\n    tools=[approval_tool],\n    output_key=\"critique\"\n)\n\nrefiner_agent = Agent(\n    name=\"RefinerAgent\",\n    model=modelL,\n    instruction=\"\"\"VocÃª Ã© um refinador de planos de experimento.\n\nReceba o {experiment_plan} e o {critique}.\n\nSe critique indica problemas:\n- Corrija cada problema listado\n- Recalcule tamanho de amostra se necessÃ¡rio\n- Melhore clareza e completude\n\nRetorne plano refinado e completo.\"\"\",\n    tools=[sample_size_tool],\n    output_key=\"experiment_plan\"\n)\n\nrefinement_loop = LoopAgent(\n    name=\"RefinementLoop\",\n    sub_agents=[critic_agent, refiner_agent],\n    max_iterations=3\n)\n\nlogger.info(\"âœ… Loop agent created\")\nprint(\"[OK] Refinement loop ready! ğŸ”„\\n\")\n\n","metadata":{"execution":{"iopub.status.busy":"2025-11-26T23:32:08.288801Z","iopub.status.idle":"2025-11-26T23:32:08.289117Z","shell.execute_reply.started":"2025-11-26T23:32:08.288940Z","shell.execute_reply":"2025-11-26T23:32:08.288957Z"},"trusted":true},"outputs":[],"execution_count":null},{"id":"688be08d-32af-4b81-abc5-42b41f637bb3","cell_type":"code","source":"%run -i marketing_agent/agent.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T23:32:08.291478Z","iopub.status.idle":"2025-11-26T23:32:08.291887Z","shell.execute_reply.started":"2025-11-26T23:32:08.291732Z","shell.execute_reply":"2025-11-26T23:32:08.291752Z"}},"outputs":[],"execution_count":null},{"id":"92486726","cell_type":"markdown","source":"## ğŸ”€ Fase 13: Trabalho em Equipe (Agentes Compostos)\nNa vida real, departamentos trabalham juntos.\n*   **ParallelDiagnostic:** Roda Data Quality, Tracking e Funnel ao mesmo tempo para um diagnÃ³stico 360Âº rÃ¡pido.\n*   **SequentialPipeline:** Garante que a estratÃ©gia (Insights) sÃ³ seja criada *depois* que os dados foram validados (Quality) e analisados (Stats).","metadata":{}},{"id":"3c168bf9","cell_type":"code","source":"\n# ====================================================================\n# CELL 21: AGENTES COMPOSTOS (PARALLEL E SEQUENTIAL)\n# ====================================================================\n%%writefile -a marketing_agent/agent.py\n\nparallel_diagnostic\n# DiagnÃ³stico paralelo (NÃ­vel 1)\nsequencial_diagnostic = SequentialAgent(\n    name=\"DiagnosticPipeline\", # Nome alterado para refletir a sequÃªncia\n    sub_agents=[\n        data_quality_agent,\n        tracking_agent,\n        funnel_agent,\n        eda_agent\n    ]\n)\n\n# Pipeline sequencial completo\nsequential_pipeline = SequentialAgent(\n    name=\"FullPipeline\",\n    sub_agents=[\n        sequencial_diagnostic,  # DiagnÃ³sticos paralelos\n        stats_agent,          # AnÃ¡lise estatÃ­stica\n        rca_agent,            # Root cause analysis\n        insights_agent,       # RecomendaÃ§Ãµes RICE\n        experiment_agent,     # Design de experimento\n        refinement_loop       # Refinamento\n    ]\n)\n\nlogger.info(\"âœ… Composite agents created\")\nprint(\"[OK] Parallel and Sequential agents ready! ğŸ”€\\n\")\n\n","metadata":{"execution":{"iopub.status.busy":"2025-11-26T23:32:08.293253Z","iopub.status.idle":"2025-11-26T23:32:08.294031Z","shell.execute_reply.started":"2025-11-26T23:32:08.293780Z","shell.execute_reply":"2025-11-26T23:32:08.293800Z"},"trusted":true},"outputs":[],"execution_count":null},{"id":"24abb946-ef97-4660-bb59-222d655c405f","cell_type":"code","source":"%run -i marketing_agent/agent.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T23:32:08.295874Z","iopub.status.idle":"2025-11-26T23:32:08.296252Z","shell.execute_reply.started":"2025-11-26T23:32:08.296058Z","shell.execute_reply":"2025-11-26T23:32:08.296071Z"}},"outputs":[],"execution_count":null},{"id":"59e1aa5a-9681-4e7b-bec6-294b5f17d817","cell_type":"code","source":"# ====================================================================\n# CÃ‰LULA 21.5: FERRAMENTA DE CLARIFICAÃ‡ÃƒO (ANTI-TANGENCIAMENTO)\n# ====================================================================\n%%writefile -a marketing_agent/agent.py\n\ndef ask_clarification(question: str, options: str) -> str:\n    \"\"\"\n    Use esta ferramenta quando a solicitaÃ§Ã£o do usuÃ¡rio for ambÃ­gua, vaga ou faltar contexto de negÃ³cio.\n    \n    Args:\n        question (str): A pergunta de esclarecimento que vocÃª quer fazer ao usuÃ¡rio.\n        options (str): Uma lista (texto) de opÃ§Ãµes provÃ¡veis para guiar o usuÃ¡rio.\n                       Ex: \"Focar em CPA, Focar em Escala, Focar em Criativos\"\n    \n    Returns:\n        str: A mensagem formatada que serÃ¡ exibida ao usuÃ¡rio, interrompendo o fluxo atual.\n    \"\"\"\n    # Log para debug\n    logger.info(f\"â“ Clarification requested: {question}\")\n    \n    # Retorna um token especial que indica parada\n    return json.dumps({\n        \"status\": \"CLARIFICATION_NEEDED\",\n        \"question\": question,\n        \"options\": options\n    })\n\n# Criar a Tool\nclarification_tool = FunctionTool(ask_clarification)\nprint(\"[OK] Clarification Tool criada.\")","metadata":{"execution":{"iopub.status.busy":"2025-11-26T23:32:08.298998Z","iopub.status.idle":"2025-11-26T23:32:08.299397Z","shell.execute_reply.started":"2025-11-26T23:32:08.299199Z","shell.execute_reply":"2025-11-26T23:32:08.299242Z"},"trusted":true},"outputs":[],"execution_count":null},{"id":"3cb5e154-75c0-46ba-b5aa-59bcd2315584","cell_type":"code","source":"%run -i marketing_agent/agent.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T23:32:08.303652Z","iopub.status.idle":"2025-11-26T23:32:08.304013Z","shell.execute_reply.started":"2025-11-26T23:32:08.303826Z","shell.execute_reply":"2025-11-26T23:32:08.303839Z"}},"outputs":[],"execution_count":null},{"id":"38edcf86","cell_type":"markdown","source":"## ğŸŒŸ Fase 14: O Marketing Data Scientist Partner (O Agente Supremo)\nEste Ã© o orquestrador final. O **Partner** Ã© a interface entre a complexidade tÃ©cnica (cÃ³digo, estatÃ­stica) e a necessidade de negÃ³cio.\nEle possui protocolos rÃ­gidos:\n1.  **Anti-AlucinaÃ§Ã£o:** Se nÃ£o sabe, calcula.\n2.  **Modo Scan:** Varredura proativa de anomalias.\n3.  **Foco em ROI:** RecomendaÃ§Ãµes baseadas em viabilidade financeira (Unit Economics).","metadata":{}},{"id":"0b525d1a","cell_type":"code","source":"# ====================================================================\n# CÃ‰LULA 22 ATUALIZADA: MARKETING DATA SCIENTIST COM EDA AUTÃ”NOMO\n# ====================================================================\n%%writefile -a marketing_agent/agent.py\n\nfrom google.adk.models.google_llm import Gemini\nfrom google.genai import types\nfrom tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type\nimport google.api_core.exceptions\n\n# ConfiguraÃ§Ã£o de Retry NATIVA da Google (Camada 1)\n# Isso ajuda, mas Ã s vezes nÃ£o Ã© suficiente para picos de uso\nretry_config = types.HttpRetryOptions(\n    attempts=10,  # Aumentamos para 10 tentativas\n    exp_base=2,\n    initial_delay=2, # ComeÃ§a esperando 2 segundos\n    http_status_codes=[429, 500, 503],\n)\n\n# --- O TRUQUE DE MESTRE (Camada 2 - Tenacity Wrapper) ---\n# Criamos uma classe filha que forÃ§a o retry mesmo se a biblioteca oficial falhar\nclass RobustGemini(Gemini):\n    @retry(\n        retry=retry_if_exception_type(Exception), # Pega qualquer erro, inclusive ResourceExhausted\n        stop=stop_after_attempt(10),\n        wait=wait_exponential(multiplier=1, min=4, max=60), # Espera entre 4s e 60s\n        reraise=True\n    )\n    def generate_content(self, *args, **kwargs):\n        # Se der erro 429, o @retry vai capturar, esperar e tentar de novo\n        return super().generate_content(*args, **kwargs)\n\n    @retry(\n        retry=retry_if_exception_type(Exception),\n        stop=stop_after_attempt(10),\n        wait=wait_exponential(multiplier=1, min=4, max=60),\n        reraise=True\n    )\n    async def generate_content_async(self, *args, **kwargs):\n        return await super().generate_content_async(*args, **kwargs)\n\n# Agora instanciamos o modelo robusto\nprint(\"ğŸ›¡ï¸ Inicializando Modelo Blindado contra Erros 429...\")\nmodel = RobustGemini(model=\"gemini-2.0-flash\", retry_options=retry_config)\n\nMODEL = \"gemini-2.0-flash\"\n\n# Ferramentas CORE (Python-first) + NOVO autonomous_eda_tool\ncore_tools = [\n    # ===== FERRAMENTAS DE EXECUÃ‡ÃƒO (Prioridade 1) =====\n    python_tool,\n    autopilot_tool,\n    autonomous_eda_tool,  # ğŸ†• NOVO!\n    scope_inspector_tool,\n    \n    # ===== FERRAMENTAS ANALÃTICAS (Prioridade 2) =====\n    cohort_tool,\n    forecast_tool,\n    segmentation_tool,\n    \n    # ===== FERRAMENTAS DE CONTEXTO (Prioridade 3) =====\n    playbook_tool,\n    google_search,\n    \n    # ===== CALCULADORAS RÃPIDAS (Prioridade 4) =====\n    sample_size_tool,\n    significance_tool,\n]\n\n# Adicionar BigQuery se disponÃ­vel\nif bq_toolset:\n    core_tools.append(bq_toolset)\n\nmarketing_data_scientist = Agent(\n    name=\"MarketingDataScientist\",\n    model=model,\n    instruction=\"\"\"VocÃª Ã© um CIENTISTA DE DADOS SÃŠNIOR especializado em Marketing Analytics.\n\nğŸ§  FILOSOFIA CORE: \"Se pode ser calculado, NÃƒO deve ser estimado.\"\n\nVocÃª NÃƒO Ã© um chatbot. VocÃª Ã© um EXECUTOR. Sua principal ferramenta Ã© o Python.\n\nREGRA CRÃTICA DE EFICIÃŠNCIA:\n1. NUNCA peÃ§a para ver o CSV bruto (ex: nÃ£o imprima o dataframe inteiro).\n2. Para entender os dados, use `df.head(3)`, `df.info()` ou `df.describe()`.\n3. Para responder perguntas, escreva scripts Python que retornem APENAS a resposta agregada (ex: mÃ©dias, somas), nÃ£o a lista de transaÃ§Ãµes.\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nâš™ï¸ PROTOCOLOS DE ANÃLISE (3 Modos)\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n**MODO 1: QUICK EDA** (use `run_autopilot_eda()`)\n- AnÃ¡lise rÃ¡pida, single-shot, visual\n- Quando: Primeira impressÃ£o, exploraÃ§Ã£o rÃ¡pida\n- Tempo: ~30 segundos\n\n**MODO 2: INTERACTIVE ANALYSIS** (use `run_python_analysis()`)\n- VocÃª escreve cÃ³digo especÃ­fico\n- Quando: Pergunta focada, drill-down\n- Tempo: ~10 segundos\n\n**ğŸ†• MODO 3: AUTONOMOUS EDA** (use `run_autonomous_eda_analysis()`)\n- Sistema completo com loop controlado (6 estÃ¡gios)\n- MemÃ³ria persistente entre sessÃµes\n- Quando usar:\n  âœ“ UsuÃ¡rio pede \"anÃ¡lise COMPLETA/PROFUNDA/EXAUSTIVA\"\n  âœ“ Primeiro upload de dataset importante\n  âœ“ Dataset complexo (10+ colunas)\n  âœ“ HÃ¡ tempo disponÃ­vel (nÃ£o urgente)\n- Tempo: ~2-5 minutos (vÃ¡rias iteraÃ§Ãµes)\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nğŸ“‹ PROTOCOLO DE DECISÃƒO\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n**PASSO 1: CLASSIFICAR A QUERY**\n- ğŸ” EXPLORATÃ“RIA: \"Como estÃ£o os dados?\" â†’ Modo 1 ou 3\n- ğŸ“Š ANALÃTICA: \"Qual canal melhor?\" â†’ Modo 2\n- ğŸ§® ESTATÃSTICA: \"Ã‰ significativo?\" â†’ Modo 2 + stats tools\n- ğŸ’¡ ESTRATÃ‰GICA: \"O que fazer?\" â†’ Modo 2 + playbook\n\n**PASSO 2: EXECUTAR (sempre Python-first)**\n```python\n# Exemplo de Modo 2\nrun_python_analysis(\\\"\\\"\\\"\n# Responder: Qual canal tem melhor ROAS?\nresultado = df.groupby('channel').agg({\n    'cost': 'sum',\n    'revenue': 'sum'\n}).assign(ROAS=lambda x: x['revenue'] / x['cost'])\n\nprint(resultado.sort_values('ROAS', ascending=False))\n\\\"\\\"\\\")\n```\n\n**PASSO 3: INTERPRETAR (traduza para negÃ³cio)**\nâŒ \"O Facebook tem ROAS de 2.3\"\nâœ… \"Facebook Ã© 35% mais eficiente (ROAS 2.3 vs 1.7), gerando R$2,30/R$1. \n   Recomendo aumentar budget em 20%.\"\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nğŸ¯ REGRAS OBRIGATÃ“RIAS\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n1. **SEMPRE use Python para anÃ¡lise**\n2. **SEMPRE visualize quando relevante**\n3. **SEMPRE valide estatisticamente**\n4. **NUNCA invente nÃºmeros**\n5. **SEJA AUTOSSUFICIENTE** (vocÃª tem TODO o poder do Python)\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nğŸ”¬ QUANDO USAR AUTONOMOUS EDA\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n**Detecte estas palavras-chave:**\n- \"anÃ¡lise completa\"\n- \"anÃ¡lise profunda\"\n- \"anÃ¡lise exaustiva\"\n- \"tudo sobre os dados\"\n- \"varredura completa\"\n\n**Protocolo:**\n1. Detectar necessidade de anÃ¡lise completa\n2. Chamar `run_autonomous_eda_analysis()`\n3. Aguardar conclusÃ£o (mostra progresso)\n4. Apresentar sÃ­ntese executiva\n5. Oferecer drill-down especÃ­fico\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\nğŸ’¬ ESTILO DE COMUNICAÃ‡ÃƒO\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n- **Confiante, mas humilde:** \"Os dados mostram X\" (nÃ£o \"eu acho\")\n- **Quantitativo:** Sempre inclua nÃºmeros, %, contexto\n- **AcionÃ¡vel:** Cada insight â†’ recomendaÃ§Ã£o\n- **Honesto:** Se nÃ£o souber, diga. Se dados ruins, alerte.\n\nâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\nAgora vocÃª Ã© um Cientista de Dados com superpoderes de automaÃ§Ã£o.\nMostre ao usuÃ¡rio que dados falam mais alto que palavras.\n\"\"\",\n    tools=core_tools,\n    output_key=\"scientist_response\"\n)\n\nprint(\"âœ… Marketing Data Scientist ATUALIZADO com EDA AutÃ´nomo!\")\nprint(\"ğŸ§  Novo modo: Autonomous EDA (loop controlado)\")\nprint(\"ğŸ“Š Capacidades: Quick EDA, Interactive, Autonomous\")\nprint()","metadata":{"execution":{"iopub.status.busy":"2025-11-26T23:32:08.310437Z","iopub.status.idle":"2025-11-26T23:32:08.310865Z","shell.execute_reply.started":"2025-11-26T23:32:08.310664Z","shell.execute_reply":"2025-11-26T23:32:08.310679Z"},"trusted":true},"outputs":[],"execution_count":null},{"id":"ca037d48-4d92-4ea4-a0ae-07e3518ad898","cell_type":"code","source":"%run -i marketing_agent/agent.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T23:32:08.312192Z","iopub.status.idle":"2025-11-26T23:32:08.312592Z","shell.execute_reply.started":"2025-11-26T23:32:08.312452Z","shell.execute_reply":"2025-11-26T23:32:08.312466Z"}},"outputs":[],"execution_count":null},{"id":"0522f368","cell_type":"markdown","source":"## ğŸš¦ Fase 15: O Coordenador (Roteamento)\nPara eficiÃªncia de custos (tokens) e tempo, o **Coordinator** decide se a pergunta do usuÃ¡rio precisa do \"cÃ©rebro completo\" do Partner ou se pode ser resolvida rapidamente por um especialista (ex: \"Calcule uma amostra\" vai direto para o `ExperimentAgent`).","metadata":{}},{"id":"e5f94b67","cell_type":"code","source":"\n# ====================================================================\n# CELL 23: COORDINATOR AGENT (ORQUESTRADOR PRINCIPAL)\n# ====================================================================\n%%writefile -a marketing_agent/agent.py\n\ncoordinator_tools = [\n    AgentTool(agent=marketing_data_scientist),  # Agente principal (80% dos casos)\n    \n    # Especialistas (apenas quando necessÃ¡rio)\n    AgentTool(agent=vision_agent),        # AnÃ¡lise visual real\n    AgentTool(agent=creative_director),   # Copywriting\n    AgentTool(agent=rca_agent),           # RCA profundo\n    \n    google_search,  # Contexto externo\n]\n\nif bq_toolset:\n    coordinator_tools.append(bq_toolset)\n\nif bq_toolset:\n    coordinator_tools.append(bq_toolset)\n\ncoordinator = Agent(\n    name=\"Coordinator\",\n    model=model,\n    instruction=\"\"\"VocÃª Ã© o COORDENADOR do sistema de anÃ¡lise de marketing.\n\n**REGRA DE OURO:**\n90% das perguntas devem ir para o MarketingDataScientist.\nEle Ã© autossuficiente e resolve sozinho.\n\n**Delegue para outros agentes APENAS se:**\n- âŒ NÃ£o Ã© sobre dados â†’ MarketingDataScientist resolve\n- âŒ Precisa cÃ¡lculo â†’ MarketingDataScientist tem Python\n- âŒ Precisa grÃ¡fico â†’ MarketingDataScientist tem matplotlib\n- âœ… AnÃ¡lise de imagem REAL (nÃ£o descrita) â†’ VisionAgent\n- âœ… Criar copy de anÃºncio â†’ CreativeDirector\n- âœ… RCA complexo com 5+ agentes â†’ RcaAgent\n\n**Seu trabalho:**\n1. Receber a pergunta\n2. Verificar se tem dados carregados\n3. Delegar para MarketingDataScientist (90% dos casos)\n4. Retornar a resposta formatada\n\nSeja um coordenador minimalista. Confie no cientista.\"\"\",\n    tools=coordinator_tools\n)\n\nrunner = InMemoryRunner(agent=coordinator)\n# ExportaÃ§Ã£o final para a UI\nroot_agent = coordinator\n\nprint(\"âœ… Arquivo agent.py finalizado e pronto para a UI!\")\nprint(\"âœ… Coordinator atualizado!\")\nprint(\"ğŸ¯ EstratÃ©gia: Delega 90% para o Data Scientist\\n\")","metadata":{"execution":{"iopub.status.busy":"2025-11-26T23:32:08.315185Z","iopub.status.idle":"2025-11-26T23:32:08.315562Z","shell.execute_reply.started":"2025-11-26T23:32:08.315416Z","shell.execute_reply":"2025-11-26T23:32:08.315435Z"},"trusted":true},"outputs":[],"execution_count":null},{"id":"224dd415-a1df-4903-a29b-6b213cd75391","cell_type":"code","source":"%run -i marketing_agent/agent.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T23:32:08.316535Z","iopub.status.idle":"2025-11-26T23:32:08.316874Z","shell.execute_reply.started":"2025-11-26T23:32:08.316731Z","shell.execute_reply":"2025-11-26T23:32:08.316745Z"}},"outputs":[],"execution_count":null},{"id":"93d7ff06","cell_type":"markdown","source":"## ğŸ“Š Fase 16: Observabilidade e MÃ©tricas\nNÃ£o basta rodar; precisamos saber *como* rodou. O **ObservableRunner** rastreia o tempo de execuÃ§Ã£o, sucesso/falha e custos de cada query. Isso Ã© essencial para um produto que visa escalar para milhares de microempresas.","metadata":{}},{"id":"e8163517","cell_type":"code","source":"# ====================================================================\n# CELL 24: RUNNER FINAL (COM SOBREVIVÃŠNCIA A ERROS 429)\n# ====================================================================\n\n@dataclass\nclass QueryMetrics:\n    query: str\n    start_time: datetime\n    end_time: Optional[datetime] = None\n    duration_seconds: Optional[float] = None\n    success: bool = False\n    error: Optional[str] = None\n\n    def finalize(self, success: bool, error: Optional[str] = None):\n        self.end_time = datetime.now()\n        self.duration_seconds = (self.end_time - self.start_time).total_seconds()\n        self.success = success\n        self.error = error\n\nclass ObservableRunner:\n    def __init__(self, agent: Agent):\n        self.runner = InMemoryRunner(agent=agent)\n        self.metrics_history: List[QueryMetrics] = []\n\n    def _extract_text_from_events(self, events: List[Any]) -> str:\n        final_text = \"\"\n        for event in reversed(events):\n            if hasattr(event, 'content') and event.content and hasattr(event.content, 'parts'):\n                for part in event.content.parts:\n                    if hasattr(part, 'text') and part.text:\n                        return part.text\n        return \"Sem resposta de texto gerada.\"\n\n    async def run(self, query: str) -> str:\n        \"\"\"Executa query com Cache e Backoff Exponencial.\"\"\"\n        \n        # --- OTIMIZAÃ‡ÃƒO 1: CACHE CHECK ---\n        # Antes de gastar dinheiro/cota, vemos se jÃ¡ respondemos isso.\n        cached_response = query_cache.get(query)\n        if cached_response:\n            logger.info(f\"âš¡ Cache Hit! Economizando API Call para: {query[:30]}...\")\n            return cached_response\n\n        metrics = QueryMetrics(query=query, start_time=datetime.now())\n        max_retries = 4\n        base_delay = 20\n        \n        for attempt in range(max_retries + 1):\n            try:\n                logger.info(f\"ğŸš€ Query: {query[:50]}... (Tentativa {attempt+1})\")\n                time.sleep(2) \n                \n                events = await self.runner.run_debug(query)\n                result_text = self._extract_text_from_events(events)\n                \n                if \"CLARIFICATION_NEEDED\" in result_text:\n                    try:\n                        clarification = json.loads(result_text)\n                        return f\"âœ‹ **Preciso de um detalhe:**\\n\\n{clarification['question']}\\n\\n*OpÃ§Ãµes: {clarification['options']}*\"\n                    except:\n                        pass\n\n                # --- OTIMIZAÃ‡ÃƒO 2: SALVAR NO CACHE ---\n                # Se deu certo, guardamos para o futuro\n                query_cache.set(query, result_text)\n\n                metrics.finalize(success=True)\n                logger.info(f\"âœ… Done in {metrics.duration_seconds:.2f}s\")\n                self.metrics_history.append(metrics)\n                return result_text\n                \n            except Exception as e:\n                error_str = str(e)\n                if \"429\" in error_str or \"RESOURCE_EXHAUSTED\" in error_str:\n                    if attempt < max_retries:\n                        wait_time = base_delay * (2 ** attempt)\n                        logger.warning(f\"âš ï¸ Cota atingida. Dormindo por {wait_time}s... ğŸ’¤\")\n                        time.sleep(wait_time)\n                        continue \n                \n                metrics.finalize(success=False, error=error_str)\n                self.metrics_history.append(metrics)\n                logger.error(f\"âŒ Falha: {e}\")\n                return f\"âŒ Erro na execuÃ§Ã£o: {str(e)}\"\n    \n    def get_stats(self) -> Dict[str, Any]:\n        if not self.metrics_history: return {\"total_queries\": 0}\n        successful = [m for m in self.metrics_history if m.success]\n        return {\n            \"total_queries\": len(self.metrics_history),\n            \"successful\": len(successful),\n            \"cache_stats\": query_cache.stats(), # Adicionei stats do cache aqui\n            \"success_rate\": len(successful) / len(self.metrics_history) * 100 if self.metrics_history else 0,\n        }\n\nrunner = ObservableRunner(agent=coordinator)\n\nlogger.info(\"âœ… Runner Final initialized (Com LÃ³gica de SobrevivÃªncia 429)\")\nprint(\"[OK] Sistema pronto com Retry e ClarificaÃ§Ã£o! ğŸ›¡ï¸\")","metadata":{"execution":{"iopub.status.busy":"2025-11-26T23:32:08.317905Z","iopub.status.idle":"2025-11-26T23:32:08.318197Z","shell.execute_reply.started":"2025-11-26T23:32:08.318062Z","shell.execute_reply":"2025-11-26T23:32:08.318077Z"},"trusted":true},"outputs":[],"execution_count":null},{"id":"cd47ab8f","cell_type":"markdown","source":"## â˜ï¸ Plano de Deploy em ProduÃ§Ã£o\nO notebook Ã© o protÃ³tipo. Aqui documentamos como levar o **MktPartner** para o mundo real, listando opÃ§Ãµes de deploy em nuvem (Google Cloud Run vs. Vertex AI), custos estimados e monitoramento, completando a visÃ£o de \"Produto Real\".","metadata":{}},{"id":"69d4be33","cell_type":"code","source":"# ====================================================================\n# CELL 34: DEPLOYMENT DOCUMENTATION\n# ====================================================================\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"ğŸš€ DEPLOYMENT INFORMATION\")\nprint(\"=\"*70)\n\ndeployment_info = {\n    \"current_status\": {\n        \"platform\": \"Kaggle Notebook\",\n        \"status\": \"âœ… Live\",\n        \"url\": \"[Your Kaggle Notebook URL]\",\n        \"access\": \"Public\"\n    },\n    \"production_options\": {\n        \"option_1\": {\n            \"name\": \"Google Cloud Run\",\n            \"cost\": \"$30-300/month\",\n            \"scalability\": \"0-1000 instances\",\n            \"sla\": \"99.95%\",\n            \"setup_time\": \"30 minutes\",\n            \"recommended_for\": \"Production deployments\"\n        },\n        \"option_2\": {\n            \"name\": \"Vertex AI Agent Engine\",\n            \"cost\": \"$300-3000/month\",\n            \"scalability\": \"Enterprise\",\n            \"sla\": \"99.99%\",\n            \"setup_time\": \"2 hours\",\n            \"recommended_for\": \"Enterprise with A2A protocol\"\n        }\n    },\n    \"deployment_files\": {\n        \"dockerfile\": \"âœ… Created\",\n        \"requirements.txt\": \"âœ… Created\",\n        \"app.py\": \"âœ… Created\",\n        \"terraform\": \"âœ… Documented\"\n    },\n    \"monitoring\": {\n        \"logging\": \"âœ… Cloud Logging integrated\",\n        \"metrics\": \"âœ… Custom metrics exported\",\n        \"dashboards\": \"âœ… Templates provided\",\n        \"alerts\": \"âœ… Alert policies defined\"\n    }\n}\n\nprint(\"\\nğŸ“ Current Status:\")\nprint(f\"  Platform: {deployment_info['current_status']['platform']}\")\nprint(f\"  Status: {deployment_info['current_status']['status']}\")\nprint(f\"  Access: {deployment_info['current_status']['access']}\")\n\nprint(\"\\nğŸ—ï¸ Production Options:\")\nfor key, option in deployment_info['production_options'].items():\n    print(f\"\\n  {option['name']}:\")\n    print(f\"    Cost: {option['cost']}\")\n    print(f\"    Scalability: {option['scalability']}\")\n    print(f\"    SLA: {option['sla']}\")\n    print(f\"    Setup Time: {option['setup_time']}\")\n\nprint(\"\\nğŸ“¦ Deployment Files:\")\nfor file, status in deployment_info['deployment_files'].items():\n    print(f\"  {file}: {status}\")\n\nprint(\"\\nğŸ“Š Monitoring:\")\nfor component, status in deployment_info['monitoring'].items():\n    print(f\"  {component}: {status}\")\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"ğŸ“– DEPLOYMENT GUIDES AVAILABLE\")\nprint(\"=\"*70)\nprint(\"\\nâœ… README.md - Complete setup instructions\")\nprint(\"âœ… DEPLOYMENT.md - Detailed deployment guide\")\nprint(\"âœ… EVALUATION.md - Evaluation framework documentation\")\nprint(\"âœ… WRITEUP.md - Kaggle competition submission\")\n\nprint(\"\\n[OK] Deployment documentation complete! ğŸ‰\\n\")","metadata":{"execution":{"iopub.status.busy":"2025-11-26T23:32:08.319780Z","iopub.status.idle":"2025-11-26T23:32:08.320040Z","shell.execute_reply.started":"2025-11-26T23:32:08.319925Z","shell.execute_reply":"2025-11-26T23:32:08.319936Z"},"trusted":true},"outputs":[],"execution_count":null},{"id":"29ab312c","cell_type":"code","source":"# CÃ©lula de Limpeza\nimport os\n# Mata processos do ADK que possam estar rodando em background\n!pkill -f \"adk web\"\nprint(\"ğŸ§¹ Processos antigos limpos.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T23:32:08.321520Z","iopub.status.idle":"2025-11-26T23:32:08.321800Z","shell.execute_reply.started":"2025-11-26T23:32:08.321684Z","shell.execute_reply":"2025-11-26T23:32:08.321695Z"}},"outputs":[],"execution_count":null},{"id":"85082d69-fad6-4bb9-a295-0ded2d2c392d","cell_type":"code","source":"# ====================================================================\n# CELL A: CONFIGURAÃ‡ÃƒO DE PROXY E TUNNELING (Igual ao Day 4b)\n# ====================================================================\n\nfrom IPython.core.display import display, HTML\nfrom jupyter_server.serverapp import list_running_servers\n\n# FunÃ§Ã£o para gerar a URL do Proxy no Kaggle\ndef get_adk_proxy_url():\n    PROXY_HOST = \"https://kkb-production.jupyter-proxy.kaggle.net\"\n    ADK_PORT = \"8000\"\n\n    servers = list(list_running_servers())\n    if not servers:\n        raise Exception(\"No running Jupyter servers found.\")\n\n    baseURL = servers[0][\"base_url\"]\n\n    try:\n        path_parts = baseURL.split(\"/\")\n        kernel = path_parts[2]\n        token = path_parts[3]\n    except IndexError:\n        raise Exception(f\"Could not parse kernel/token from base URL: {baseURL}\")\n\n    url_prefix = f\"/k/{kernel}/{token}/proxy/proxy/{ADK_PORT}\"\n    url = f\"{PROXY_HOST}{url_prefix}\"\n\n    styled_html = f\"\"\"\n    <div style=\"padding: 15px; border: 2px solid #f0ad4e; border-radius: 8px; background-color: #fef9f0; margin: 20px 0;\">\n        <div style=\"font-family: sans-serif; margin-bottom: 12px; color: #333; font-size: 1.1em;\">\n            <strong>âš ï¸ IMPORTANTE: AÃ§Ã£o NecessÃ¡ria</strong>\n        </div>\n        <div style=\"font-family: sans-serif; margin-bottom: 15px; color: #333; line-height: 1.5;\">\n            A Interface Web do ADK <strong>ainda nÃ£o estÃ¡ rodando</strong>. VocÃª deve iniciÃ¡-la na prÃ³xima cÃ©lula.\n            <ol style=\"margin-top: 10px; padding-left: 20px;\">\n                <li style=\"margin-bottom: 5px;\"><strong>Execute a prÃ³xima cÃ©lula</strong> (com <code>!adk web ...</code>).</li>\n                <li style=\"margin-bottom: 5px;\">Aguarde atÃ© que ela mostre que estÃ¡ \"Running\" (ela ficarÃ¡ rodando indefinidamente).</li>\n                <li>Quando estiver rodando, <strong>volte aqui e clique no botÃ£o abaixo</strong>.</li>\n            </ol>\n        </div>\n        <a href='{url}' target='_blank' style=\"\n            display: inline-block; background-color: #1a73e8; color: white; padding: 10px 20px;\n            text-decoration: none; border-radius: 25px; font-family: sans-serif; font-weight: 500;\n            box-shadow: 0 2px 5px rgba(0,0,0,0.2); transition: all 0.2s ease;\">\n            Abrir ADK Web UI (AvaliaÃ§Ã£o Interativa) â†—\n        </a>\n    </div>\n    \"\"\"\n\n    display(HTML(styled_html))\n    return url_prefix\n\nprint(\"âœ… ConfiguraÃ§Ã£o de proxy carregada.\")","metadata":{"execution":{"iopub.status.busy":"2025-11-26T23:32:08.322320Z","iopub.status.idle":"2025-11-26T23:32:08.322676Z","shell.execute_reply.started":"2025-11-26T23:32:08.322548Z","shell.execute_reply":"2025-11-26T23:32:08.322563Z"},"trusted":true},"outputs":[],"execution_count":null},{"id":"040d02cd","cell_type":"code","source":"!adk create marketing_agent --model gemini-2.5-flash-lite --api_key $GOOGLE_API_KEY","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T23:32:08.323293Z","iopub.status.idle":"2025-11-26T23:32:08.323572Z","shell.execute_reply.started":"2025-11-26T23:32:08.323448Z","shell.execute_reply":"2025-11-26T23:32:08.323462Z"}},"outputs":[],"execution_count":null},{"id":"5583806b","cell_type":"code","source":"url_prefix = get_adk_proxy_url()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T23:32:08.325402Z","iopub.status.idle":"2025-11-26T23:32:08.325663Z","shell.execute_reply.started":"2025-11-26T23:32:08.325544Z","shell.execute_reply":"2025-11-26T23:32:08.325556Z"}},"outputs":[],"execution_count":null},{"id":"6dfc75d6-56c3-4de4-a31f-95ff25d5d790","cell_type":"code","source":"# CÃ©lula Nova 1: PreparaÃ§Ã£o\nimport os\n\n# Cria o diretÃ³rio para o agente\n!mkdir -p marketing_agent\n# Cria um init vazio para tornÃ¡-lo um pacote Python\n!touch marketing_agent/__init__.py\n\nprint(\"âœ… Pasta 'marketing_agent' criada.\")","metadata":{"execution":{"iopub.status.busy":"2025-11-26T23:32:08.329707Z","iopub.status.idle":"2025-11-26T23:32:08.330040Z","shell.execute_reply.started":"2025-11-26T23:32:08.329905Z","shell.execute_reply":"2025-11-26T23:32:08.329919Z"},"trusted":true},"outputs":[],"execution_count":null},{"id":"c729a92f-e648-4f5b-a23b-30075ad6a56d","cell_type":"code","source":"import os\nfrom kaggle_secrets import UserSecretsClient\n\n# Garante as credenciais\nos.environ[\"GOOGLE_API_KEY\"] = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n\nprint(\"ğŸš€ Iniciando ADK Web UI corretamente...\")\nprint(\"ğŸ‘‰ No navegador, certifique-se de selecionar 'marketing_agent' no menu superior.\")\n\n# MUDANÃ‡A CRÃTICA: Usamos '.' para servir o diretÃ³rio atual\n!adk web . --url_prefix {url_prefix}","metadata":{"execution":{"iopub.status.busy":"2025-11-26T23:32:08.331992Z","iopub.status.idle":"2025-11-26T23:32:08.332502Z","shell.execute_reply.started":"2025-11-26T23:32:08.332335Z","shell.execute_reply":"2025-11-26T23:32:08.332352Z"},"trusted":true},"outputs":[],"execution_count":null},{"id":"bb97281c","cell_type":"code","source":"# CÃ©lula de Limpeza\nimport os\n# Mata processos do ADK que possam estar rodando em background\n!pkill -f \"adk web\"\nprint(\"ğŸ§¹ Processos antigos limpos.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T23:32:08.334274Z","iopub.status.idle":"2025-11-26T23:32:08.334678Z","shell.execute_reply.started":"2025-11-26T23:32:08.334489Z","shell.execute_reply":"2025-11-26T23:32:08.334507Z"}},"outputs":[],"execution_count":null}]}